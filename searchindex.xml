<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>行为模式</title><url>https://www.zhaohaiyu.com/post/designmode/behavioral/</url><categories><category>design mode</category></categories><tags><tag>设计模式</tag></tags><content type="html"> 责任链模式 责任链模式是一种行为设计模式， 允许你将请求沿着处理者链进行发送。 收到请求后， 每个处理者均可对请求进行处理， 或将其传递给链上的下个处理者。比如 kratos,gin等开源库的中间件实现。
代码实现 package main import ( "context" "fmt" ) type Handler func(ctx context.Context, req interface{}) (resp interface{}, err error) type Middleware func(next Handler) Handler func Chain(middlewares ...Middleware) Middleware { return func(next Handler) Handler { for i := len(middlewares) - 1; i >= 0; i-- { next = middlewares[i](next) } return next } } func main() { c := Chain(func(next Handler) Handler { return func(ctx context.Context, req interface{}) (resp interface{}, err error) { fmt.Println("handler 1 before") resp, err = next(ctx, req) fmt.Println("handler 1 after") return resp, err } }, func(next Handler) Handler { return func(ctx context.Context, req interface{}) (resp interface{}, err error) { fmt.Println("handler 2 before") resp, err = next(ctx, req) fmt.Println("handler 2 after") return resp, err } }) resp, err := c(func(ctx context.Context, req interface{}) (resp interface{}, err error) { fmt.Println("handler req:", req) return req, nil })(context.Background(), "hello") fmt.Println(resp, err) } /* handler 1 before handler 2 before handler req: hello handler 2 after handler 1 after hello &lt;nil> */ 观察者模式 观察者模式用于触发联动。一个对象的改变会触发其它观察者的相关动作，而此对象无需关心连动对象的具体实现。
代码实现 package main import "fmt" type subject interface { register(Observer observer) deregister(Observer observer) notifyAll() } type observer interface { update(string) getID() string } type item struct { observerList []observer name string inStock bool } func newItem(name string) *item { return &amp;item{ name: name, } } func (i *item) updateAvailability() { fmt.Printf("Item %s is now in stock\n", i.name) i.inStock = true i.notifyAll() } func (i *item) register(o observer) { i.observerList = append(i.observerList, o) } func (i *item) deregister(o observer) { i.observerList = removeFromslice(i.observerList, o) } func (i *item) notifyAll() { for _, observer := range i.observerList { observer.update(i.name) } } func removeFromslice(observerList []observer, observerToRemove observer) []observer { observerListLength := len(observerList) for i, observer := range observerList { if observerToRemove.getID() == observer.getID() { observerList[observerListLength-1], observerList[i] = observerList[i], observerList[observerListLength-1] return observerList[:observerListLength-1] } } return observerList } type customer struct { id string } func (c *customer) update(itemName string) { fmt.Printf("Sending email to customer %s for item %s\n", c.id, itemName) } func (c *customer) getID() string { return c.id } func main() { shirtItem := newItem("Nike Shirt") observerFirst := &amp;customer{id: "abc@gmail.com"} observerSecond := &amp;customer{id: "xyz@gmail.com"} shirtItem.register(observerFirst) shirtItem.register(observerSecond) shirtItem.updateAvailability() } /* Item Nike Shirt is now in stock Sending email to customer abc@gmail.com for item Nike Shirt Sending email to customer xyz@gmail.com for item Nike Shirt */ 模板方法模式 模版方法模式使用继承机制，把通用步骤和通用方法放到父类中，把具体实现延迟到子类中实现。使得实现符合开闭原则。
如实例代码中通用步骤在父类中实现（准备、下载、保存、收尾）下载和保存的具体实现留到子类中，并且提供 保存方法的默认实现。
因为Golang不提供继承机制，需要使用匿名组合模拟实现继承。
此处需要注意：因为父类需要调用子类方法，所以子类需要匿名组合父类的同时，父类需要持有子类的引用。
代码实现 package main import "fmt" type Downloader interface { Download(uri string) } type template struct { implement uri string } type implement interface { download() save() } func newTemplate(impl implement) *template { return &amp;template{ implement: impl, } } func (t *template) Download(uri string) { t.uri = uri fmt.Print("prepare downloading\n") t.implement.download() t.implement.save() fmt.Print("finish downloading\n") } func (t *template) save() { fmt.Print("default save\n") } type HTTPDownloader struct { *template } func NewHTTPDownloader() Downloader { downloader := &amp;HTTPDownloader{} template := newTemplate(downloader) downloader.template = template return downloader } func (d *HTTPDownloader) download() { fmt.Printf("download %s via http\n", d.uri) } func (*HTTPDownloader) save() { fmt.Printf("http save\n") } type FTPDownloader struct { *template } func NewFTPDownloader() Downloader { downloader := &amp;FTPDownloader{} template := newTemplate(downloader) downloader.template = template return downloader } func (d *FTPDownloader) download() { fmt.Printf("download %s via ftp\n", d.uri) } func main() { downloader := NewHTTPDownloader() downloader.Download("http://example.com/abc.zip") downloader = NewFTPDownloader() downloader.Download("ftp://example.com/abc.zip") } /* prepare downloading download http://example.com/abc.zip via http http save finish downloading prepare downloading download ftp://example.com/abc.zip via ftp default save finish downloading */ 命令模式 命令模式是一种行为设计模式， 它可将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、 延迟请求执行或将其放入队列中， 且能实现可撤销操作。
命令模式本质是把某个对象的方法调用封装到对象中，方便传递、存储、调用。
示例中把主板单中的启动(start)方法和重启(reboot)方法封装为命令对象，再传递到主机(box)对象中。于两个按钮进行绑定：
第一个机箱(box1)设置按钮1(button1) 为开机按钮2(button2)为重启。 第二个机箱(box1)设置按钮2(button2) 为开机按钮1(button1)为重启。 从而得到配置灵活性。
除了配置灵活外，使用命令模式还可以用作：
批处理 任务队列 undo, redo 等把具体命令封装到对象中使用的场合
代码实现 package command import "fmt" type Command interface { Execute() } type StartCommand struct { mb *MotherBoard } func NewStartCommand(mb *MotherBoard) *StartCommand { return &amp;StartCommand{ mb: mb, } } func (c *StartCommand) Execute() { c.mb.Start() } type RebootCommand struct { mb *MotherBoard } func NewRebootCommand(mb *MotherBoard) *RebootCommand { return &amp;RebootCommand{ mb: mb, } } func (c *RebootCommand) Execute() { c.mb.Reboot() } type MotherBoard struct{} func (*MotherBoard) Start() { fmt.Print("system starting\n") } func (*MotherBoard) Reboot() { fmt.Print("system rebooting\n") } type Box struct { button1 Command button2 Command } func NewBox(button1, button2 Command) *Box { return &amp;Box{ button1: button1, button2: button2, } } func (b *Box) PressButton1() { b.button1.Execute() } func (b *Box) PressButton2() { b.button2.Execute() } 策略模式 它能让你定义一系列算法， 并将每种算法分别放入独立的类中， 以使算法的对象能够相互替换。
代码实现 package main import "fmt" type Payment struct { context *PaymentContext strategy PaymentStrategy } type PaymentContext struct { Name, CardID string Money int } func NewPayment(name, cardid string, money int, strategy PaymentStrategy) *Payment { return &amp;Payment{ context: &amp;PaymentContext{ Name: name, CardID: cardid, Money: money, }, strategy: strategy, } } func (p *Payment) Pay() { p.strategy.Pay(p.context) } type PaymentStrategy interface { Pay(*PaymentContext) } type Cash struct{} func (*Cash) Pay(ctx *PaymentContext) { fmt.Printf("Pay $%d to %s by cash\n", ctx.Money, ctx.Name) } type Bank struct{} func (*Bank) Pay(ctx *PaymentContext) { fmt.Printf("Pay $%d to %s by bank account %s\n", ctx.Money, ctx.Name, ctx.CardID) } func main() { payment := NewPayment("Ada", "", 123, &amp;Cash{}) payment.Pay() payment = NewPayment("Bob", "0002", 888, &amp;Bank{}) payment.Pay() } /* Pay $123 to Ada by cash Pay $888 to Bob by bank account 0002 */ 状态模式 让你能在一个对象的内部状态变化时改变其行为， 使其看上去就像改变了自身所属的类一样。
代码实现 package main import ( "fmt" ) // Machine 状态机 type Machine struct { state IState } // SetState 更新状态 func (m *Machine) SetState(state IState) { m.state = state } // GetStateName 获取当前状态 func (m *Machine) GetStateName() string { return m.state.GetName() } func (m *Machine) Approval() { m.state.Approval(m) } func (m *Machine) Reject() { m.state.Reject(m) } // IState 状态 type IState interface { // 审批通过 Approval(m *Machine) // 驳回 Reject(m *Machine) // 获取当前状态名称 GetName() string } // leaderApproveState 直属领导审批 type leaderApproveState struct{} // Approval 获取状态名字 func (leaderApproveState) Approval(m *Machine) { fmt.Println("leader 审批成功") m.SetState(GetFinanceApproveState()) } // GetName 获取状态名字 func (leaderApproveState) GetName() string { return "LeaderApproveState" } // Reject 获取状态名字 func (leaderApproveState) Reject(m *Machine) {} func GetLeaderApproveState() IState { return &amp;leaderApproveState{} } // financeApproveState 财务审批 type financeApproveState struct{} // Approval 审批通过 func (f financeApproveState) Approval(m *Machine) { fmt.Println("财务审批成功") fmt.Println("出发打款操作") } // 拒绝 func (f financeApproveState) Reject(m *Machine) { m.SetState(GetLeaderApproveState()) } // GetName 获取名字 func (f financeApproveState) GetName() string { return "FinanceApproveState" } // GetFinanceApproveState GetFinanceApproveState func GetFinanceApproveState() IState { return &amp;financeApproveState{} } func main() { m := &amp;Machine{state: GetLeaderApproveState()} fmt.Println("LeaderApproveState", m.GetStateName()) m.Approval() fmt.Println("FinanceApproveState", m.GetStateName()) m.Reject() fmt.Println("LeaderApproveState", m.GetStateName()) m.Approval() fmt.Println("FinanceApproveState", m.GetStateName()) m.Approval() } /* LeaderApproveState LeaderApproveState leader 审批成功 FinanceApproveState FinanceApproveState LeaderApproveState LeaderApproveState leader 审批成功 FinanceApproveState FinanceApproveState 财务审批成功 出发打款操作 */ 迭代器模式 让你能在不暴露集合底层表现形式 （列表、 栈和树等） 的情况下遍历集合中所有的元素。
代码实现 package main import "fmt" type collection interface { createIterator() iterator } type userCollection struct { users []*user } func (u *userCollection) createIterator() iterator { return &amp;userIterator{ users: u.users, } } type iterator interface { hasNext() bool getNext() *user } type userIterator struct { index int users []*user } func (u *userIterator) hasNext() bool { if u.index &lt; len(u.users) { return true } return false } func (u *userIterator) getNext() *user { if u.hasNext() { user := u.users[u.index] u.index++ return user } return nil } type user struct { name string age int } func main() { user1 := &amp;user{ name: "a", age: 30, } user2 := &amp;user{ name: "b", age: 20, } userCollection := &amp;userCollection{ users: []*user{user1, user2}, } iterator := userCollection.createIterator() for iterator.hasNext() { user := iterator.getNext() fmt.Printf("User is %+v\n", user) } } /* User is &amp;{name:a age:30} User is &amp;{name:b age:20} */ 访问者模式 访问者模式可以给一系列对象透明的添加功能，并且把相关代码封装到一个类中。
对象只要预留访问者接口Accept则后期为对象添加功能的时候就不需要改动对象。
代码实现 package main import "fmt" type Customer interface { Accept(Visitor) } type Visitor interface { Visit(Customer) } type EnterpriseCustomer struct { name string } type CustomerCol struct { customers []Customer } func (c *CustomerCol) Add(customer Customer) { c.customers = append(c.customers, customer) } func (c *CustomerCol) Accept(visitor Visitor) { for _, customer := range c.customers { customer.Accept(visitor) } } func NewEnterpriseCustomer(name string) *EnterpriseCustomer { return &amp;EnterpriseCustomer{ name: name, } } func (c *EnterpriseCustomer) Accept(visitor Visitor) { visitor.Visit(c) } type IndividualCustomer struct { name string } func NewIndividualCustomer(name string) *IndividualCustomer { return &amp;IndividualCustomer{ name: name, } } func (c *IndividualCustomer) Accept(visitor Visitor) { visitor.Visit(c) } type ServiceRequestVisitor struct{} func (*ServiceRequestVisitor) Visit(customer Customer) { switch c := customer.(type) { case *EnterpriseCustomer: fmt.Printf("serving enterprise customer %s\n", c.name) case *IndividualCustomer: fmt.Printf("serving individual customer %s\n", c.name) } } // only for enterprise type AnalysisVisitor struct{} func (*AnalysisVisitor) Visit(customer Customer) { switch c := customer.(type) { case *EnterpriseCustomer: fmt.Printf("analysis enterprise customer %s\n", c.name) } } func main() { c := &amp;CustomerCol{} c.Add(NewEnterpriseCustomer("A company")) c.Add(NewEnterpriseCustomer("B company")) c.Add(NewIndividualCustomer("bob")) c.Accept(&amp;ServiceRequestVisitor{}) c = &amp;CustomerCol{} c.Add(NewEnterpriseCustomer("A company")) c.Add(NewIndividualCustomer("bob")) c.Add(NewEnterpriseCustomer("B company")) c.Accept(&amp;AnalysisVisitor{}) } /* serving enterprise customer A company serving enterprise customer B company serving individual customer bob analysis enterprise customer A company analysis enterprise customer B company */ 备忘录模式 备忘录模式用于保存程序内部状态到外部，又不希望暴露内部状态的情形。
程序内部状态使用窄接口传递给外部进行存储，从而不暴露程序实现细节。
备忘录模式同时可以离线保存内部状态，如保存到数据库，文件等。
代码实现 package main import "fmt" type Memento interface{} type Game struct { hp, mp int } type gameMemento struct { hp, mp int } func (g *Game) Play(mpDelta, hpDelta int) { g.mp += mpDelta g.hp += hpDelta } func (g *Game) Save() Memento { return &amp;gameMemento{ hp: g.hp, mp: g.mp, } } func (g *Game) Load(m Memento) { gm := m.(*gameMemento) g.mp = gm.mp g.hp = gm.hp } func (g *Game) Status() { fmt.Printf("Current HP:%d, MP:%d\n", g.hp, g.mp) } func main() { game := &amp;Game{ hp: 10, mp: 10, } game.Status() progress := game.Save() game.Play(-2, -3) game.Status() game.Load(progress) game.Status() } /* Current HP:10, MP:10 Current HP:7, MP:8 Current HP:10, MP:10 */ 解释器模式 解释器模式定义一套语言文法，并设计该语言解释器，使用户能使用特定文法控制解释器行为。
解释器模式的意义在于，它分离多种复杂功能的实现，每个功能只需关注自身的解释。
对于调用者不用关心内部的解释器的工作，只需要用简单的方式组合命令就可以。
代码实现 package main import ( "fmt" "strconv" "strings" ) type Node interface { Interpret() int } type ValNode struct { val int } func (n *ValNode) Interpret() int { return n.val } type AddNode struct { left, right Node } func (n *AddNode) Interpret() int { return n.left.Interpret() + n.right.Interpret() } type MinNode struct { left, right Node } func (n *MinNode) Interpret() int { return n.left.Interpret() - n.right.Interpret() } type Parser struct { exp []string index int prev Node } func (p *Parser) Parse(exp string) { p.exp = strings.Split(exp, " ") for { if p.index >= len(p.exp) { return } switch p.exp[p.index] { case "+": p.prev = p.newAddNode() case "-": p.prev = p.newMinNode() default: p.prev = p.newValNode() } } } func (p *Parser) newAddNode() Node { p.index++ return &amp;AddNode{ left: p.prev, right: p.newValNode(), } } func (p *Parser) newMinNode() Node { p.index++ return &amp;MinNode{ left: p.prev, right: p.newValNode(), } } func (p *Parser) newValNode() Node { v, _ := strconv.Atoi(p.exp[p.index]) p.index++ return &amp;ValNode{ val: v, } } func (p *Parser) Result() Node { return p.prev } func main() { p := &amp;Parser{} p.Parse("1 + 2 + 3 - 4 + 5 - 6") res := p.Result().Interpret() expect := 1 if res != expect { fmt.Println(res,expect) } } 中介模式 中介者模式封装对象之间互交，使依赖变的简单，并且使复杂互交简单化，封装在中介者中。
例子中的中介者使用单例模式生成中介者。
中介者的change使用switch判断类型。
代码实现 package main import ( "fmt" "strings" ) type CDDriver struct { Data string } func (c *CDDriver) ReadData() { c.Data = "music,image" fmt.Printf("CDDriver: reading data %s\n", c.Data) GetMediatorInstance().changed(c) } type CPU struct { Video string Sound string } func (c *CPU) Process(data string) { sp := strings.Split(data, ",") c.Sound = sp[0] c.Video = sp[1] fmt.Printf("CPU: split data with Sound %s, Video %s\n", c.Sound, c.Video) GetMediatorInstance().changed(c) } type VideoCard struct { Data string } func (v *VideoCard) Display(data string) { v.Data = data fmt.Printf("VideoCard: display %s\n", v.Data) GetMediatorInstance().changed(v) } type SoundCard struct { Data string } func (s *SoundCard) Play(data string) { s.Data = data fmt.Printf("SoundCard: play %s\n", s.Data) GetMediatorInstance().changed(s) } type Mediator struct { CD *CDDriver CPU *CPU Video *VideoCard Sound *SoundCard } var mediator *Mediator func GetMediatorInstance() *Mediator { if mediator == nil { mediator = &amp;Mediator{} } return mediator } func (m *Mediator) changed(i interface{}) { switch inst := i.(type) { case *CDDriver: m.CPU.Process(inst.Data) case *CPU: m.Sound.Play(inst.Sound) m.Video.Display(inst.Video) } } func main() { mediator := GetMediatorInstance() mediator.CD = &amp;CDDriver{} mediator.CPU = &amp;CPU{} mediator.Video = &amp;VideoCard{} mediator.Sound = &amp;SoundCard{} //Tiggle mediator.CD.ReadData() fmt.Printf("%#v\n", mediator) } /* CDDriver: reading data music,image CPU: split data with Sound music, Video image SoundCard: play music VideoCard: display image &amp;main.Mediator{CD:(*main.CDDriver)(0xc000010250), CPU:(*main.CPU)(0xc000060040), Video:(*main.VideoCard)(0xc000010260), Sound:(*main.SoundCard)(0xc000010270)} */ References https://github.com/senghoo/golang-design-pattern https://refactoringguru.cn/design-patterns https://lailin.xyz/post/singleton.html</content></entry><entry><title>结构型模式</title><url>https://www.zhaohaiyu.com/post/designmode/structure/</url><categories><category>design mode</category></categories><tags><tag>设计模式</tag></tags><content type="html"> 适配器模式 适配器模式用于转换一种接口适配另一种接口。比如，现在有个借口是对json字符串进行分析等，现在有一些yaml文件也要分析，这时候我我们就应该给yaml字符串就个适配器，转换成json字符串，然后就行分析。
代码实现 package main import ( "fmt" "github.com/ghodss/yaml" ) type Analysis interface { Analyze(string) error } type JsonAnalysis struct{} func (*JsonAnalysis) Analyze(jsonStr string) error { // 函数逻辑 fmt.Println(jsonStr) return nil } type yamlAnalysis struct { ja *JsonAnalysis } func (y *yamlAnalysis) Analyze(yamlStr string) error { bs, err := yaml.YAMLToJSON([]byte(yamlStr)) if err != nil { return err } return y.ja.Analyze(string(bs)) } func main() { ja := &amp;JsonAnalysis{} err := ja.Analyze("{\"name\":\"zhy\",\"age\":18}") if err != nil { fmt.Println(err) } ya := &amp;yamlAnalysis{ja: ja} err = ya.Analyze("name: you\nage: 88") if err != nil { fmt.Println(err) } } /* {"name":"zhy","age":18} {"age":88,"name":"you"} */ 桥接模式 桥接模式分离抽象部分和实现部分。使得两部分独立扩展。
桥接模式类似于策略模式，区别在于策略模式封装一系列算法使得算法可以互相替换。
策略模式使抽象部分和实现部分分离，可以独立变化。
比如要发消息，可以发很多种方式，微信、qq、email、短信等等，也可以发很多类型，日常、紧急等的。这时我们可以把发送的的方法做抽象，把类型做实现。
代码实现 package main import "fmt" type Message interface { SendMessage(s string) error } type MessageMethod interface { Send(string) error } type qq struct{} func (*qq) Send(s string) error { fmt.Println("send qq:", s) return nil } type weixin struct{} func (*weixin) Send(s string) error { fmt.Println("send weixin:", s) return nil } type email struct{} func (*email) Send(s string) error { fmt.Println("send email:", s) return nil } type InfoMessage struct { method MessageMethod } func (i *InfoMessage) SendMessage(s string) error { s = "info message: " + s return i.method.Send(s) } type UrgencyMessage struct { method MessageMethod } func (u *UrgencyMessage) SendMessage(s string) error { s = "urgency message: " + s return u.method.Send(s) } func main() { qq := new(qq) weixin := new(weixin) email := new(email) info := new(InfoMessage) info.method = qq info.SendMessage("hello") info.method = weixin info.SendMessage("hello") info.method = email info.SendMessage("hello") urgency := new(UrgencyMessage) urgency.method = qq urgency.SendMessage("hello") urgency.method = weixin urgency.SendMessage("hello") urgency.method = email urgency.SendMessage("hello") } /* send qq: info message: hello send weixin: info message: hello send email: info message: hello send qq: urgency message: hello send weixin: urgency message: hello send email: urgency message: hello */ 装饰器模式 装饰模式使用对象组合的方式动态改变或增加对象行为。Go语言借助于匿名组合和非入侵式接口可以很方便实现装饰模式。使用匿名组合，在装饰器中不必显式定义转调原对象方法。
代码实现 package main import "fmt" type Component interface { Calc() int } type ConcreteComponent struct{} func (*ConcreteComponent) Calc() int { return 10 } type MulDecorator struct { Component num int } func WarpMulDecorator(c Component, num int) Component { return &amp;MulDecorator{ Component: c, num: num, } } func (d *MulDecorator) Calc() int { return d.Component.Calc() * d.num } type AddDecorator struct { Component num int } func WarpAddDecorator(c Component, num int) Component { return &amp;AddDecorator{ Component: c, num: num, } } func (d *AddDecorator) Calc() int { return d.Component.Calc() + d.num } func main() { c := &amp;ConcreteComponent{} md := WarpMulDecorator(c, 2) ad := WarpAddDecorator(c, 3) fmt.Println(md.Calc()) fmt.Println(ad.Calc()) } /* 20 13 */ 代理模式 代理模式用于延迟处理操作或者在进行实际操作前后进行其它处理。比如在限流中间件中
代码实现 package main import ( "errors" "fmt" "sync" "time" ) type Serve interface { handle(name string) (string, error) } type server struct { lock sync.RWMutex serve Serve maxAllowedRequest int rateLimiter map[string]int } func (s *server) getService(name string) (string, error) { s.lock.RLock() nowNumber := s.rateLimiter[name] s.lock.RUnlock() if nowNumber >= s.maxAllowedRequest { return "", errors.New("rate limit") } // 更新计数器 s.lock.Lock() s.rateLimiter[name]++ s.lock.Unlock() str, err := s.serve.handle(name) // 执行后减少计数器 s.lock.Lock() s.rateLimiter[name]-- s.lock.Unlock() if err != nil { return "", err } return str, nil } type hand struct{} func (h *hand) handle(name string) (string, error) { time.Sleep(time.Microsecond * 500) return fmt.Sprintf("hello %s", name), nil } func main() { wg := &amp;sync.WaitGroup{} wg.Add(20) s := &amp;server{ serve: &amp;hand{}, maxAllowedRequest: 10, rateLimiter: map[string]int{}, } for i := 0; i &lt; 20; i++ { go func(i int) { defer wg.Done() res, err := s.getService("world") if err != nil { fmt.Println(i, "error:", err) } else { fmt.Println(i, "success:", res) } }(i) } wg.Wait() } /* 15 error: rate limit 18 error: rate limit 10 error: rate limit 4 error: rate limit 7 error: rate limit 6 error: rate limit 16 error: rate limit 9 error: rate limit 11 error: rate limit 17 error: rate limit 14 success: hello world 19 success: hello world 13 success: hello world 2 success: hello world 12 success: hello world 1 success: hello world 3 success: hello world 8 success: hello world 5 success: hello world 0 success: hello world */ 组合模式 组合模式统一对象和对象集，使得使用相同接口使用对象和对象集。
组合模式常用于树状结构，用于统一叶子节点和树节点的访问，并且可以用于应用某一操作到所有子节点。
比如要搜索文件夹下的所有文件名
代码实现 package main import "fmt" type component interface { search(string) } type file struct { name string } func (f *file) search(keyword string) { fmt.Printf("Searching for keyword %s in file %s\n", keyword, f.name) } func (f *file) getName() string { return f.name } type folder struct { components []component name string } func (f *folder) search(keyword string) { fmt.Printf("Serching recursively for keyword %s in folder %s\n", keyword, f.name) for _, composite := range f.components { composite.search(keyword) } } func (f *folder) add(c component) { f.components = append(f.components, c) } func main() { file1 := &amp;file{name: "File1"} file2 := &amp;file{name: "File2"} file3 := &amp;file{name: "File3"} folder1 := &amp;folder{ name: "Folder1", } folder1.add(file1) folder2 := &amp;folder{ name: "Folder2", } folder2.add(file2) folder2.add(file3) folder2.add(folder1) folder2.search("rose") } /* Serching recursively for keyword rose in folder Folder2 Searching for keyword rose in file File2 Searching for keyword rose in file File3 Serching recursively for keyword rose in folder Folder1 Searching for keyword rose in file File1 */ 外观模式 API 为facade 模块的外观接口，大部分代码使用此接口简化对facade类的访问。
facade模块同时暴露了a和b 两个Module 的NewXXX和interface，其它代码如果需要使用细节功能时可以直接调用。
代码实现 package main import "fmt" func NewAPI() API { return &amp;apiImpl{ a: NewAModuleAPI(), b: NewBModuleAPI(), } } //API is facade interface of facade package type API interface { Test() string } //facade implement type apiImpl struct { a AModuleAPI b BModuleAPI } func (a *apiImpl) Test() string { aRet := a.a.TestA() bRet := a.b.TestB() return fmt.Sprintf("%s\n%s", aRet, bRet) } //NewAModuleAPI return new AModuleAPI func NewAModuleAPI() AModuleAPI { return &amp;aModuleImpl{} } //AModuleAPI ... type AModuleAPI interface { TestA() string } type aModuleImpl struct{} func (*aModuleImpl) TestA() string { return "A module running" } //NewBModuleAPI return new BModuleAPI func NewBModuleAPI() BModuleAPI { return &amp;bModuleImpl{} } //BModuleAPI ... type BModuleAPI interface { TestB() string } type bModuleImpl struct{} func (*bModuleImpl) TestB() string { return "B module running" } func main() { api := NewAPI() fmt.Println(api.Test()) } /* A module running B module running */ 享元模式 享元模式从对象中剥离出不发生改变且多个实例需要的重复数据，独立出一个享元，使多个对象共享，从而节省内存以及减少对象数量。
代码实现 package main import "fmt" type ImageFlyweightFactory struct { maps map[string]*ImageFlyweight } var imageFactory *ImageFlyweightFactory func GetImageFlyweightFactory() *ImageFlyweightFactory { if imageFactory == nil { imageFactory = &amp;ImageFlyweightFactory{ maps: make(map[string]*ImageFlyweight), } } return imageFactory } func (f *ImageFlyweightFactory) Get(filename string) *ImageFlyweight { image := f.maps[filename] if image == nil { image = NewImageFlyweight(filename) f.maps[filename] = image } return image } type ImageFlyweight struct { data string } func NewImageFlyweight(filename string) *ImageFlyweight { // Load image file data := fmt.Sprintf("image data %s", filename) return &amp;ImageFlyweight{ data: data, } } func (i *ImageFlyweight) Data() string { return i.data } type ImageViewer struct { *ImageFlyweight } func NewImageViewer(filename string) *ImageViewer { image := GetImageFlyweightFactory().Get(filename) return &amp;ImageViewer{ ImageFlyweight: image, } } func (i *ImageViewer) Display() { fmt.Printf("Display: %s\n", i.Data()) } References https://github.com/senghoo/golang-design-pattern https://refactoringguru.cn/design-patterns https://lailin.xyz/post/singleton.html</content></entry><entry><title>创建者模式</title><url>https://www.zhaohaiyu.com/post/designmode/creator/</url><categories><category>design mode</category></categories><tags><tag>设计模式</tag></tags><content type="html"> 单例模式 为什么要用单例模式 保证一个对象只有一个实例 ，减少内存开销。比如一些可以复用一个连接的网络，比如http2 client等，而且可以减少网络开销。
为什么不用个全局变量控制 因为任何代码都有可能覆盖掉那些变量的内容， 从而引发程序崩溃。
代码实现 package main import ( "fmt" "sync" ) type Single struct { } var single *Single var once = &amp;sync.Once{} func NewSingle() *Single { once.Do(func() { single = &amp;Single{ // 初始化 } }) return single } func main() { for i := 0; i &lt; 1000; i++ { s := NewSingle() fmt.Printf("create %d,address %p\n", i, s) } } /* 结果： create 0,address 0x1164fe0 create 1,address 0x1164fe0 create 2,address 0x1164fe0 create 3,address 0x1164fe0 create 4,address 0x1164fe0 create 5,address 0x1164fe0 create 6,address 0x1164fe0 create 7,address 0x1164fe0 create 8,address 0x1164fe0 ... */ 工厂模式 我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。比如电脑支持intel cpu，现在要支持amd cpu，我们就可以让所有cpu实现接口。
简单工厂模式 实现简单，不适合复杂场景
package main import ( "errors" "fmt" ) // 工厂接口 type CpuFactory interface { Run() string } type IntelCpu struct{} func (*IntelCpu) Run() string { return "intel cpu is running" } type AmdCpu struct{} func (*AmdCpu) Run() string { return "amd cpu is running" } func NewCpu(name string) (CpuFactory, error) { switch name { case "intel": return &amp;IntelCpu{}, nil case "amd": return &amp;AmdCpu{}, nil default: return nil, errors.New("no such cpu") } } func main() { c1, err := NewCpu("intel") if err != nil { panic(err) } fmt.Println(c1.Run()) c2, err := NewCpu("amd") if err != nil { panic(err) } fmt.Println(c2.Run()) _, err = NewCpu("other") fmt.Println(err) } /* 结果： intel cpu is running amd cpu is running no such cpu */ 工厂方法模式 大部分时候，我们创建对象要创建很多逻辑，比如初始化变量，从远端请求config等等。这是我们需要每次struct提供个创建方法。
package main import ( "errors" "fmt" ) // 工厂接口 type CpuFactory interface { Run() string } type IntelCpu struct{} func (*IntelCpu) Run() string { return "intel cpu is running" } func NewIntelCpu() *IntelCpu { // 做创建逻辑 return &amp;IntelCpu{} } type AmdCpu struct{} func (*AmdCpu) Run() string { return "amd cpu is running" } func NewAmdCpu() *AmdCpu { // 做创建逻辑 return &amp;AmdCpu{} } func NewCpu(name string) (CpuFactory, error) { switch name { case "intel": return NewIntelCpu(), nil case "amd": return NewAmdCpu(), nil default: return nil, errors.New("no such cpu") } } func main() { c1, err := NewCpu("intel") if err != nil { panic(err) } fmt.Println(c1.Run()) c2, err := NewCpu("amd") if err != nil { panic(err) } fmt.Println(c2.Run()) _, err = NewCpu("other") fmt.Println(err) } /* 结果： intel cpu is running amd cpu is running no such cpu */ 抽象工厂模式 抽象工厂模式则是针对的多个产品等级结构， 我们可以将一种产品等级想象为一个产品族，所谓的产品族，是指位于不同产品等级结构中功能相关联的产品组成的家族。用于复杂场景，比如amd和intel都生成cpu和gpu
package main import "fmt" // 抽象工厂接口 type ElementAbstractFactory interface { CreateCpu() Cpu // cpu CreateGpu() Gpu // Gpu } func GetElementAbstractFactory(brand string) (ElementAbstractFactory, error) { if brand == "intel" { return &amp;intel{}, nil } if brand == "amd" { return &amp;amd{}, nil } return nil, fmt.Errorf("Wrong brand type passed") } // cpu 具体工厂 type Cpu interface { Run() string } type Gpu interface { Graphics() string } type intel struct{} func (*intel) CreateCpu() Cpu { return &amp;intelCpu{} } func (*intel) CreateGpu() Gpu { return &amp;intelGpu{} } type intelCpu struct{} func (*intelCpu) Run() string { return "intel cpu is running" } type intelGpu struct{} func (*intelGpu) Graphics() string { return "intel gpu is working on graphics" } type amd struct{} func (*amd) CreateCpu() Cpu { return &amp;amdCpu{} } func (*amd) CreateGpu() Gpu { return &amp;amdGpu{} } type amdCpu struct{} func (*amdCpu) Run() string { return "amd cpu is running" } type amdGpu struct{} func (*amdGpu) Graphics() string { return "amd gpu is working on graphics" } func main() { e, _ := GetElementAbstractFactory("intel") cpu := e.CreateCpu() gpu := e.CreateGpu() fmt.Println(cpu.Run()) fmt.Println(gpu.Graphics()) e2, _ := GetElementAbstractFactory("amd") cpu2 := e2.CreateCpu() gpu2 := e2.CreateGpu() fmt.Println(cpu2.Run()) fmt.Println(gpu2.Graphics()) } /* intel cpu is running intel gpu is working on graphics amd cpu is running amd gpu is working on graphics */ 生成器模式 在对其进行构造时需要对诸多成员变量和嵌套对象进行繁复的初始化工作。 这些初始化代码通常深藏于一个包含众多参数且让人基本看不懂的构造函数中； 甚至还有更糟糕的情况， 那就是这些代码散落在客户端代码的多个位置。比如在go中，就可以利用指针传递完成初始化。
package main import "fmt" // Computer 是生成器接口 type Computer interface { Cpu() Gpu() } type Director struct { builder Computer } // NewDirector ... func NewDirector(builder Computer) *Director { return &amp;Director{ builder: builder, } } // Construct Product func (d *Director) Construct() { d.builder.Cpu() d.builder.Gpu() } type Computer1 struct { cpu string gpu string } func (c *Computer1) Cpu() { c.cpu = "intel" } func (c *Computer1) Gpu() { c.gpu = "nvida" } type Computer2 struct { cpu string gpu string } func (c *Computer2) Cpu() { c.cpu = "amd" } func (c *Computer2) Gpu() { c.gpu = "amd" } func main() { c1 := Computer1{} d := NewDirector(&amp;c1) fmt.Printf("%+v\n", c1) d.Construct() fmt.Printf("%+v\n", c1) c2 := Computer2{} d2 := NewDirector(&amp;c2) fmt.Printf("%+v\n", c2) d2.Construct() fmt.Printf("%+v\n", c2) } /* {cpu: gpu:} {cpu:intel gpu:nvida} {cpu: gpu:} {cpu:amd gpu:amd} */ 原型模式 原型模式使对象能复制自身，并且暴露到接口中，使客户端面向接口编程时，不知道接口实际对象的情况下生成新的对象。
原型模式配合原型管理器使用，使得客户端在不知道具体类的情况下，通过接口管理器得到新的实例，并且包含部分预设定配置。
package main //Cloneable 是原型对象需要实现的接口 type Cloneable interface { Clone() Cloneable } type PrototypeManager struct { prototypes map[string]Cloneable } func NewPrototypeManager() *PrototypeManager { return &amp;PrototypeManager{ prototypes: make(map[string]Cloneable), } } func (p *PrototypeManager) Get(name string) Cloneable { return p.prototypes[name].Clone() } func (p *PrototypeManager) Set(name string, prototype Cloneable) { p.prototypes[name] = prototype } References https://github.com/senghoo/golang-design-pattern https://refactoringguru.cn/design-patterns https://lailin.xyz/post/singleton.html</content></entry><entry><title>Go错误处理</title><url>https://www.zhaohaiyu.com/post/go/go-error/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> error定义 数据结构 go语言error是一普通的值，实现方式为简单一个接口。
// The error built-in interface type is the conventional interface for // representing an error condition, with the nil value representing no error. type error interface { Error() string } 创建error
使用errors.New() // New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return &amp;errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 返回的是errorString结构体 实现了error接口的Error()方法
使用fmt.Errorf（）创建 创建方式为把字符串拼接起来，然后调用errors.New().
基础库中的自定义的error bufio中的错误：
ErrTooLong = errors.New("bufio.Scanner: token too long") ErrNegativeAdvance = errors.New("bufio.Scanner: SplitFunc returns negative advance count") ErrAdvanceTooFar = errors.New("bufio.Scanner: SplitFunc returns advance count beyond input") ErrBadReadCount = errors.New("bufio.Scanner: Read returned impossible count") error的比较 package main import ( "errors" "fmt" ) type errorString struct { s string } func new(s string) error { return &amp;errorString{s: s} } func (e *errorString) Error() string { return e.s } func main() { error1 := errors.New("test") error2 := new("test") fmt.Println(error1 == error2) // false } // 比较结构体 package main import ( "fmt" ) type errorString struct { s string } func new(s string) error { return &amp;errorString{s: s} } func (e *errorString) Error() string { return e.s } func main() { error1 := new("test") fmt.Println(error1 == new("test")) // false } package main import ( "fmt" ) type errorString struct { s string } func new(s string) error { return errorString{s: s} } func (e errorString) Error() string { return e.s } func main() { error1 := new("test") fmt.Println(error1 == new("test")) // true } error对比为对比对比实现interface的结构体类型 和结构体本身
Error or Exception 处理错误的演进 C 单返回值，一般通过传递指针作为入参，返回值为 int 表示成功还是失败。 C++ 引入了 exception，但是无法知道被调用方会抛出什么异常。 Java 引入了 checked exception，方法的所有者必须申明，调用者必须处理。在启动时抛出大量的异常是司空见惯的事情，并在它们的调用堆栈中尽职地记录下来。Java 异常不再是异常，而是变得司空见惯了。它们从良性到灾难性都有使用，异常的严重性由函数的调用者来区分 go Go 的处理异常逻辑是不引入 exception，支持多参数返回，所以你很容易的在函数签名中带上实现了 error interface 的对象，交由调用者来判定。
如果一个函数返回了 value, error，你不能对这个 value 做任何假设，必须先判定 error。唯一可以忽略 error 的是，如果你连 value 也不关心。
Go 中有 panic 的机制，如果你认为和其他语言的 exception 一样，那你就错了。当我们抛出异常的时候，相当于你把 exception 扔给了调用者来处理。比如，你在 C++ 中，把 string 转为 int，如果转换失败，会抛出异常。或者在 java 中转换 string 为 date 失败时，会抛出异常。
Go panic 意味着 fatal error(就是挂了)。不能假设调用者来解决 panic，意味着代码不能继续运行。
使用多个返回值和一个简单的约定，Go 解决了让程序员知道什么时候出了问题，并为真正的异常情况保留了 panic。
代码对比 package main import "fmt" func Positive(x int) bool { return x >= 0 } func Check(x int) { if Positive(x) { fmt.Println("正数") } else { fmt.Println("负数") } } func main() { Check(-1) // 负数 Check(0) // 正数 bug Check(1) // 正数 } package main import "fmt" func Positive(x int) (bool, bool) { if x == 0 { return false, false } return x >= 0, true } func Check(x int) { t, ok := Positive(x) if !ok { fmt.Println("零") return } if t { fmt.Println("正数") } else { fmt.Println("负数") } } func main() { Check(-1) // 负数 Check(0) // 零 Check(1) // 正数 } package main import ( "errors" "fmt" ) func Positive(x int) (bool, error) { if x == 0 { return false, errors.New("为零") } return x >= 0, nil } func Check(x int) { t, err := Positive(x) if err != nil { fmt.Println(err) return } if t { fmt.Println("正数") } else { fmt.Println("负数") } } func main() { Check(-1) // 负数 Check(0) // 为零 Check(1) // 正数 } error使用 对于真正意外的情况，那些表示不可恢复的程序错误，例如索引越界、不可恢复的环境问题、栈溢出，我们才使用 panic。对于其他的错误情况，我们应该是期望使用 error 来进行判定。
简单。
考虑失败，而不是成功。
没有隐藏的控制流。
完全交给你来控制 error。
Error are values。
Sentinel Error 预定义的特定错误，我们叫为 sentinel error，这个名字来源于计算机编程中使用一个特定值来表示不可能进行进一步处理的做法。所以对于 Go，我们使用特定的值来表示错误。
if err == ErrSomething { … } 类似的 io.EOF，更底层的 syscall.ENOENT。
使用 sentinel 值是最不灵活的错误处理策略，因为调用方必须使用 == 将结果与预先声明的值进行比较。当您想要提供更多的上下文时，这就出现了一个问题，因为返回一个不同的错误将破坏相等性检查。
甚至是一些有意义的 fmt.Errorf 携带一些上下文，也会破坏调用者的 == ，调用者将被迫查看 error.Error() 方法的输出，以查看它是否与特定的字符串匹配。
不依赖检查 error.Error 的输出。 不应该依赖检测 error.Error 的输出，Error 方法存在于 error 接口主要用于方便程序员使用，但不是程序(编写测试可能会依赖这个返回)。这个输出的字符串用于记录日志、输出到 stdout 等。
Sentinel errors 成为你 API 公共部分。 如果您的公共函数或方法返回一个特定值的错误，那么该值必须是公共的，当然要有文档记录，这会增加 API 的表面积。
如果 API 定义了一个返回特定错误的 interface，则该接口的所有实现都将被限制为仅返回该错误，即使它们可以提供更具描述性的错误。
比如 io.Reader。像 io.Copy 这类函数需要 reader 的实现者比如返回 io.EOF 来告诉调用者没有更多数据了，但这又不是错误。
Sentinel errors 在两个包之间创建了依赖。 sentinel errors 最糟糕的问题是它们在两个包之间创建了源代码依赖关系。例如，检查错误是否等于 io.EOF，您的代码必须导入 io 包。这个特定的例子听起来并不那么糟糕，因为它非常常见，但是想象一下，当项目中的许多包导出错误值时，存在耦合，项目中的其他包必须导入这些错误值才能检查特定的错误条件(in the form of an import loop)。
结论: 尽可能避免 sentinel errors。 我的建议是避免在编写的代码中使用 sentinel errors。在标准库中有一些使用它们的情况，但这不是一个您应该模仿的模式。
错误类型 Error type 是实现了 error 接口的自定义类型。例如 MyError 类型记录了文件和行号以展示发生了什么。
type Myerror struct { line int file string s string } func (e *Myerror) Error() string { return e.s } func new(file string, line int, s string) error { return &amp;Myerror{line: line, file: file, s: s} } 因为 MyError 是一个 type，调用者可以使用断言转换成这个类型，来获取更多的上下文信息。
err := new("main.go", 23, "test error") switch err := err.(type) { case nil: fmt.Println("err is nil") case *Myerror: fmt.Println("type is *Myerror err line :", err.line) default: fmt.Println("None of them") } // 结果:type is *Myerror err line : 23 与错误值相比，错误类型的一大改进是它们能够包装底层错误以提供更多上下文。
一个不错的例子就是 os.PathError 他提供了底层执行了什么操作、那个路径出了什么问题。
调用者要使用类型断言和类型 switch，就要让自定义的 error 变为 public。这种模型会导致和调用者产生强耦合，从而导致 API 变得脆弱。
结论是尽量避免使用 error types，虽然错误类型比 sentinel errors 更好，因为它们可以捕获关于出错的更多上下文，但是 error types 共享 error values 许多相同的问题。
因此，我的建议是避免错误类型，或者至少避免将它们作为公共 API 的一部分。
非透明的error 在我看来，这是最灵活的错误处理策略，因为它要求代码和调用者之间的耦合最少。
我将这种风格称为不透明错误处理，因为虽然您知道发生了错误，但您没有能力看到错误的内部。作为调用者，关于操作的结果，您所知道的就是它起作用了，或者没有起作用(成功还是失败)。
这就是不透明错误处理的全部功能–只需返回错误而不假设其内容
package main import "os" func test() error { f, err := os.Open("filename.txt") if err != nil { return err } // use f } 为行为而不是类型断言错误 在少数情况下，这种二分错误处理方法是不够的。例如，与进程外的世界进行交互(如网络活动)，需要调用方调查错误的性质，以确定重试该操作是否合理。在这种情况下，我们可以断言错误实现了特定的行为，而不是断言错误是特定的类型或值。考虑这个例子：
// 封装内部 type temporary interface { Temporary() bool } func IsTemporary(err error) bool { te, ok := err.(temporary) return ok &amp;&amp; te.Temporary() } // net包的error type Error interface { error Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary? } // 错误处理 if nerr, ok := err.(net.Error); ok &amp;&amp; nerr.Temporary() { // 处理 return } if err != nil { } Handling Error 无错误的正常流程代码，将成为一条直线，而不是缩进的代码。
f,err := os.Open("file") if err != nil { // 处理错误 return } // 逻辑 f,err = os.Open("file2") if err != nil { // 处理错误 return } // 逻辑 通过消除错误消除错误处理
// 改进前 func AutoRusquest() (err error) { err = Anto() if err != nil { return } return } // 改进后 func AutoRusquest() (err error) { return Anto() } func main() { err := AutoRusquest() if err != nil { // log } } // 统计行数 func Countlines(r io.Reader) (int, error) { var ( br = bufio.NewReader(r) lines int err error ) for { _, err = br.ReadString('\n') lines++ if err != nil { break } } if err != io.EOF { return 0, err } return lines, nil } // 改进后 func Countlines(r io.Reader) (int, error) { sr := bufio.NewScanner(r) lines := 0 for sr.Scan() { lines ++ } return lines,sr.Err() } Wrap errors 传统error的问题 还记得之前我们 auth 的代码吧，如果 Auto 返回错误，则 Aut0Request 会将错误返回给调用方，调用者可能也会这样做，依此类推。在程序的顶部，程序的主体将把错误打印到屏幕或日志文件中，打印出来的只是：没有这样的文件或目录。
没有生成错误的 file:line 信息。没有导致错误的调用堆栈的堆栈跟踪。这段代码的作者将被迫进行长时间的代码分割，以发现是哪个代码路径触发了文件未找到错误。
func AutoRusquest() (err error) { err = Anto() if err != nil { err = fmt.Errorf("auto failed:%v",err) return } return } 但是正如我们前面看到的，这种模式与 sentinel errors 或 type assertions 的使用不兼容，因为将错误值转换为字符串，将其与另一个字符串合并，然后将其转换回 fmt.Errorf 破坏了原始错误，导致等值判定失败。
你应该只处理一次错误。处理错误意味着检查错误值，并做出单个决策。
func WriteAll(w io.Writer, buf []byte) { w.Write(buf) } 我们经常发现类似的代码，在错误处理中，带了两个任务: 记录日志并且再次返回错误。
func WriteAll(w io.Writer, buf []byte) error { _, err := w.Write(buf) if err != nil { log.Panicln("write buf failed:", err) return err } return nil } 在这个例子中，如果在 w.Write 过程中发生了一个错误，那么一行代码将被写入日志文件中，记录错误发生的文件和行，并且错误也会返回给调用者，调用者可能会记录并返回它，一直返回到程序的顶部。
func WriteConfig(w *io.Writer,config *Config) { buf, err := json.Marshal(conf) if err != nil { log.Printf("could not marshal config: %V", err) return err } if err := Writeall(w, buf); err != nil { log.Printf("could not write config: %v", err) return err } } func main() { err := Writeconfig(f, &amp;conf) fmt.Println(err) } /* unable to write: io.EOF could not write config: io.EOF */ Go 中的错误处理契约规定，在出现错误的情况下，不能对其他返回值的内容做出任何假设。由于 JSON 序列化失败，buf 的内容是未知的，可能它不包含任何内容，但更糟糕的是，它可能包含一个半写的 JSON 片段。
由于程序员在检查并记录错误后忘记 return，损坏的缓冲区将被传递给 WriteAll，这可能会成功，因此配置文件将被错误地写入。但是，该函数返回的结果是正确的。
栈处理错误 日志记录与错误无关且对调试没有帮助的信息应被视为噪音，应予以质疑。记录的原因是因为某些东西失败了，而日志包含了答案。
错误要被日志记录。
应用程序处理错误，保证100%完整性。
之后不再报告当前错误。
包:github.com/pkg/errors
func main() { _, err := Readconfig() if err != nil { fmt.Println(err) os.Exit(1) } } func Readfile(path string) ([]byte, error) { f, err := os.Open(path) if err != nil { return nil, errors.Wrap(err, "open failed") } defer f.Close() buf, err := ioutil.ReadAll(f) if err != nil { return nil, errors.Wrap(err, "read failed") } return buf, nil } func Readconfig() ([]byte, error) { home := os.Getenv("HOME") config, err := Readfile(filepath.Join(home, "settings.xml")) return config, errors.WithMessage(err, "could not read config") } /* could not read config: open failed: open /Users/zhaohaiyu/settings.xml: no such file or directory exit status 1 */ func main() { _, err := Readconfig() if err != nil { fmt.Printf("original error: %T -> %v\n", errors.Cause(err), errors.Cause(err)) fmt.Printf("stack trace: \n%+v\n", err) os.Exit(1) } } /* original error: *os.PathError -> open /Users/zhaohaiyu/settings.xml: no such file or directory stack trace: open /Users/zhaohaiyu/settings.xml: no such file or directory open failed main.Readfile /Users/zhaohaiyu/code/test/main.go:35 main.Readconfig /Users/zhaohaiyu/code/test/main.go:51 main.main /Users/zhaohaiyu/code/test/main.go:22 runtime.main /usr/local/Cellar/go/1.15.3/libexec/src/runtime/proc.go:204 runtime.goexit /usr/local/Cellar/go/1.15.3/libexec/src/runtime/asm_amd64.s:1374 could not read config exit status 1 */ 通过使用 pkg/errors 包，您可以向错误值添加上下文，这种方式既可以由人也可以由机器检查。
errors.Wrap(err, "read failed") wrap errors使用 在你的应用代码中，使用 errors.New 或者 errros.Errorf 返回错误。 func parseargs(args []string) error { if len(args) &lt; 3 { return errors.Errorf("not enough arguments, expected at Least") } // ... return nil } 如果调用其他的函数，通常简单的直接返回。 if err != nil { return err } 如果和其他库进行协作，考虑使用 errors.Wrap 或者 errors.Wrapf 保存堆栈信息。同样适用于和标准库协作的时候。 f, err := os.Open(file) if err != nil { return errors.Wrapf(err, "open %s failed",file) } 直接返回错误，而不是每个错误产生的地方到处打日志。
在程序的顶部或者是工作的 goroutine 顶部(请求入口)，使用 %+v 把堆栈详情记录。
func main() { err := app.Run() if err != nil { fmt.Printf("FATAL:%+v\n", err) os.Exit(1) } } 使用 errors.Cause 获取 root error，再进行和 sentinel error 判定。 总结: Packages that are reusable across many projects only return root error values.（选择 wrap error 是只有 applications 可以选择应用的策略。具有最高可重用性的包只能返回根错误值。此机制与 Go 标准库中使用的相同(kit 库的 sql.ErrNoRows)。）
If the error is not going to be handled, wrap and return up the call stack.（这是关于函数/方法调用返回的每个错误的基本问题。如果函数/方法不打算处理错误，那么用足够的上下文 wrap errors 并将其返回到调用堆栈中。例如，额外的上下文可以是使用的输入参数或失败的查询语句。确定您记录的上下文是足够多还是太多的一个好方法是检查日志并验证它们在开发期间是否为您工作。）
Once an error is handled, it is not allowed to be passed up the call stack any longer.（ 一旦确定函数/方法将处理错误，错误就不再是错误。如果函数/方法仍然需要发出返回，则它不能返回错误值。它应该只返回零(比如降级处理中，你返回了降级数据，然后需要 return nil)。）
Go1.13 error 函数在调用栈中添加信息向上传递错误，例如对错误发生时发生的情况的简要描述。
if err != nil { return fmt.Errorf("decompress %v:%v", name, err) } 使用创建新错误 fmt.Errorf 丢弃原始错误中除文本外的所有内容。正如我们在上面的QueryError 中看到的那样，我们有时可能需要定义一个包含底层错误的新错误类型，并将其保存以供代码检查。这里是 QueryError：
type QueryError struct { Query string Err error } 程序可以查看 QueryError \p值以根据底层错误做出决策。
if e, ok := err.(*Queryerror); ok &amp;&amp; e.Err == ErrPermission { //query failed because of a permission problem } go1.13为 errors 和 fmt 标准库包引入了新特性，以简化处理包含其他错误的错误。其中最重要的是: 包含另一个错误的 error 可以实现返回底层错误的 Unwrap 方法。如果 e1.Unwrap() 返回 e2，那么我们说 e1 包装 e2，您可以展开 e1 以获得 e2。
按照此约定，我们可以为上面的 QueryError 类型指定一个 Unwrap 方法，该方法返回其包含的错误:
func (e *Queryerror) Unwrap() error { return e.Err } go1.13 errors 包包含两个用于检查错误的新函数：Is 和 As。
// Similar to: // if err = Errnotfound {...} if errors.Is(err, Errnotfound) { // something wasnt found } // Similar to // if e, ok := err.(*Queryerror); ok {...} var e *Queryerror // Note: *Queryerror is the type of the error if errorsAs(err, &amp;e) { // err is a *Queryerror, and e is set to the errors value } Wrapping errors with %w 如前所述，使用 fmt.Errorf 向错误添加附加信息。
if err != nil { return fmt.Errorf("decompress %v:%v", name, err) } 在 Go 1.13中 fmt.Errorf 支持新的 %w 谓词。
if err != nil { return fmt.Errorf("decompress %v:%w", name, err) } 用 %w 包装错误可用于 errors.Is 以及 errors.As
err := fmt.Errorf("access denied: % W", Errpermission) if errors.Is(err, Errpermission) { // ... } Go2介绍 https://go.googlesource.com/proposal/+/master/design/29934-error-values.md 参考文章 https://u.geekbang.org/subject/go https://lailin.xyz/post/go-training-03.html</content></entry><entry><title>项目目录结构</title><url>https://www.zhaohaiyu.com/post/go/project-directory/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>DDD</tag></tags><content type="html"> 什么是DDD？ DDD 是 Domain-Driven Design 的缩写。 其主要的思想是，我们在设计软件时，先从业务出发，理解真实的业务含义，将业务中的一些概念吸收到软件建模中来，避免造出“大而无用”软件。也避免软件设计没有内在联系，否则一团散沙，无法继续演进。
为什么要使用DDD？ 过去，最常用的架构是三层架构，最典型的是MVC。三层架构的问题就是控制层依赖业务层，业务层又依赖数据层。特别是在数据层为贫血模型下，会让业务层的代码高速膨胀。在维护过程中，改了一点需求就会引发意想不到的bug，修复bug又会引起其他的bug。
贫血模型和充血模型 贫血模型
所谓贫血模型，是指Model 中，仅包含状态(属性），不包含行为(方法），采用这种设计时，需要分离出DB层，专门用于数据库操作。
充血模型
Model 中既包括状态，又包括行为，是最符合面向对象的设计方式。
业务层设计 我们在写业务代码的时候，最终要的往往在业务层，控制层就是最一些参数校验处理，数据层就是持久化数据。业务逻辑集中在业务层，在三层就够中业务层往往依赖数据层，吧orm的model对象拿到业务层使用，这是出bug概率最大的问题。那我们能不能做出设计，在业务层，既不依赖控制层也不依赖数据层呢？
我们使用反向依赖的方式，让数据层依赖业务层。
比如我们要查询一些用户的订单信息
type User struct { Id int Name string Password string Age uint8 } type Order struct { Id int Good string PayTime time.Time } type UserRepo interface { GetUsers(ctx context.Context,name string) ([]*User,error) } type OrderRepo interface { GetOrders(ctx context.Context,userId int) ([]*Order,error) } type UserUseCase struct { ur UserRepo or OrderRepo } func NewUserUseCase(ur UserRepo,or OrderRepo) *UserUseCase { return &amp;UserUseCase{ ur:ur, or:or, } } func (uuc *UserUseCase) GetOrders(ctx context.Context,name string) ([]*Order,error) { users,err := uuc.ur.GetUsers(ctx,name) if err != nil || len(users) == 0 { return fmt.Errorf("xxx%w",err) } userId := users[0].Id return uuc.or.GetOrders(ctx,userId) } 在上面的例子中，在GetOrders方法中调用接口Repos中的方法，把业务代码写完之后，进行单元测试我们只要mock实现各个repo的接口就好。然后再持久层（数据层）实现这些repo方法，在方法中把PO转成DO。在控制层使用NewUserUseCase创建UseCase。进行调用吧DO转化成DTO返回。
当然在业务复杂时，usecase的方法要简单，吧逻辑都封装到domain service中。
DTO DO和PO DTO: Data Transfer Object的缩写。用于表示一个数据传输对象。DTO 通常用于不同服务或服务不同分层之间的数据传输。
BO: Business Object 的缩写,用于表示一个业务对象。
PO: Persistant Object缩写。用于数据库中一条记录映射成struct。
项目例子 项目例子可以查看 beer-shop 项目，它是基于微服务框架kratos 实现的微服务项目。</content></entry><entry><title>kratos v2版本命令行工具使用</title><url>https://www.zhaohaiyu.com/post/microservice/kratos-v2-tool/</url><categories><category>microservice</category><category>go</category></categories><tags><tag>微服务</tag><tag>kratos</tag></tags><content type="html"> kratos命令行工具是什么？ kratos tool 是微服务框架 kratos 的命令行工具，提供创建模板，编译protobuf 文件，运行项目等功能。
使用 下载 go install github.com/go-kratos/kratos/cmd/kratos/v2@latest 查看是否安装成功
kratos -v kratos version v2.1.3 升级 kratos upgrade 查看帮助 kratos --help Kratos: An elegant toolkit for Go microservices. Usage: kratos [command] Available Commands: changelog Get a kratos change log completion generate the autocompletion script for the specified shell help Help about any command new Create a service template proto Generate the proto files run Run project upgrade Upgrade the kratos tools Flags: -h, --help help for kratos -v, --version version for kratos Use "kratos [command] --help" for more information about a command. new命令 kratos new 命令为创建一个kratos项目
参数：
-r repo地址 默认为https://github.com/go-kratos/kratos-layout
-b git版本 默认为main分支
-t 超时时间 默认为60s
也可添加环境变量KRATOS_LAYOUT_REPO 知道远程repo
创建一个项目
kratos new helloworld 因为默认远程仓库地址是 github上的，在国内很容易创建失败，所以要需要设置终端或者git代理（什么是终端代理和git代理可以百度或者google一下）。
当然你也可以使用-r 知道国内仓库 我们提供一个国内镜像https://gitee.com/go-kratos/kratos-layout。
如果嫌弃每次都要-r指定麻烦，也可以把KRATOS_LAYOUT_REPO=https://gitee.com/go-kratos/kratos-layout 加入到path中。
kratos new helloworld -r https://gitee.com/go-kratos/kratos-layout proto命令 proto命令下有 add client 和 server子命令
add kratos proto add 为创建一个proto模板
kratos proto add api/helloworld/v2/hello.proto 在目录api/helloworld/v2 下可以看到生成的文件
syntax = "proto3"; package api.helloworld.v2; option go_package = "helloworld/api/helloworld/v2;v2"; option java_multiple_files = true; option java_package = "api.helloworld.v2"; service Hello { rpc CreateHello (CreateHelloRequest) returns (CreateHelloReply); rpc UpdateHello (UpdateHelloRequest) returns (UpdateHelloReply); rpc DeleteHello (DeleteHelloRequest) returns (DeleteHelloReply); rpc GetHello (GetHelloRequest) returns (GetHelloReply); rpc ListHello (ListHelloRequest) returns (ListHelloReply); } message CreateHelloRequest {} message CreateHelloReply {} message UpdateHelloRequest {} message UpdateHelloReply {} message DeleteHelloRequest {} message DeleteHelloReply {} message GetHelloRequest {} message GetHelloReply {} message ListHelloRequest {} message ListHelloReply {} client kratos proto client 为生成 Proto 代码
使用这个命令需要下载 protobuf 工具 protoc，可以在官网下载对应版本 Protobuf release版本 kratos proto client api/helloworld/v2/ 这条命令就可以编译api/helloworld/v2/下的所有.proto文件
如果我们需要 import 其他proto文件 可以在命令后面加上protoc的参数
比如
kratos proto client api/helloworld/v2/ --proto_path=api/helloworld/v2 默认也会把 ./third_party 下import 进来 需要第三方的proto文件 可以放在这里
server kratos proto server为指定proto文件生成简单的service代码
参数：
-t 生成代码的位置 默认是internal/service 比如
kratos proto server api/helloworld/v2/hello.proto -t=internal/service/hello 生成的代码
package service import ( "context" pb "helloworld/api/helloworld/v2" ) type HelloService struct { pb.UnimplementedHelloServer } func NewHelloService() *HelloService { return &amp;HelloService{} } func (s *HelloService) ListHello(ctx context.Context, req *pb.ListHelloRequest) (*pb.ListHelloReply, error) { return &amp;pb.ListHelloReply{}, nil } run命令 启动服务
kratos run</content></entry><entry><title>Go泛型入门</title><url>https://www.zhaohaiyu.com/post/go/go-generics/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>泛型</tag></tags><content type="html"> 备注：这是一个 beta 版本的内容
这个教程介绍了 Go 泛型的基础概念。 通过泛型，你可以声明并使用函数或者是类型，那些用于调用代码时参数需要兼容多个不同类型的情况。
在这个教程里，你会声明两个普通的函数，然后复制一份相同的逻辑到一个泛型的方法里。
你会通过以下几个章节来进行学习：
为你的代码创建一个文件夹； 添加非泛型函数； 添加一个泛型函数来处理多种类型； 在调用泛型函数时删除类型参数； 声明一个类型约束。 备注：对其他教程，可以查看教程 备注：你同时也可以使用 &ldquo;Go dev branch"模式 来编辑和运行你的代码，如果你更喜欢以这种形式的话
前提条件 安装 Go 1.18 Beta 1 或者更新的版本。对安装流程，请看安装并使用 beta 版本。 代码编辑器。任何你顺手的代码编辑器。 一个命令终端。Go 在任何终端工具上都很好使用，比如 Linux 、Mac、PowerShell 或者 Windows 上的 cmd。 安装并使用 beta 版本 这个教程需要 Beta 1 的泛型特性。安装 beta 版本，需要通过下面几个步骤：
1、 执行下面的指令安装 beta 版本
$ go install golang.org/dl/go1.18beta1@latest 2、 执行下面的指令下载更新
$ go1.18beta1 download 3、用 beta 版本执行 go 命令，而不是 Go 的发布版本 (如果你本地有安装的话)
你可以使用 beta 版本名称或者把 beta 重命名成别的名称来执行命令。
使用 beta 版本名称，你可以通过 go1.18beta1 来执行指令而不是 go：
$ go1.18beta1 version 通过对 beta 版本名称重命名，你可以简化指令：
$ alias go=go1.18beta1 $ go version 在这个教程中将假设你已经对 beta 版本名称进行了重命名。
为你的代码创建一个文件夹 在一开始，先给你要写的代码创建一个文件夹
1、 打开一个命令提示符并切换到/home 文件夹
在 Linux 或者 Mac 上：
$ cd 在 windows 上：
C:\> cd %HOMEPATH% 在接下去的教程里面会用$来代表提示符。指令在 windows 上也适用。
2、 在命令提示符下，为你的代码创建一个名为 generics 的目录
$ mkdir generics $ cd generics 3、 创建一个 module 来存放你的代码
执行go mod init指令，参数为你新代码的 module 路径
$ go mod init example/generics go: creating new go.mod: module example/generics 备注：对生产环境，你会指定一个更符合你自己需求的 module 路径。更多的请看依赖管理 接下来，你会增加一些简单的和 maps 相关的代码。
添加普通函数 在这一步中，你将添加两个函数，每个函数都会累加 map 中的值 ，并返回总和。
你将声明两个函数而不是一个，因为你要处理两种不同类型的 map：一个存储 int64 类型的值，另一个存储 float64 类型的值。
写代码 1、 用你的文本编辑器，在 generics 文件夹里面创建一个叫 main.go 的文件。你将会在这个文件内写你的 Go 代码。
2、 到 main.go 文件的上方，粘贴如下的包的声明。
package main 一个独立的程序（相对于一个库）总是在 main 包中。
3、 在包的声明下面，粘贴以下两个函数的声明。
// SumInts adds together the values of m. func SumInts(m map[string]int64) int64 { var s int64 for _, v := range m { s += v } return s } // SumFloats adds together the values of m. func SumFloats(m map[string]float64) float64 { var s float64 for _, v := range m { s += v } return s } 在这段代码中，你：
声明两个函数，将一个 map 的值加在一起，并返回总和。 SumFloats 接收一个 map，key 为 string 类型，value 为 floa64 类型。 SumInt 接收一个 map，key 为 string 类型，value 为 int64 类型。 4、 在 main.go 的顶部，包声明的下面，粘贴以下 main 函数，用来初始化两个 map，并在调用你在上一步中声明的函数时将它们作为参数。
func main() { // Initialize a map for the integer values ints := map[string]int64{ "first": 34, "second": 12, } // Initialize a map for the float values floats := map[string]float64{ "first": 35.98, "second": 26.99, } fmt.Printf("Non-Generic Sums: %v and %v\n", SumInts(ints), SumFloats(floats)) } 在这段代码中，你：
初始化一个 key 为 string，value 为float64的 map 和一个 key 为 string，value 为int64的 map，各有 2 条数据； 调用之前声明的两个方法来获取每个 map 的值的总和； 打印结果。 5、 靠近 main.go 顶部，仅在包声明的下方，导入你刚刚写的代码所需要引用的包。
第一行代码应该看起来如下所示：
package main import "fmt" 6、 保存 main.go.
运行代码 在 main.go 所在目录下，通过命令行运行代码
$ go run . Non-Generic Sums: 46 and 62.97 有了泛型，你可以只写一个函数而不是两个。接下来，你将为 maps 添加一个泛型函数，来允许接收整数类型或者是浮点数类型。
添加泛型函数处理多种类型 在这一节，你将会添加一个泛型函数来接收一个 map，可能值是整数类型或者浮点数类型的 map，有效地用一个函数替换掉你刚才写的 2 个函数。
为了支持不同类型的值，这个函数需要有一个方法来声明它所支持的类型。另一方面，调用代码将需要一种方法来指定它是用整数还是浮点数来调用。
为了实现上面的描述，你将会声明一个除了有普通函数参数，还有类型参数的函数。这个类型参数实现了函数的通用性，使得它可以处理多个不同的类型。你将会用类型参数和普通函数参数来调用这个泛型函数。
每个类型参数都有一个类型约束，类似于每个类型参数的 meta-type。每个类型约束都指定了调用代码时每个对应输入参数的可允许的类型。
虽然类型参数的约束通常代表某些类型，但是在编译的时候类型参数只代表一个类型 - 在调用代码时作为类型参数。如果类型参数的类型不被类型参数的约束所允许，代码则无法编译。
需要记住的是类型参数必须满足泛型代码对它的所有的操作。举个例子，如果你的代码尝试去做一些 string 的操作 (比如索引)，而这个类型参数包含数字的类型，那代码是无法编译的。
在下面你要编写的代码里，你会使用允许整数或者浮点数类型的限制。
写代码 1、 在你之前写的两个函数的下方，粘贴下面的泛型函数
// SumIntsOrFloats sums the values of map m. It supports both int64 and float64 // as types for map values. func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V { var s V for _, v := range m { s += v } return s } 在这段代码里，你：
声明了一个带有 2 个类型参数 (方括号内) 的 SumIntsOrFloats 函数，K 和 V，一个使用类型参数的参数，类型为 map[K] V 的参数 m。 为 K 类型参数指定可比较的类型约束。事实上，针对此类情况，在 Go 里面可比较的限制是会提前声明。它允许任何类型的值可以作为比较运算符==和!=的操作符。在 Go 里面，map 的 key 是需要可比较的。因此，将 K 声明为可比较的是很有必要的，这样你就可以使用 K 作为 map 变量的 key。这样也保证了调用代码方使用一个被允许的类型做 map 的 key。 为 V 类型参数指定一个两个类型合集的类型约束：int64 和 float64。使用|指定了 2 个类型的合集，表示约束允许这两种类型。任何一个类型都会被编译器认定为合法的传参参数。 指定参数 m 为类型 map[K] V，其中 K 和 V 的类型已经指定为类型参数。注意到因为 K 是可比较的类型，所以 map[K] V 是一个有效的 map 类型。如果我们没有声明 K 是可比较的，那么编译器会拒绝对 map[K] V 的引用。 2、 在 main.go 里，在你现在的代码下方，粘贴如下代码：
fmt.Printf("Generic Sums: %v and %v\n", SumIntsOrFloats[string, int64](ints), SumIntsOrFloats[string, float64](floats)) 在这段代码里，你：
调用你刚才声明的泛型函数，传递你创建的每个 map。
指定类型参数 - 在方括号内的类型名称 - 来明确你所调用的函数中应该用哪些类型来替代类型参数。
你将会在下一节看到，你通常可以在函数调用时省略类型参数。Go 通常可以从代码里推断出来。
打印函数返回的总和。
运行代码 在 main.go 所在目录下，通过命令行运行代码
$ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 为了运行你的代码，在每次调用的时候，编译器都会用该调用中指定的具体类型替换类型参数。
在调用你写的泛型函数时，你指定了类型参数来告诉编译器用什么类型来替换函数的类型参数。正如你将在下一节所看到的，在许多情况下，你可以省略这些类型参数，因为编译器可以推断出它们。
当调用泛型函数时移除类型参数 在这一节，你会添加一个泛型函数调用的修改版本，通过一个小的改变来简化代码。在这个例子里你将移除掉不需要的类型参数。
当 Go 编译器可以推断出你要使用的类型时，你可以在调用代码中省略类型参数。编译器从函数参数的类型中推断出类型参数。
注意这不是每次都可行的。举个例子，如果你需要调用一个没有参数的泛型函数，那么你需要在调用函数时带上类型参数。
写代码 在 main.go 的代码下方，粘贴下面的代码。 fmt.Printf("Generic Sums, type parameters inferred: %v and %v\n", SumIntsOrFloats(ints), SumIntsOrFloats(floats)) 在这段代码里，你：
调用泛型函数，省略类型参数。 运行代码 在 main.go 所在目录下，通过命令行运行代码
$ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 Generic Sums, type parameters inferred: 46 and 62.97 接下来，你将通过把整数和浮点数的合集定义到一个你可以重复使用的类型约束中，比如从其他的代码，来进一步简化这个函数。
声明类型约束 在最后一节中，你将把你先前定义的约束移到它自己的 interface 中，这样你就可以在多个地方重复使用它。以这种方式声明约束有助于简化代码，尤其当一个约束越来越复杂的时候。
你将类型参数定义为一个 interface。约束允许任何类型实现这个 interface。举个例子，如果你定义了一个有三个方法的类型参数 interface，然后用它作为一个泛型函数的类型参数，那么调用这个函数的类型参数必须实现这些方法。
你将在本节中看到，约束 interface 也可以指代特定的类型。
写代码 1、 在 main 函数上面，紧接着 import 下方，粘贴如下代码来定义类型约束。
type Number interface { int64 | float64 } 在这段代码里，你：
声明一个 Number interface 类型作为类型限制
在 interface 内声明 int64 和 float64 的合集
本质上，你是在把函数声明中的合集移到一个新的类型约束中。这样子，当你想要约束一个类型参数为 int64 或者 float64，你可以使用 Number interface 而不是写 int64 | float64。
2、 在你已写好的函数下方，粘贴如下泛型函数，SumNumbers。
// SumNumbers sums the values of map m. Its supports both integers // and floats as map values. func SumNumbers[K comparable, V Number](m map[K]V) V { var s V for _, v := range m { s += v } return s } 在这段代码，你：
声明一个泛型函数，其逻辑与你之前声明的泛型函数相同，但是是使用新的 interface 类型作为类型参数而不是合集。和之前一样，你使用类型参数作为参数和返回类型。 3、 在 main.go，在你已写完的代码下方，粘贴如下代码。
fmt.Printf("Generic Sums with Constraint: %v and %v\n", SumNumbers(ints), SumNumbers(floats)) 在这段代码里，你：
每个 map 依次调用 SumNumbers，并打印数值的总和。 与上一节一样，你可以在调用泛型函数时省略类型参数（方括号中的类型名称）。Go 编译器可以从其他参数中推断出类型参数。 运行代码 在 main.go 所在目录下，通过命令行运行代码
$ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 Generic Sums, type parameters inferred: 46 and 62.97 Generic Sums with Constraint: 46 and 62.97 总结 完美结束！你刚才已经给你自己介绍了 Go 的泛型。
如果你想继续试验，你可以尝试用整数约束和浮点数约束来写 Number interface，来允许更多的数字类型。
建议阅读的相关文章：
Go Tour 是一个很好的，手把手教 Go 基础的介绍。 你可以在 Effective Go 和 How to write Go code 中找到非常实用的 GO 的练习。 完整代码 你可以在 Go playground 运行这个代码。在 playground 只需要点击Run按钮即可。
package main import "fmt" type Number interface { int64 | float64 } func main() { // Initialize a map for the integer values ints := map[string]int64{ "first": 34, "second": 12, } // Initialize a map for the float values floats := map[string]float64{ "first": 35.98, "second": 26.99, } fmt.Printf("Non-Generic Sums: %v and %v\n", SumInts(ints), SumFloats(floats)) fmt.Printf("Generic Sums: %v and %v\n", SumIntsOrFloats[string, int64](ints), SumIntsOrFloats[string, float64](floats)) fmt.Printf("Generic Sums, type parameters inferred: %v and %v\n", SumIntsOrFloats(ints), SumIntsOrFloats(floats)) fmt.Printf("Generic Sums with Constraint: %v and %v\n", SumNumbers(ints), SumNumbers(floats)) } // SumInts adds together the values of m. func SumInts(m map[string]int64) int64 { var s int64 for _, v := range m { s += v } return s } // SumFloats adds together the values of m. func SumFloats(m map[string]float64) float64 { var s float64 for _, v := range m { s += v } return s } // SumIntsOrFloats sums the values of map m. It supports both floats and integers // as map values. func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V { var s V for _, v := range m { s += v } return s } // SumNumbers sums the values of map m. Its supports both integers // and floats as map values. func SumNumbers[K comparable, V Number](m map[K]V) V { var s V for _, v := range m { s += v } return s } 原文地址 Tutorial: Getting started with generics - The Go Programming Language Go 官方出品泛型教程：如何开始使用泛型 · GoCN社区</content></entry><entry><title>vscode常用快捷键及插件</title><url>https://www.zhaohaiyu.com/post/editor/vscode/</url><categories><category>editor</category></categories><tags/><content type="html"> macOS 全局 Command + Shift + P / F1 显示命令面板 Command + P 快速打开 Command + Shift + N 打开新窗口 Command + W 关闭窗口 基本 Command + X 剪切（未选中文本的情况下，剪切光标所在行） Command + C 复制（未选中文本的情况下，复制光标所在行） Option + Up 向上移动行 Option + Down 向下移动行 Option + Shift + Up 向上复制行 Option + Shift + Down 向下复制行 Command + Shift + K 删除行 Command + Enter 下一行插入 Command + Shift + Enter 上一行插入 Command + Shift + \ 跳转到匹配的括号 Command + [ 减少缩进 Command + ] 增加缩进 Home 跳转至行首 End 跳转到行尾 Command + Up 跳转至文件开头 Command + Down 跳转至文件结尾 Ctrl + PgUp 按行向上滚动 Ctrl + PgDown 按行向下滚动 Command + PgDown 按屏向下滚动 Command + PgUp 按屏向上滚动 Command + Shift + [ 折叠代码块 Command + Shift + ] 展开代码块 Command + K Command + [ 折叠全部子代码块 Command + K Command + ] 展开全部子代码块 Command + K Command + 0 折叠全部代码块 Command + K Command + J 展开全部代码块 Command + K Command + C 添加行注释 Command + K Command + U 移除行注释 Command + / 添加、移除行注释 Option + Shift + A 添加、移除块注释 Option + Z 自动换行、取消自动换行 多光标与选择 Option + 点击 插入多个光标 Command + Option + Up 向上插入光标 Command + Option + Down 向下插入光标 Command + U 撤销上一个光标操作 Option + Shift + I 在所选行的行尾插入光标 Command + I 选中当前行 Command + Shift + L 选中所有与当前选中内容相同部分 Command + F2 选中所有与当前选中单词相同的单词 Command + Ctrl + Shift + Left 折叠选中 Command + Ctrl + Shift + Right 展开选中 Alt + Shift + 拖动鼠标 选中代码块 Command + Shift + Option + Up 列选择 向上 Command + Shift + Option + Down 列选择 向下 Command + Shift + Option + Left 列选择 向左 Command + Shift + Option + Right 列选择 向右 Command + Shift + Option + PgUp 列选择 向上翻页 Command + Shift + Option + PgDown 列选择 向下翻页 查找替换 Command + F 查找 Command + Option + F 替换 Command + G 查找下一个 Command + Shift + G 查找上一个 Option + Enter 选中所有匹配项 Command + D 向下选中相同内容 Command + K Command + D 移除前一个向下选中相同内容 进阶 Ctrl + Space 打开建议 Command + Shift + Space 参数提示 Tab Emmet插件缩写补全 Option + Shift + F 格式化 Command + K Command + F 格式化选中内容 F12 跳转到声明位置 Option + F12 查看具体声明内容 Command + K F12 分屏查看具体声明内容 Command + . 快速修复 Shift + F12 显示引用 F2 重命名符号 Command + Shift + . 替换为上一个值 Command + Shift + , 替换为下一个值 Command + K Command + X 删除行尾多余空格 Command + K M 更改文件语言 导航 Command + T 显示所有符号 Ctrl + G 跳转至某行 Command + P 跳转到某个文件 Command + Shift + O 跳转到某个符号 Command + Shift + M 打开问题面板 F8下一个错误或警告位置 Shift + F8 上一个错误或警告位置 Ctrl + Shift + Tab 编辑器历史记录 Ctrl + -后退 Ctrl + Shift + - 前进 Ctrl + Shift + M Tab 切换焦点 编辑器管理 Command + W 关闭编辑器 Command + K F 关闭文件夹 Command + \ 编辑器分屏 Command + 1 切换到第一分组 Command + 2 切换到第二分组 Command + 3 切换到第三分组 Command + K Command + Left 切换到上一分组 Command + K Command + Right 切换到下一分组 Command + K Command + Shift + Left 左移编辑器 Command + K Command + Shift + Right 右移编辑器 Command + K Left 激活左侧编辑组 Command + K Right 激活右侧编辑组 文件管理 Command + N 新建文件 Command + O 打开文件 Command + S 保存文件 Command + Shift + S 另存为 Command + Option + S 全部保存 Command + W 关闭 Command + K Command + W 全部关闭 Command + Shift + T 重新打开被关闭的编辑器 Command + K Enter 保持打开 Ctrl + Tab 打开下一个 Ctrl + Shift + Tab 打开上一个 Command + K P 复制当前文件路径 Command + K R 在资源管理器中查看当前文件 Command + K O 新窗口打开当前文件 显示 Command + Ctrl + F 全屏、退出全屏 Command + Option + 1 切换编辑器分屏方式（横、竖） Command + + 放大 Command + - 缩小 Command + B 显示、隐藏侧边栏 Command + Shift + E 显示资源管理器 或 切换焦点 Command + Shift + F 显示搜索框 Ctrl + Shift + G 显示Git面板 Command + Shift + D 显示调试面板 Command + Shift + X 显示插件面板 Command + Shift + H 全局搜索替换 Command + Shift + J 显示、隐藏高级搜索 Command + Shift + C 打开新终端 Command + Shift + U 显示输出面板 Command + Shift + V Markdown预览窗口 Command + K V 分屏显示 Markdown预览窗口 调试 F9 设置 或 取消断点 F5 开始 或 继续 F11 进入 Shift + F11 跳出 F10 跳过 Command + K Command + I 显示悬停信息 集成终端 Ctrl +显示终端 Ctrl + Shift +新建终端 Command + Up 向上滚动 Command + Down 向下滚动 PgUp 向上翻页 PgDown 向下翻页 Command + Home 滚动到顶部 Command + End 滚动到底部 windows &amp; linux 注释:
单行注释:[ctrl+k,ctrl+c] 或 ctrl+/
取消单行注释:[ctrl+k,ctrl+u] (按下ctrl不放，再按k + u)
多行注释:[alt+shift+A]
多行注释:/**
移动行:alt+up/down
显示/隐藏左侧目录栏 ctrl + b
复制当前行:shift + alt +up/down
删除当前行:shift + ctrl + k
控制台终端显示与隐藏:ctrl + ~
查找文件/安装vs code 插件地址:ctrl + p
代码格式化:shift + alt +f
新建一个窗口: ctrl + shift + n
行增加缩进: ctrl + [
行减少缩进: ctrl + ]
裁剪尾随空格(去掉一行的末尾那些没用的空格) : ctrl + shift + x
字体放大/缩小: ctrl + ( + 或 - )
拆分编辑器 :ctrl + 1/2/3
切换窗口: ctrl + shift + left/right
关闭编辑器窗口: ctrl + w
关闭所有窗口 : ctrl + k + w
切换全屏 :F11
自动换行: alt + z
显示git: ctrl + shift + g
全局查找文件:ctrl + p
显示相关插件的命令(如:git log):ctrl + shift + p
选中文字:shift + left / right / up / down
折叠代码: ctrl + k + 0-9 (0是完全折叠)
展开代码: ctrl + k + j (完全展开代码)
删除行 : ctrl + shift + k
快速切换主题:ctrl + k / ctrl + t
快速回到顶部 : ctrl + home
快速回到底部 : ctrl + end
格式化选定代码 :ctrl + k / ctrl +f
选中代码 : shift + 鼠标左键
多行同时添加内容（光标）:ctrl + alt + up/down
全局替换:ctrl + shift + h
当前文件替换:ctrl + h
打开最近打开的文件:ctrl + r
打开新的命令窗:ctrl + shift + c
vscode常用插件 Bracket Pair Colorize 2 彩虹括号 Material Icon Theme 文件样式 open in browser 游览器打开html Remote Development 远程开发 protobuf proto buffer协议文件编写 Gitlens git加强版 go go语言 Python Python语言 Vetur vue框架 todo-tree todo</content></entry><entry><title>Nethttp Gin</title><url>https://www.zhaohaiyu.com/post/go/nethttp-gin/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>http</tag></tags><content type="html"> net/http 路由注册 func test1() { http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, "Hello world!") }) err := http.ListenAndServe(":9001", nil) if err != nil { log.Fatal("ListenAndServer:", err) } } 在使用ListenAndServe这个方法时，系统就会给我们指派一个路由器，DefaultServeMux是系统默认使用的路由器，如果ListenAndServe这个方法的第2个参数传入nil，系统就会默认使用DefaultServeMux。当然，这里也可以传入自定义的路由器。
先看http.HandleFunc("/", ...)，从HandleFunc方法点进去，如下：
func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 在这里调用了DefaultServeMux的HandleFunc方法，这个方法有两个参数，pattern是匹配的路由规则，handler表示这个路由规则对应的处理方法，并且这个处理方法有两个参数。
在我们书写的代码示例中，pattern对应/，handler对应sayHello，当我们在浏览器中输入http://localhost:9001时，就会触发匿名函数。
我们再顺着DefaultServeMux的HandleFunc方法继续点下去，如下：
func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic("http: nil handler") } mux.Handle(pattern, HandlerFunc(handler)) } 在这个方法中，路由器又调用了Handle方法，注意这个Handle方法的第2个参数，将之前传入的handler这个响应方法强制转换成了HandlerFunc类型。
这个HandlerFunc类型到底是个什么呢？如下：
type HandlerFunc func(ResponseWriter, *Request) 看来和我们定义的"/&ldquo;的匿名函数的类型都差不多。但是！！！ 这个HandlerFunc默认实现了ServeHTTP接口！这样HandlerFunc对象就有了ServeHTTP方法！如下：
// ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 接下来，我们返回去继续看mux的Handle方法，也就是这段代码mux.Handle(pattern, HandlerFunc(handler))。这段代码做了哪些事呢？源码如下
// Handle registers the handler for the given pattern. // If a handler already exists for pattern, Handle panics. func (mux *ServeMux) Handle(pattern string, handler Handler) { mux.mu.Lock() defer mux.mu.Unlock() if pattern == "" { panic("http: invalid pattern") } if handler == nil { panic("http: nil handler") } if _, exist := mux.m[pattern]; exist { panic("http: multiple registrations for " + pattern) } if mux.m == nil { mux.m = make(map[string]muxEntry) } e := muxEntry{h: handler, pattern: pattern} mux.m[pattern] = e if pattern[len(pattern)-1] == '/' { mux.es = appendSorted(mux.es, e) } if pattern[0] != '/' { mux.hosts = true } } 主要就做了一件事，向DefaultServeMux的map[string]muxEntry中增加对应的路由规则和handler。
map[string]muxEntry是个什么鬼？
map是一个字典对象，它保存的是key-value。
[string]表示这个字典的key是string类型的，这个key值会保存我们的路由规则。
muxEntry是一个实例对象，这个对象内保存了路由规则对应的处理方法。
mux.es 为模糊匹配 有长倒短排序 比如有路由/hello/ 访问/hello/world 时没有路由 会落到/hello/上
找到相应代码，如下：
// 路由器 type ServeMux struct { mu sync.RWMutex m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. hosts bool // whether any patterns contain hostnames } type muxEntry struct { h Handler pattern string } // 路由响应方法 type Handler interface { ServeHTTP(ResponseWriter, *Request) } net/http 运行 第二部分主要就是研究这句代码err := http.ListenAndServe(":9001",nil)，也就是ListenAndServe这个方法。从这个方法点进去，如下：
func ListenAndServe(addr string, handler Handler) error { server := &amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 在这个方法中，初始化了一个server对象，然后调用这个server对象的ListenAndServe方法，在这个方法中，如下：
func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == "" { addr = ":http" } ln, err := net.Listen("tcp", addr) if err != nil { return err } return srv.Serve(ln) } 在这个方法中，调用了net.Listen("tcp", addr)，也就是底层用TCP协议搭建了一个服务，然后监控我们设置的端口。
代码的最后，调用了srv的Serve方法，如下：
func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } origListener := l l = &amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(&amp;l, true) { return ErrServerClosed } defer srv.trackListener(&amp;l, false) baseCtx := context.Background() if srv.BaseContext != nil { baseCtx = srv.BaseContext(origListener) if baseCtx == nil { panic("BaseContext returned a nil context") } } var tempDelay time.Duration // how long to sleep on accept failure ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { rw, err := l.Accept() if err != nil { select { case &lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := err.(net.Error); ok &amp;&amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay > max { tempDelay = max } srv.logf("http: Accept error: %v; retrying in %v", err, tempDelay) time.Sleep(tempDelay) continue } return err } connCtx := ctx if cc := srv.ConnContext; cc != nil { connCtx = cc(connCtx, rw) if connCtx == nil { panic("ConnContext returned nil") } } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew, runHooks) // before Serve can return go c.serve(connCtx) } } 最后3段代码比较重要，也是Go语言支持高并发的体现，如下：
c := srv.newConn(rw) c.setState(c.rwc, StateNew, runHooks) // before Serve can return go c.serve(connCtx) 上面那一大坨代码，总体意思是进入方法后，首先开了一个for循环，在for循环内时刻Accept请求，请求来了之后，会为每个请求创建一个Conn，然后单独开启一个goroutine，把这个请求的数据当做参数扔给这个Conn去服务：go c.serve()。用户的每一次请求都是在一个新的goroutine去服务，每个请求间相互不影响。
在conn的serve方法中，有一句代码很重要，如下：
serverHandler{c.server}.ServeHTTP(w, w.req) 表示serverHandler也实现了ServeHTTP接口，ServeHTTP方法实现如下：
func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == "*" &amp;&amp; req.Method == "OPTIONS" { handler = globalOptionsHandler{} } if req.URL != nil &amp;&amp; strings.Contains(req.URL.RawQuery, ";") { var allowQuerySemicolonsInUse int32 req = req.WithContext(context.WithValue(req.Context(), silenceSemWarnContextKey, func() { atomic.StoreInt32(&amp;allowQuerySemicolonsInUse, 1) })) defer func() { if atomic.LoadInt32(&amp;allowQuerySemicolonsInUse) == 0 { sh.srv.logf("http: URL query contains semicolon, which is no longer a supported separator; parts of the query may be stripped when parsed; see golang.org/issue/25192") } }() } handler.ServeHTTP(rw, req) } 在这里如果handler为空（这个handler就可以理解为是我们自定义的路由器），就会使用系统默认的DefaultServeMux，代码的最后调用了DefaultServeMux的ServeHTTP()
func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == "*" { if r.ProtoAtLeast(1, 1) { w.Header().Set("Connection", "close") } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) //这里返回的h是Handler接口对象 h.ServeHTTP(w, r) //调用Handler接口对象的ServeHTTP方法实际上就调用了我们定义的sayHello方法 } func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. if r.Method == "CONNECT" { // If r.URL.Path is /tree and its handler is not registered, // the /tree -> /tree/ redirect applies to CONNECT requests // but the path canonicalization does not. if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // All other requests have any port stripped and path cleaned // before passing to mux.handler. host := stripHostPort(r.Host) path := cleanPath(r.URL.Path) // If the given path is /tree and its handler is not registered, // redirect for /tree/. if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } if path != r.URL.Path { _, pattern = mux.handler(host, path) u := &amp;url.URL{Path: path, RawQuery: r.URL.RawQuery} return RedirectHandler(u.String(), StatusMovedPermanently), pattern } return mux.handler(host, r.URL.Path) } func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), "" } return } func (mux *ServeMux) match(path string) (h Handler, pattern string) { // Check for exact match first. v, ok := mux.m[path] if ok { return v.h, v.pattern } // Check for longest valid match. mux.es contains all patterns // that end in / sorted from longest to shortest. for _, e := range mux.es { if strings.HasPrefix(path, e.pattern) { return e.h, e.pattern } } return nil, "" } 它会根据用户请求的URL到路由器里面存储的map中匹配，匹配成功就会返回存储的handler，调用这个handler的ServeHTTP()就可以执行到相应的处理方法了，这个处理方法实际上就是我们刚开始定义的sayHello()，只不过这个sayHello()被HandlerFunc又包了一层，因为HandlerFunc实现了ServeHTTP接口，所以在调用HandlerFunc对象的ServeHTTP()时，实际上在ServeHTTP ()的内部调用了我们的sayHello()。
总结 调用http.ListenAndServe(":9090",nil) 实例化server 调用server的ListenAndServe() 调用server的Serve方法，开启for循环，在循环中Accept请求 对每一个请求实例化一个Conn，并且开启一个goroutine为这个请求进行服务go c.serve() 读取每个请求的内容c.readRequest() 调用serverHandler的ServeHTTP()，如果handler为空，就把handler设置为系统默认的路由器DefaultServeMux 调用handler的ServeHTTP() =>实际上是调用了DefaultServeMux的ServeHTTP() 在ServeHTTP()中会调用路由对应处理handler 在路由对应处理handler中会执行sayHello() 有一个需要注意的点： DefaultServeMux和路由对应的处理方法handler都实现了ServeHTTP接口，他们俩都有ServeHTTP方法，但是方法要达到的目的不同，在DefaultServeMux的ServeHttp()里会执行路由对应的处理handler的ServeHttp()。
自定义个简单的路由 package mux import ( "net/http" "strings" ) type muxEntry struct { h TesthandleFunc } type TesthandleFunc func(http.ResponseWriter, *http.Request) type TestHandler struct { routes map[string]map[string]muxEntry } func (h *TestHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { method := strings.ToUpper(r.Method) path := r.URL.Path if route, ok := h.routes[method]; ok { if entry, ok := route[path]; ok { entry.h(w, r) return } } w.WriteHeader(http.StatusNotFound) } func Newhandler() *TestHandler { return &amp;TestHandler{routes: make(map[string]map[string]muxEntry)} } func (h *TestHandler) Handle(method, path string, handler TesthandleFunc) { method = strings.ToUpper(method) if _, ok := h.routes[method]; !ok { h.routes[method] = make(map[string]muxEntry) } h.routes[method][path] = muxEntry{handler} } package main import ( "fmt" "net/http" "study/mux" ) func main() { handler := mux.Newhandler() handler.Handle("GET", "/hello", func(rw http.ResponseWriter, r *http.Request) { rw.Write([]byte("Hello World")) }) handler.Handle("Post", "/hello/world", func(rw http.ResponseWriter, r *http.Request) { fmt.Fprintln(rw, "你好") }) http.ListenAndServe(":9002", handler) } 自定义context
package router import ( "encoding/json" "net/http" "strings" ) type Context struct { w http.ResponseWriter r *http.Request } func (c *Context) Json(code int, v interface{}) { c.w.Header().Set("Content-Type", "application/json") c.w.WriteHeader(code) s, _ := json.Marshal(v) c.w.Write(s) } type Routerfunc func(c *Context) type RouterHandler struct { routes map[string]map[string]Routerfunc } func NewRouterHandler() *RouterHandler { return &amp;RouterHandler{routes: make(map[string]map[string]Routerfunc)} } func (h *RouterHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { method := strings.ToUpper(r.Method) path := r.URL.Path c := &amp;Context{w: w, r: r} if route, ok := h.routes[method]; ok { if h, ok := route[path]; ok { h(c) return } } w.WriteHeader(http.StatusNotFound) } func (h *RouterHandler) Handle(method, path string, handler Routerfunc) { method = strings.ToUpper(method) if _, ok := h.routes[method]; !ok { h.routes[method] = make(map[string]Routerfunc) } h.routes[method][path] = handler } func (r *RouterHandler) Run(addr string) error { return http.ListenAndServe(addr, r) } Gin type Engine struct { RouterGroup pool sync.Pool trees methodTrees }// trie type RouterGroup struct { basePath string engine *Engine } func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { c := engine.pool.Get().(*Context) // 从pool 拿出一个context c.writermem.reset(w) // 记录http.ResponseWriter 及 *http.Request c.Request = req c.reset() // 重置上一个留下的值 engine.handleHTTPRequest(c) engine.pool.Put(c) // 把用完的context放回池子 } // get: /bac 添加路由
func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { absolutePath := group.calculateAbsolutePath(relativePath) handlers = group.combineHandlers(handlers) group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj() } Context
type Context struct { Request *http.Request Writer ResponseWriter Params Params handlers HandlersChain index int8 fullPath string engine *Engine params *Params skippedNodes *[]skippedNode // This mutex protect Keys map mu sync.RWMutex // Keys is a key/value pair exclusively for the context of each request. Keys map[string]interface{} // Errors is a list of errors attached to all the handlers/middlewares who used this context. Errors errorMsgs // Accepted defines a list of manually accepted formats for content negotiation. Accepted []string // queryCache use url.ParseQuery cached the param query result from c.Request.URL.Query() queryCache url.Values // formCache use url.ParseQuery cached PostForm contains the parsed form data from POST, PATCH, // or PUT body parameters. formCache url.Values // SameSite allows a server to define a cookie attribute making it impossible for // the browser to send this cookie along with cross-site requests. sameSite http.SameSite } func (c *Context) Next() { c.index++ for c.index &lt; int8(len(c.handlers)) { c.handlers[c.index](c) c.index++ } } func (engine *Engine) handleHTTPRequest(c *Context) { httpMethod := c.Request.Method rPath := c.Request.URL.Path unescape := false if engine.UseRawPath &amp;&amp; len(c.Request.URL.RawPath) > 0 { rPath = c.Request.URL.RawPath unescape = engine.UnescapePathValues } if engine.RemoveExtraSlash { rPath = cleanPath(rPath) } // Find root of the tree for the given HTTP method t := engine.trees for i, tl := 0, len(t); i &lt; tl; i++ { if t[i].method != httpMethod { continue } root := t[i].root // Find route in tree value := root.getValue(rPath, c.params, c.skippedNodes, unescape) if value.params != nil { c.Params = *value.params } if value.handlers != nil { c.handlers = value.handlers c.fullPath = value.fullPath c.Next() c.writermem.WriteHeaderNow() return } if httpMethod != http.MethodConnect &amp;&amp; rPath != "/" { if value.tsr &amp;&amp; engine.RedirectTrailingSlash { redirectTrailingSlash(c) return } if engine.RedirectFixedPath &amp;&amp; redirectFixedPath(c, root, engine.RedirectFixedPath) { return } } break } if engine.HandleMethodNotAllowed { for _, tree := range engine.trees { if tree.method == httpMethod { continue } if value := tree.root.getValue(rPath, nil, c.skippedNodes, unescape); value.handlers != nil { c.handlers = engine.allNoMethod serveError(c, http.StatusMethodNotAllowed, default405Body) return } } } c.handlers = engine.allNoRoute serveError(c, http.StatusNotFound, default404Body) }</content></entry><entry><title>通过 layout 探索 kratos 运行原理</title><url>https://www.zhaohaiyu.com/post/microservice/kratos-layout/</url><categories><category>microservice</category><category>go</category></categories><tags/><content type="html"> 创建项目 首先需要安装好对应的依赖环境，以及工具：
go 下载 protoc go install google.golang.org/protobuf/cmd/protoc-gen-go@latest protoc-gen-go go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest # 创建项目模板 kratos new helloworld cd helloworld # 拉取项目依赖 go mod download # 生成proto模板 kratos proto add api/helloworld/helloworld.proto # 生成proto源码 kratos proto client api/helloworld/helloworld.proto # 生成server模板 kratos proto server api/helloworld/helloworld.proto -t internal/service 执行命令后,会在当前目录下生成一个 service 工程,工程骨架如下,具体的工程骨架说明可以访问 layout 运行项目 # 生成所有proto源码、wire等等 go generate ./... # 编译成可执行文件 go build -o ./bin/ ./... # 运行项目 ./bin/helloworld -conf ./configs 看到如下输出则证明项目启动正常
level=INFO module=app service_id=7114ad8a-b3bf-11eb-a1b9-f0189850d2cb service_name= version= level=INFO module=transport/grpc msg=[gRPC] server listening on: [::]:9000 level=INFO module=transport/http msg=[HTTP] server listening on: [::]:8000 测试接口
curl 'http://127.0.0.1:8000/helloworld/krtaos' 输出： { "message": "Hello kratos" } 应用是如何跑起来的? 通过上面的图例👆,我们可以直观观察到应用的调用链,简化来说如下图流程所示👇
1. 注入依赖并调用 newApp() 方法 // helloword/cmd/main.go func main() { flag.Parse() logger := log.NewStdLogger(os.Stdout) // 调用 go-kratos/kratos/v2/config,创建 config 实例,并指定了来源和配置解析方法 c := config.New( config.WithSource( file.NewSource(flagconf), ), config.WithDecoder(func(kv *config.KeyValue, v map[string]interface{}) error { return yaml.Unmarshal(kv.Value, v) }), ) if err := c.Load(); err != nil { panic(err) } // 将配置扫描到,通过 proto 声明的 conf struct 上 var bc conf.Bootstrap if err := c.Scan(&amp;bc); err != nil { panic(err) } // 通过 wire 将依赖注入,并调用 newApp 方法 app, cleanup, err := initApp(bc.Server, bc.Data, logger) if err != nil { panic(err) } // 省略代码... } 2. 创建 kratos 实例 项目 main.go 的 newApp() 方法中,调用了 go-kratos/kratos/v2/app.go 中的 kratos.New() 方法
// helloword/cmd/main.go func newApp(logger log.Logger, hs *http.Server, gs *grpc.Server) *kratos.App { return kratos.New( // 配置应用 kratos.Name(Name), kratos.Version(Version), kratos.Metadata(map[string]string{}), kratos.Logger(logger), // kratos.Server() 传入的 http/grpc 服务会通过 buildInstance() 转换成registry.ServiceInstance struct* kratos.Server( hs, gs, ), ) } 该方法会返回一个 App struct,包含 Run() 和 Stop() 方法
// go-kratos/kratos/v2/app.go type App struct { opts options //配置 ctx context.Context // 上下文 cancel func() // context 的取消方法 instance *registry.ServiceInstance //通过 kratos.Server()声明的实例,并通过 buildInstance() 转换后的 *registry.ServiceInstance struct log *log.Helper // 日志 } // Run executes all OnStart hooks registered with the application's Lifecycle. func (a *App) Run() error { // 省略代码... } // Stop gracefully stops the application. func (a *App) Stop() error { // 省略代码... } 3. 调用 Run() 方法# 项目在 main 方法中调用了 kratos.App struct 的 Run() 方法.
// helloword/cmd/main.go // 省略代码... // 启动 Kratos if err := app.Run(); err != nil { panic(err) } Run() 方法的实现细节
// go-kratos/kratos/v2/app.go func (a *App) Run() error { a.log.Infow( "service_id", a.opts.id, "service_name", a.opts.name, "version", a.opts.version, ) g, ctx := errgroup.WithContext(a.ctx) // 遍历通过 kratos.Server() 声明的服务实例 for _, srv := range a.opts.servers { srv := srv // 执行两个goroutine, 用于处理服务启动和退出 g.Go(func() error { &lt;-ctx.Done() // 阻塞,等待调用 cancel 方法 return srv.Stop() // 协程退出后,调用实例的停止方法 }) g.Go(func() error { return srv.Start() // 调用实例的运行方法 }) } // 判断是否调用 kratos.Registrar() 配置了注册发现中心 if a.opts.registrar != nil { // 将实例注册到注册中心 if err := a.opts.registrar.Register(a.opts.ctx, a.instance); err != nil return err } } // 监听进程退出信号 c := make(chan os.Signal, 1) signal.Notify(c, a.opts.sigs...) // 处理进程退出和 context 退出 g.Go(func() error { for { select { case &lt;-ctx.Done(): return ctx.Err() case &lt;-c: // 调用 kratos.App 的停止方法 a.Stop() } } }) if err := g.Wait(); err != nil &amp;&amp; !errors.Is(err, context.Canceled) { return err } return nil } 4. 应用退出 Kratos 实例在启动时,监听了系统的进程退出信号,当收到退出信号时,kratos 会调用 App struct 的 Stop() 方法
// go-kratos/kratos/v2/app.go func (a *App) Stop() error { // 判断是否有注册中心配置 if a.opts.registrar != nil { // 在注册中心中将实例注销 if err := a.opts.registrar.Deregister(a.opts.ctx, a.instance); err != nil { return err } } // 控制 goroutine 的退出,当调用 a.cancel()时,Run()方法中 监听的 &lt;-ctx.Done() 收到消息后,没有阻塞后,方法会调用 server 的 Stop()方法,停止服务 if a.cancel != nil { a.cancel() } return nil } 文章转自： https://go-kratos.dev/blog/go-layout-operation-process/</content></entry><entry><title>限流</title><url>https://www.zhaohaiyu.com/post/microservice/currentlimiting/</url><categories><category>microservice</category></categories><tags/><content type="html"> 令牌桶算法 是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下：
假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌。 桶中最多存放 b 个令牌，当桶满时，新添加的令牌被丢弃或拒绝。 当一个 n 个字节大小的数据包到达，将从桶中删除n 个令牌，接着数据包被发送到网络上。 如果桶中的令牌不足 n 个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。 令牌桶速率限制算法: golang.org/x/time/rate
漏桶算法 作为计量工具(The Leaky Bucket Algorithm as a Meter)时，可以用于流量整形(Traffic Shaping)和流量控制(TrafficPolicing)，漏桶算法的描述如下：
一个固定容量的漏桶，按照常量固定速率流出水滴。 如果桶是空的，则不需流出水滴。 可以以任意速率流入水滴到漏桶。 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。 漏桶率限制算法: go.uber.org/ratelimit
过载保护 令牌桶与漏桶的缺点 漏斗桶/令牌桶确实能够保护系统不被拖垮, 但不管漏斗桶还是令牌桶, 其防护思路都是设定一个指标, 当超过该指标后就阻止或减少流量的继续进入，当系统负载降低到某一水平后则恢复流量的进入。但其通常都是被动的，其实际效果取决于限流阈值设置是否合理，但往往设置合理不是一件容易的事情。
集群增加机器或者减少机器限流阈值是否要重新设置? 设置限流阈值的依据是什么? 人力运维成本是否过高? 当调用方反馈429时, 这个时候重新设置限流, 其实流量高峰已经过了重新评估限流是否有意义? 这些其实都是采用漏斗桶/令牌桶的缺点, 总体来说就是太被动, 不能快速适应流量变化。 因此我们需要一种自适应的限流算法，即: 过载保护，根据系统当前的负载自动丢弃流量。
过载保护方法 计算系统临近过载时的峰值吞吐作为限流的阈值来进行流量控制，达到系统保护。
服务器临近过载时，主动抛弃一定量的负载，目标是自保。 在系统稳定的前提下，保持系统的吞吐量。 利特尔法则 计算吞吐量：利特尔法则 L = λ * W
利特尔法则由麻省理工大学斯隆商学院（MIT Sloan School of Management）的教授 John Little﹐于 1961 年所提出与证明。它是一个有关提前期与在制品关系的简单数学公式，这一法则为精益生产的改善方向指明了道路。 —- MBA 智库百科 (mbalib.com) 如上图所示，如果我们开一个小店，平均每分钟进店 2 个客人(λ)，每位客人从等待到完成交易需要 4 分钟(W)，那我们店里能承载的客人数量就是 2 * 4 = 8 个人
同理，我们可以将 λ 当做 QPS， W 呢是每个请求需要花费的时间，那我们的系统的吞吐就是 L = λ * W ，所以我们可以使用利特尔法则来计算系统的吞吐量。
什么时候系统的吞吐量就是最大的吞吐量？ 首先我们可以通过统计过去一段时间的数据，获取到平均每秒的请求量，也就是 QPS，以及请求的耗时时间，为了避免出现前面 900ms 一个请求都没有最后 100ms 请求特别多的情况，我们可以使用滑动窗口算法来进行统计。
最容易想到的就是我们从系统启动开始，就把这些值给保存下来，然后计算一个吞吐的最大值，用这个来表示我们的最大吞吐量就可以了。但是这样存在一个问题是，我们很多系统其实都不是独占一台机器的，一个物理机上面往往有很多服务，并且一般还存在一些超卖，所以可能第一个小时最大处理能力是 100，但是这台节点上其他服务实例同时都在抢占资源的时候，这个处理能力最多就只能到 80 了
所以我们需要一个数据来做启发阈值，只要这个指标达到了阈值那我们就进入流控当中。常见的选择一般是 CPU、Memory、System Load，这里我们以 CPU 为例
只要我们的 CPU 负载超过 80% 的时候，获取过去 5s 的最大吞吐数据，然后再统计当前系统中的请求数量，只要当前系统中的请求数大于最大吞吐那么我们就丢弃这个请求。
如何计算接近峰值时的系统吞吐？
CPU: 使用一个独立的线程采样，每隔 250ms 触发一次。在计算均值时，使用了简单滑动平均去除峰值的影响。 Inflight: 当前服务中正在进行的请求的数量。 Pass&amp;RT: 最近5s，pass 为每100ms采样窗口内成功请求的数量，rt 为单个采样窗口中平均响应时间。 我们使用 CPU 的滑动均值(CPU > 800)作为启发阈值，一旦触发进入到过载保护阶段，算法为：(pass* rt) &lt; inflight 限流效果生效后，CPU 会在临界值(800)附近抖动，如果不使用冷却时间，那么一个短时间的 CPU 下降就可能导致大量请求被放行，严重时会打满 CPU。 在冷却时间后，重新判断阈值(CPU > 800 )，是否持续进入过载保护。 什么是限流 限流是指在一段时间内，定义某个客户或应用可以接收或处理多少个请求的技术。例如，通过限流，你可以过滤掉产生流量峰值的客户和微服务，或者可以确保你的应用程序在自动扩展(Auto Scaling)失效前都不会出现过载的情况。
令牌桶、漏桶 针对单个节点，无法分布式限流。 QPS 限流 不同的请求可能需要数量迥异的资源来处理。 某种静态 QPS 限流不是特别准。 给每个用户设置限制 全局过载发生时候，针对某些“异常”进行控制。 一定程度的“超卖”配额。 按照优先级丢弃。 拒绝请求也需要成本。 分布式限流 分布式限流，是为了控制某个应用全局的流量，而非真对单个节点纬度。
单个大流量的接口，使用 redis 容易产生热点。 pre-request 模式对性能有一定影响，高频的网络往返。 思考：
从获取单个 quota 升级成批量 quota。quota: 表示速率，获取后使用令牌桶算法来限制。 每次心跳后，异步批量获取 quota，可以大大减少请求 redis 的频次，获取完以后本地消费，基于令牌桶拦截。 每次申请的配额需要手动设定静态值略欠灵活，比如每次要20，还是50。 如何基于单个节点按需申请，并且避免出现不公平的现象？ 初次使用默认值，一旦有过去历史窗口的数据，可以基于历史窗口数据进行 quota 请求。 思考：
我们经常面临给一组用户划分稀有资源的问题，他们都享有等价的权利来获取资源，但是其中一些用户实际上只需要比其他用户少的资源。 那么我们如何来分配资源呢？一种在实际中广泛使用的分享技术称作“最大最小公平分享”(Max-Min Fairness)。 直观上，公平分享分配给每个用户想要的可以满足的最小需求，然后将没有使用的资源均匀的分配给需要‘大资源’的用户。 最大最小公平分配算法的形式化定义如下：
资源按照需求递增的顺序进行分配。 不存在用户得到的资源超过自己的需求。 未得到满足的用户等价的分享资源。 限流的重要性 每个接口配置阈值，运营工作繁重，最简单的我们配置服务级别 quota，更细粒度的，我们可以根据不同重要性设定 quota，我们引入了重要性(criticality):
最重要 CRITICAL_PLUS，为最终的要求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。 重要 CRITICAL，生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题。但是可能没那么严重。 可丢弃的 SHEDDABLE_PLUS 这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些请求通常可以过几分钟、几小时后重试。 可丢弃的 SHEDDABLE 这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用。 gRPC 系统之间，需要自动传递重要性信息。如果后端接受到请求 A，在处理过程中发出了请求 B 和 C 给其他后端，请求 B 和 C 会使用与 A 相同的重要性属性。
全局配额不足时，优先拒绝低优先级的。 全局配额，可以按照重要性分别设置。 过载保护时，低优先级的请求先被拒绝。 熔断 断路器(Circuit Breakers): 为了限制操作的持续时间，我们可以使用超时，超时可以防止挂起操作并保证系统可以响应。因为我们处于高度动态的环境中，几乎不可能确定在每种情况下都能正常工作的准确的时间限制。断路器以现实世界的电子元件命名，因为它们的行为是都是相同的。断路器在分布式系统中非常有用，因为重复的故障可能会导致雪球效应，并使整个系统崩溃。
服务依赖的资源出现大量错误。 某个用户超过资源配额时，后端任务会快速拒绝请求，返回“配额不足”的错误，但是拒绝回复仍然会消耗一定资源。有可能后端忙着不停发送拒绝请求，导致过载。 如上图所示，熔断器存在三个状态:
关闭(closed): 关闭状态下没有触发断路保护，所有的请求都正常通行 打开(open): 当错误阈值触发之后，就进入开启状态，这个时候所有的流量都会被节流，不运行通行 半打开(half-open): 处于打开状态一段时间之后，会尝试尝试放行一个流量来探测当前 server 端是否可以接收新流量，如果这个没有问题就会进入关闭状态，如果有问题又会回到打开状态 Google SRE 过载保护算法 max(0, (requests - K*accepts) / (requests + 1)) 算法如上所示，这个公式计算的是请求被丢弃的概率[3] requests: 一段时间的请求数量 accepts: 成功的请求数量 K: 倍率，K 越小表示越激进，越小表示越容易被丢弃请求 这个算法的好处是不会直接一刀切的丢弃所有请求，而是计算出一个概率来进行判断，当成功的请求数量越少，K越小的时候 requests−K∗accepts 的值就越大，计算出的概率也就越大，表示这个请求被丢弃的概率越大
Gutter 基于熔断的 gutter kafka ，用于接管自动修复系统运行过程中的负载，这样只需要付出10%的资源就能解决部分系统可用性问题。 我们经常使用 failover 的思路，但是完整的 failover 需要翻倍的机器资源，平常不接受流量时，资源浪费。高负载情况下接管流量又不一定完整能接住。所以这里核心利用熔断的思路，是把抛弃的流量转移到 gutter 集群，如果 gutter 也接受不住的流量，重新回抛到主集群，最大力度来接受。
客户端流控 positive feedback: 用户总是积极重试，访问一个不可达的服务。
客户端需要限制请求频次，retry backoff 做一定的请求退让。 可以通过接口级别的error_details，挂载到每个 API 返回的响应里。 参考文章 https://blog.csdn.net/m__l__/article/details/109175787 https://lailin.xyz/post/go-training-week6-4-auto-limiter.html https://lailin.xyz/post/go-training-week6-6-breaker.html</content></entry><entry><title>隔离</title><url>https://www.zhaohaiyu.com/post/microservice/quarantine/</url><categories><category>microservice</category></categories><tags/><content type="html"> 什么是隔离？ 隔离，本质上是对系统或资源进行分割，从而实现当系统发生故障时能限定传播范围和影响范围，即发生故障后只有出问题的服务不可用，保证其他服务仍然可用。
服务隔离 动静隔离 例如 CDN
小到 CPU 的 cacheline false sharing、数据库 mysql 表设计中避免 bufferpool 频繁过期，隔离动静表，大到架构设计中的图片、静态资源等缓存加速。本质上都体现的一样的思路，即加速/缓存访问变换频次小的。比如 CDN 场景中，将静态资源和动态 API 分离，也是体现了隔离的思路:
降低应用服务器负载，静态文件访问负载全部通过CDN。 对象存储存储费用最低。 海量存储空间，无需考虑存储架构升级。 静态CDN带宽加速，延迟低。 archive: 稿件表，存储稿件的名称、作者、分类、tag、状态等信息，表示稿件的基本信息。 在一个投稿流程中，一旦稿件创建改动的频率比较低。 archive_stat: 稿件统计表，表示稿件的播放、点赞、收藏、投币数量，比较高频的更新。 随着稿件获取流量，稿件被用户所消费，各类计数信息更新比较频繁。 MySQL BufferPool 是用于缓存 DataPage 的，DataPage 可以理解为缓存了表的行，那么如果频繁更新 DataPage 不断会置换，会导致命中率下降的问题，所以我们在表设计中，仍然可以沿用类似的思路，其主表基本更新，在上游 Cache 未命中，透穿到 MySQL，仍然有 BufferPool 的缓存。
读写隔离 例如主从，除此之外还有常见的 CQRS 模式，分库分表等
常见的隔离技术，当用于读取操作的服务器出现故障时，写服务器照常可以运作，反之也一样。
轻重隔离 核心隔离：例如上面讲到将核心业务独立部署，非核心业务共享资源 热点隔离：例如上面讲到的 remote cache 到 local cache 用户隔离：不同的用户可能有不同的级别，例如上面讲到的外部用户和管理员 物理隔离 线程 常见的例子就是线程池，这个在 Golang 中一般不用过多考虑，runtime 已经帮我们管理好了
主要通过线程池进行隔离，也是实现服务隔离的基础。（可将图中隔离媒介换成线程池即可）
把业务进行分类并交给不同的线程池进行处理，当某个线程池处理一种业务请求发生问题时，不会讲故障扩散和影响到其他线程池，保证服务可用。
假设系统存在商品服务、用户服务和订单服务3个微服务，通过设置运行时环境得到3个服务一共使用200个线程，客户端调用这3个微服务共享线程池时可能会引发服务雪崩，将线程分别隔离后则不会触发整体雪崩。
进程 我们现在一般使用容器化服务，跑在 k8s 上这就是一种进程级别的隔离
将系统拆分为多个子系统来实现物理隔离，各个子系统运行在独立的容器和JVM中，通过进程隔离使得一个子系统出现问题不会影响其他子系统。
机房 我们目前在 K8s 的基础上做一些开发，常见的一种做法就是将我们的服务的不同副本尽量的分配在不同的可用区，实际上就是云厂商的不同机房，避免机房停电或者着火之类的影响
如果有条件，对于大型高可用系统，会进行多机房部署，每个机房的服务都有自己的服务分组，本机房的服务应该只调用同机房服务。
当一个机房出现故障，将请求快速切换到其他机房确保服务继续可用。
集群 非常重要的服务我们可以部署多套，在物理上进行隔离，常见的有异地部署，也可能就部署在同一个区域
将某些服务单独部署成集群，或对于某些服务可以进行分组集群管理，某一个集群出现问题之后就不会影响到其他集群，从而实现隔离。
参考文章 https://blog.csdn.net/xiaofeng10330111/article/details/86772740 https://lailin.xyz/post/go-training-week6-usability-1-bulkhe.html</content></entry><entry><title>基于 OpenTelemetry 的链路追踪</title><url>https://www.zhaohaiyu.com/post/operations/open-telemetry/</url><categories><category>operations</category></categories><tags><tag>运维</tag><tag>traceing</tag></tags><content type="html"> 链路追踪的前世今生 分布式跟踪（也称为分布式请求跟踪）是一种用于分析和监控应用程序的方法，尤其是使用微服务架构构建的应用程序。分布式跟踪有助于精确定位故障发生的位置以及导致性能差的原因。
起源 链路追踪(Distributed Tracing)　一词最早出现于谷歌发布的论文 《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》 中,这篇论文对于实现链路追踪,对于后来出现的 Jaeger、Zipkin 等开源分布式追踪项目设计理念仍有很深的影响。
微服务架构是一个分布式的架构,会有很多个不同的服务。不同的服务之前相互调用,如果出现了错误由于一个请求经过了 N 个服务。随着业务的增加越来越多的服务之间的调用，如果没有一个工具去记录调用链，解决问题的时候就会像下面图片里小猫咪玩的毛线球一样，毫无头绪，无从下手
所以需要有一个工具能够清楚的了解一个请求经过了哪些服务,顺序是如何,从而能够轻易的定位问题。
百家争艳 从谷歌发布 Dapper 后，分布式链路追踪工具越来越多，以下简单列举了一些常用的链路追踪系统
Skywalking 阿里 鹰眼 大众点评 CAT Twitter Zipkin Naver pinpoint Uber Jaeger 争锋相对？ 随着链路追踪工具越来越多，开源领域主要分为两派，一派是以 CNCF技术委员 会为主的 OpenTracing 的规范，例如 jaeger zipkin 都是遵循了OpenTracing 的规范。而另一派则是谷歌作为发起者的 OpenCensus，而且谷歌本身还是最早提出链路追踪概念的公司，后期连微软也加入了 OpenCensus
OpenTelemetry 诞生 OpenTelemetric 是一组 API、SDK、模组和集成，专为创建和管理‎‎遥测数据‎‎（如追踪、指标和日志）而设
微软加入 OpenCensus 后，直接打破了之前平衡的局面，间接的导致了 OpenTelemetry 的诞生 谷歌和微软下定决心结束江湖之乱，首要的问题是如何整合两个两个社区已有的项目，OpenTelemetry 主要的理念就是，兼容 OpenCensus 和 OpenTracing ，可以让使用者无需改动或者很小的改动就可以接入 OpenTelemetry
Kratos 的链路追踪实践 Kratos 一套轻量级 Go 微服务框架，包含大量微服务相关框架及工具。
tracing 中间件 kratos 框架提供的自带中间件中有一个名为 tracing 中间件，它基于 Opentelemetry 实现了kratos 框架的链路追踪功能，中间件的代码可以从 middleware/tracing 中看到。
实现原理 kratos 的链路追踪中间件由三个文件组成 carrie.go,tracer.go,tracing.go。client和 server 的实现原理基本相同，本文以 server 实现进行原理解析。
首先当请求进入时，tracing 中间件会被调用,首先调用了 tracer.go 中的 NewTracer 方法 // Server returns a new server middleware for OpenTelemetry. func Server(opts ...Option) middleware.Middleware { // 调用 tracer.go 中的 NewTracer 传入了一个 SpanKindServer 和配置项 tracer := NewTracer(trace.SpanKindServer, opts...) // ... 省略代码 } tracer.go 中的 NewTracer 方法被调用后会返回一个 Tracer,实现如下 func NewTracer(kind trace.SpanKind, opts ...Option) *Tracer { options := options{} for _, o := range opts { o(&amp;options) } // 判断是否存在 otel 追踪提供者配置，如果存在则设置 if options.TracerProvider != nil { otel.SetTracerProvider(options.TracerProvider) } /* 判断是否存在 Propagators 设置，如果存在设置则覆盖，不存在则设置一个默认的TextMapPropagator 注意如果没有设置默认的TextMapPropagator,链路信息则无法正确的传递 */ if options.Propagators != nil { otel.SetTextMapPropagator(options.Propagators) } else { otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.Baggage{}, propagation.TraceContext{})) } var name string // 判断当前中间件的类型，是 server 还是 client if kind == trace.SpanKindServer { name = "server" } else if kind == trace.SpanKindClient { name = "client" } else { panic(fmt.Sprintf("unsupported span kind: %v", kind)) } // 调用 otel包的 Tracer 方法 传入 name 用来创建一个 tracer 实例 tracer := otel.Tracer(name) return &amp;Tracer{tracer: tracer, kind: kind} } 判断当前请求类型，处理需要采集的数据，并调用 tracer.go 中的 Start 方法 var ( component string operation string carrier propagation.TextMapCarrier ) // 判断请求类型 if info, ok := http.FromServerContext(ctx); ok { // HTTP component = "HTTP" // 取出请求的地址 operation = info.Request.RequestURI // 调用 otel/propagation包中的 HeaderCarrier，会处理 http.Header 以用来满足TextMapCarrier interface // TextMapCarrier 是一个文本映射载体，用于承载信息 carrier = propagation.HeaderCarrier(info.Request.Header) // otel.GetTextMapPropagator().Extract() 方法用于将文本映射载体，读取到上下文中 ctx = otel.GetTextMapPropagator().Extract(ctx, propagation.HeaderCarrier(info.Request.Header)) } else if info, ok := grpc.FromServerContext(ctx); ok { // Grpc component = "gRPC" operation = info.FullMethod // // 调用 grpc/metadata包中metadata.FromIncomingContext(ctx)传入 ctx，转换 grpc 的元数据 if md, ok := metadata.FromIncomingContext(ctx); ok { // 调用carrier.go 中的 MetadataCarrier 将 MD 转换 成文本映射载体 carrier = MetadataCarrier(md) } } // 调用 tracer.Start 方法 ctx, span := tracer.Start(ctx, component, operation, carrier) // ... 省略代码 } 调用 tracing.go 中的 Start 方法 func (t *Tracer) Start(ctx context.Context, component string, operation string, carrier propagation.TextMapCarrier) (context.Context, trace.Span) { // 判断当前中间件如果是 server则将 carrier 注入到上下文中 if t.kind == trace.SpanKindServer { ctx = otel.GetTextMapPropagator().Extract(ctx, carrier) } // 调用otel/tracer 包中的 start 方法，用来创建一个 span ctx, span := t.tracer.Start(ctx, // tracing.go 中声明的请求路由作为 spanName operation, // 设置 span 的属性，设置了一个 component，component的值为请求类型 trace.WithAttributes(attribute.String("component", component)), // 设置 span种类 trace.WithSpanKind(t.kind), ) // 判断如果当前中间件是 client 则将 carrier 注入到请求里面 if t.kind == trace.SpanKindClient { otel.GetTextMapPropagator().Inject(ctx, carrier) } return ctx, span } defer 声明了一个闭包方法 // 这个地方要注意，需要使用闭包，因为 defer 的参数是实时计算的如果异常发生，err 会一直为 nil // https://github.com/go-kratos/kratos/issues/927 defer func() { tracer.End(ctx, span, err) }() 中间件继续执行 // tracing.go 69行 reply, err = handler(ctx, req) 中间件调用结束 defer 中的闭包被调用后执行了 tracer.go 中的 End 方法 func (t *Tracer) End(ctx context.Context, span trace.Span, err error) { // 判断是否有异常发生，如果有则设置一些异常信息 if err != nil { // 记录异常 span.RecordError(err) // 设置span 属性 span.SetAttributes( // 设置事件为异常 attribute.String("event", "error"), // 设置 message 为 err.Error(). attribute.String("message", err.Error()), ) //设置了 span 的状态 span.SetStatus(codes.Error, err.Error()) } else { // 如果没有发生异常，span 状态则为 ok span.SetStatus(codes.Ok, "OK") } // 中止 span span.End() } 如何使用 tracing 中间件的使用示例可以从 kratos/examples/traces ,该示例简单的实现了跨服务间的链路追踪,以下代码片段包含部分示例代码。
// https://github.com/go-kratos/kratos/blob/7f835db398c9d0332e69b81bad4c652b4b45ae2e/examples/traces/app/message/main.go#L38 // 首先调用otel 库方法，得到一个 TracerProvider func tracerProvider(url string) (*tracesdk.TracerProvider, error) { // examples/traces 中使用的是 jaeger，其他方式可以查看 opentelemetry 官方示例 exp, err := jaeger.NewRawExporter(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(url))) if err != nil { return nil, err } tp := tracesdk.NewTracerProvider( tracesdk.WithSampler(tracesdk.AlwaysSample()), // 设置 Batcher，注册jaeger导出程序 tracesdk.WithBatcher(exp), // 记录一些默认信息 tracesdk.WithResource(resource.NewWithAttributes( semconv.ServiceNameKey.String(pb.User_ServiceDesc.ServiceName), attribute.String("environment", "development"), attribute.Int64("ID", 1), )), ) return tp, nil } 在 grpc/server 中使用 // https://github.com/go-kratos/kratos/blob/main/examples/traces/app/message/main.go grpcSrv := grpc.NewServer( grpc.Address(":9000"), grpc.Middleware( // Configuring tracing Middleware tracing.Server( tracing.WithTracerProvider(tp), ), ), ) 在 grpc/client 中使用 // https://github.com/go-kratos/kratos/blob/149fc0195eb62ee1fbc2728adb92e1bcd1a12c4e/examples/traces/app/user/main.go#L63 conn, err := grpc.DialInsecure(ctx, grpc.WithEndpoint("127.0.0.1:9000"), grpc.WithMiddleware( tracing.Client( tracing.WithTracerProvider(s.tracer), tracing.WithPropagators( propagation.NewCompositeTextMapPropagator(propagation.Baggage{}, propagation.TraceContext{}), ), ) ), grpc.WithTimeout(2*time.Second), ) 在 http/server 中使用 // https://github.com/go-kratos/kratos/blob/main/examples/traces/app/user/main.go httpSrv := http.NewServer(http.Address(":8000")) httpSrv.HandlePrefix("/", pb.NewUserHandler(s, http.Middleware( // Configuring tracing middleware tracing.Server( tracing.WithTracerProvider(tp), tracing.WithPropagators( propagation.NewCompositeTextMapPropagator(propagation.Baggage{}, propagation.TraceContext{}), ), ), ), ) 在 http/client 中使用 http.NewClient(ctx, http.WithMiddleware( tracing.Client( tracing.WithTracerProvider(s.tracer), ), )) 如何实现一个其他场景的 tracing 我们可以借鉴 kratos 的 tracing 中间件的代码来实现例如数据库的 tracing，如下面的代码片段，作者借鉴了tracing 中间件，实现了 qmgo 库操作 MongoDB 数据库的 tracing。
func mongoTracer(ctx context.Context,tp trace.TracerProvider, command interface{}) { var ( commandName string failure string nanos int64 reply bson.Raw queryId int64 eventName string ) otel.SetTracerProvider(tp) reply = bson.Raw{} switch value := command.(type) { case *event.CommandStartedEvent: commandName = value.CommandName reply = value.Command queryId = value.RequestID eventName = "CommandStartedEvent" case *event.CommandSucceededEvent: commandName = value.CommandName nanos = value.DurationNanos queryId = value.RequestID eventName = "CommandSucceededEvent" case *event.CommandFailedEvent: commandName = value.CommandName failure = value.Failure nanos = value.DurationNanos queryId = value.RequestID eventName = "CommandFailedEvent" } duration, _ := time.ParseDuration(strconv.FormatInt(nanos, 10) + "ns") tracer := otel.Tracer("mongodb") kind := trace.SpanKindServer ctx, span := tracer.Start(ctx, commandName, trace.WithAttributes( attribute.String("event", eventName), attribute.String("command", commandName), attribute.String("query", reply.String()), attribute.Int64("queryId", queryId), attribute.String("ms", duration.String()), ), trace.WithSpanKind(kind), ) if failure != "" { span.RecordError(errors.New(failure)) } span.End() } 文章转自 https://go-kratos.dev/blog/go-kratos-opentelemetry-practice</content></entry><entry><title>Go工程化 - 依赖注入</title><url>https://www.zhaohaiyu.com/post/go/wire/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>wire</tag></tags><content type="html"> 我们在微服务框架kratos v2 的默认项目模板中kratos-layout 使用了google/wire 进行依赖注入，也建议开发者在维护项目时使用该工具。
wire 乍看起来比较违反直觉，导致很多同学不理解为什么要用或不清楚如何用（也包括曾经的我），本文来帮助大家理解 wire 的使用。
What wire 是由 google 开源的一个供 Go 语言使用的依赖注入代码生成工具。它能够根据你的代码，生成相应的依赖注入 go 代码。
而与其它依靠反射实现的依赖注入工具不同的是，wire 能在编译期（准确地说是代码生成时）如果依赖注入有问题，在代码生成时即可报出来，不会拖到运行时才报，更便于 debug。
Why 理解依赖注入 什么是依赖注入？为什么要依赖注入？ 依赖注入就是 Java 遗毒（不是）
依赖注入 (Dependency Injection，缩写为 DI)，可以理解为一种代码的构造模式（就是写法），按照这样的方式来写，能够让你的代码更加容易维护。
对于很多软件设计模式和架构的理念，我们都无法理解他们要绕好大一圈做复杂的体操、用奇怪的方式进行实现的意义。他们通常都只是丢出来一段样例，说这样写就很好很优雅，由于省略掉了这种模式是如何发展出来的推导过程，我们只看到了结果，导致理解起来很困难。那么接下来我们来尝试推导还原一下整个过程，看看代码是如何和为什么演进到依赖注入模式的，以便能够更好理解使用依赖注入的意义。
依赖是什么？ 这里的依赖是个名词，不是指软件包的依赖（比如那坨塞在 node_modules 里面的东西），而是指软件中某一个模块（对象/实例）所依赖的其它外部模块（对象/实例）。
注入到哪里？ 被依赖的模块，在创建模块时，被注入到（即当作参数传入）模块的里面。
不 DI 是啥样？DI 了又样子？ 下面用 go 伪代码来做例子，领会精神即可。
假设个场景，你在打工搞一个 web 应用，它有一个简单接口。最开始的项目代码可能长这个样子：
# 下面为伪代码，忽略了很多与主题无关的细节 type App struct { } # 假设这个方法将会匹配并处理 GET /biu/&lt;id> 这样的请求 func (a *App) GetData(id string) string { # todo: write your data query return "some data" } func NewApp() *App { return &amp;App{} } app := App() app.Run() 你要做的是接一个 mysql，从里面把数据按照 id 查出来，返回。 要连 mysql 的话，假设我们已经有了个NewMySQLClient的方法返回 client 给你，初始化时传个地址进去就能拿到数据库连接，并假设它有个Exec的方法给你执行参数。
不用 DI，通过全局变量传递依赖实例 一种写法是，在外面全局初始化好 client，然后 App 直接拿来调用。
var mysqlUrl = "mysql://blabla" var db = NewMySQLClient(mysqlUrl) type App struct { } func (a *App) GetData(id string) string { data := db.Exec("select data from biu where id = ? limit 1", id) return data } func NewApp() *App { return &amp;App{} } func main() { app := App() app.Run() } 这就是没用依赖注入，app 依赖了全局变量 db，这是比较糟糕的一种做法。db 这个对象游离在全局作用域，暴露给包下的其他模块，比较危险。（设想如果这个包里其他代码在运行时悄悄把你的这个 db 变量替换掉会发生啥）
不用 DI，在 App 的初始化方法里创建依赖实例 另一种方式是这样的：
type App struct { db *MySQLClient } func (a *App) GetData(id string) string { data := a.db.Exec("select data from biu where id = ? limit 1", id) return data } func NewApp() *App { return &amp;App{db: NewMySQLClient(mysqlUrl)} } func main() { app := NewApp("mysql://blabla") app.Run() } 这种方法稍微好一些，db 被塞到 app 里面了，不会有 app 之外的无关代码碰它，比较安全，但这依然不是依赖注入，而是在内部创建了依赖，接下来你会看到它带来的问题。
老板：我们的数据要换个地方存 （需要变更实现） 你的老板不知道从哪听说——Redis 贼特么快，要不我们的数据改从 Redis 里读吧。这个时候你的内心有点崩溃，但毕竟要恰饭的，就硬着头皮改上面的代码。
type App struct { ds *RedisClient } func (a *App) GetData(id string) string { data := a.ds.Do("GET", "biu_"+id) return data } func NewApp() *App { return &amp;App{ds: NewRedisClient(redisAddr)} } func main() { app := NewApp("redis://ooo") app.Run() } 上面基本进行了 3 处修改：
App 初始化方法里改成了初始化 RedisClient get_data 里取数据时改用 run 方法，并且查询语句也换了 App 实例化时传入的参数改成了 redis 地址 老板：要不，我们再换个地方存？/我们要加测试，需要 Mock 老板的思路总是很广的，又过了两天他又想换成 Postgres 存了；或者让你们给 App 写点测试代码，只测接口里面的逻辑，通常我们不太愿意在旁边再起一个数据库，那么就需要 mock 掉数据源这块东西，让它直接返回数据给请求的 handler 用，来进行针对性的测试。
这种情况怎么办？再改里面的代码？这不科学。
面向接口编程 一个很重要的思路就是要面向接口(interface)编程，而不是面向具体实现编程。
什么叫面向具体实现编程呢？比如上述的例子里改动的部分：调 mysqlclient 的 exec_sql 执行一条 sql，被改成了：调 redisclient 的 do 执行一句 get 指令。由于每种 client 的接口设计不同，每换一个实现，就得改一遍。
而面向接口编程的思路，则完全不同。我们不要听老板想用啥就马上写代码。首先就得预料到，这个数据源的实现很有可能被更换，因此在一开始就应该做好准备（设计）。
设计接口 Python 里面有个概念叫鸭子类型(duck-typing)，就是如果你叫起来像鸭子，走路像鸭子，游泳像鸭子，那么你就是一只鸭子。这里的叫、走路、游泳就是我们约定的鸭子接口，而你如果完整实现了这些接口，我们可以像对待一个鸭子一样对待你。
在我们上面的例子中，不论是 Mysql 实现还是 Redis 实现，他们都有个共同的功能：用一个 id，查一个数据出来，那么这就是共同的接口。
我们可以约定一个叫 DataSource 的接口，它必须有一个方法叫 GetById，功能是要接收一个 id，返回一个字符串
type DataSource interface { GetById(id string) string } 然后我们就可以把各个数据源分别进行封装，按照这个 interface 定义实现接口，这样我们的 App 里处理请求的部分就可以稳定地调用 GetById 这个方法，而底层数据实现只要实现了 DataSource 这个 interface 就能花式替换，不用改 App 内部的代码了。
// 封装个redis type redis struct { r *RedisClient } func NewRedis(addr string) *redis { return &amp;redis{r: NewRedisClient(addr)} } func (r *redis) GetById(id string) string { return r.r.Do("GET", "biu_"+id) } // 再封装个mysql type mysql struct { m *MySQLClient } func NewMySQL(addr string) *redis { return &amp;mysql{m: NewMySQLClient(addr)} } func (m *mysql) GetById(id string) string { return r.m.Exec("select data from biu where id = ? limit 1", id) } type App struct { ds DataSource } func NewApp(addr string) *App { //需要用Mysql的时候 return &amp;App{ds: NewMySQLClient(addr)} //需要用Redis的时候 return &amp;App{ds: NewRedisClient(addr)} } 由于两种数据源都实现了 DataSource 接口，因此可以直接创建一个塞到 App 里面了，想用哪个用哪个，看着还不错？
等一等，好像少了些什么 addr 作为参数，是不是有点简单？通常初始化一个数据库连接，可能有一堆参数，配在一个 yaml 文件里，需要解析到一个 struct 里面，然后再传给对应的 New 方法。
配置文件可能是这样的：
redis: addr: 127.0.0.1:6379 read_timeout: 0.2s write_timeout: 0.2s 解析结构体是这样的：
type RedisConfig struct { Network string `json:"network,omitempty"` Addr string `json:"addr,omitempty"` ReadTimeout *duration.Duration `json:"read_timeout,omitempty"` WriteTimeout *duration.Duration `json:"write_timeout,omitempty"` } 结果你的NewApp方法可能就变成了这个德性：
func NewApp() *App { var conf *RedisConfig yamlFile, err := ioutil.ReadFile("redis_conf.yaml") if err != nil { panic(err) } err = yaml.Unmarshal(yamlFile, &amp;conf) if err != nil { panic(err) } return &amp;App{ds: NewRedisClient(conf)} } NewApp 说，停停，你们年轻人不讲武德，我的责任就是创建一个 App 实例，我只需要一个 DataSource 注册进去，至于这个 DataSource 是怎么来的我不想管，这么一坨处理 conf 的代码凭什么要放在我这里，我也不想关心你这配置文件是通过网络请求拿来的还是从本地磁盘读的，我只想把 App 组装好扔出去直接下班。
依赖注入终于可以登场了 还记得前面是怎么说依赖注入的吗？被依赖的模块，在创建模块时，被注入到（即当作参数传入）初始化函数里面。通过这种模式，正好可以让 NewApp 早点下班。我们在外面初始化好 NewRedis 或者 NewMysql，得到的 DataSource 直接扔给 NewApp。
也就是这样
func NewApp(ds DataSource) *App { return &amp;App{ds: ds} } 那坨读配置文件初始化 redis 的代码扔到初始化 DataSource 的方法里去
func NewRedis() DataSource { var conf *RedisConfig yamlFile, err := ioutil.ReadFile("redis_conf.yaml") if err != nil { panic(err) } err = yaml.Unmarshal(yamlFile, &amp;conf) if err != nil { panic(err) } return &amp;redis{r: NewRedisClient(conf)} } 更进一步，NewRedis 这个方法甚至也不需要关心文件是怎么读的，它的责任只是通过 conf 初始化一个 DataSource 出来，因此你可以继续把读 config 的代码往外抽，把 NewRedis 做成接收一个 conf，输出一个 DataSource
func GetRedisConf() *RedisConfig func NewRedis(conf *RedisConfig) DataSource 因为之前整个组装过程是散放在 main 函数下面的，我们把它抽出来搞成一个独立的 initApp 方法。最后你的 App 初始化逻辑就变成了这样
func initApp() *App { c := GetRedisConf() r := NewRedis(c) app := NewApp(r) return app } func main() { app := initApp() app.Run() } 然后你可以通过实现 DataSource 的接口，更换前面的读取配置文件的方法，和更换创建 DataSource 的方法，来任意修改你的底层实现（读配置文件的实现，和用哪种 DataSource 来查数据），而不用每次都改一大堆代码。这使得你的代码层次划分得更加清楚，更容易维护了。
这就是依赖注入。
手工依赖注入的问题 上文这一坨代码，把各个实例初始化好，再按照各个初始化方法的需求塞进去，最终构造出 app 的这坨代码，就是注入依赖的过程。
c := GetRedisConf() r := NewRedis(c) app := NewApp(r) 目前只有一个 DataSource，这样手写注入过程还可以，一旦你要维护的东西多了，比如你的 NewApp 是这样的NewApp(r *Redis, es *ES, us *UserSerivce, db *MySQL) *App然后其中 UserService 是这样的UserService(pg *Postgres, mm *Memcached)，这样形成了多层次的一堆依赖需要注入，徒手去写非常麻烦。
而这部分，就是 wire 这样的依赖注入工具能够起作用的地方了——他的功能只是通过生成代码帮你注入依赖，而实际的依赖实例需要你自己创建（初始化）。
How wire 的主要问题是，看文档学不会。反正我最初看完文档之后是一头雾水——这是啥，这要干啥？但通过我们刚才的推导过程，应该大概理解了为什么要用依赖注入，以及 wire 在这其中起到什么作用——通过生成代码帮你注入依赖，而实际的依赖实例需要你自己创建（初始化）。
接下来就比较清楚了。
首先要实现一个wire.go的文件，里面定义好 Injector。
// +build wireinject func initApp() (*App) { panic(wire.Build(GetRedisConf, NewRedis, SomeProviderSet, NewApp)) } 然后分别实现好 Provider。
执行wire命令后 他会扫描整个项目，并帮你生成一个wire_gen.go文件，如果你有什么没有实现好，它会报错出来。
你学会了吗？
重新理解 等一等，先别放弃治疗，让我们用神奇的中文编程来解释一下要怎么做。
谁参与编译？ 上面那个initApp方法，官方文档叫它 Injector，由于文件里首行// +build wireinject这句注释，这个 wire.go 文件只会由 wire 读取，在 go 编译器在编译代码时不会去管它，实际会读的是生成的 wire_gen.go 文件。
而 Provider 就是你代码的一部分，肯定会参与到编译过程。
Injector 是什么鬼东西？ Injector 就是你最终想要的结果——最终的 App 对象的初始化函数，也就是前面那个例子里的initApp方法。
把它理解为你去吃金拱门，进门看到点餐机，噼里啪啦点了一堆，最后打出一张单子。
// +build wireinject func 来一袋垃圾食品() 一袋垃圾食品 { panic(wire.Build(来一份巨无霸套餐, 来一份双层鳕鱼堡套餐, 来一盒麦乐鸡, 垃圾食品打包)) } 这就是你点的单子，它不参与编译，实际参与编译的代码是由 wire 帮你生成的。
Provider 是什么鬼东西？ Provider 就是创建各个依赖的方法，比如前面例子里的 NewRedis 和 NewApp 等。
你可以理解为，这些是金拱门的服务员和后厨要干的事情： 金拱门后厨需要提供这些食品的制作服务——实现这些实例初始化方法。
func 来一盒麦乐鸡() 一盒麦乐鸡 {} func 垃圾食品打包(一份巨无霸套餐, 一份双层鳕鱼堡套餐, 一盒麦乐鸡) 一袋垃圾食品 {} wire 里面还有个 ProviderSet 的概念，就是把一组 Provider 打包，因为通常你点单的时候很懒，不想这样点你的巨无霸套餐：我要一杯可乐，一包薯条，一个巨无霸汉堡；你想直接戳一下就好了，来一份巨无霸套餐。这个套餐就是 ProviderSet，一组约定好的配方，不然你的点单列表（injector 里的 Build）就会变得超级长，这样你很麻烦，服务员看着也很累。
用其中一个套餐举例
// 先定义套餐内容 var 巨无霸套餐 = wire.NewSet(来一杯可乐，来一包薯条，来一个巨无霸汉堡) // 然后实现各个食品的做法 func 来一杯可乐() 一杯可乐 {} func 来一包薯条() 一包薯条 {} func 来一个巨无霸汉堡() 一个巨无霸汉堡 {} wire 工具做了啥？ 重要的事情说三遍，通过生成代码帮你注入依赖。
在金拱门的例子里就是，wire 就是个服务员，它按照你的订单，去叫做相应的同事把各个食物/套餐做好，然后最终按需求打包给你。这个中间协调构建的过程，就是注入依赖。
这样的好处就是， 对于金拱门，假设他们突然换可乐供应商了，直接把来一杯可乐替换掉就行，返回一种新的可乐，而对于顾客不需要有啥改动。 对于顾客来说，点单内容可以变换，比如我今天不想要麦乐鸡了，或者想加点别的，只要改动我的点单(只要金拱门能做得出来)，然后通过 wire 重新去生成即可，不需要关注这个服务员是如何去做这个订单的。
现在你应该大概理解 wire 的用处和好处了。
总结 让我们从金拱门回来，重新总结一下用 wire 做依赖注入的过程。
1. 定义 Injector 创建wire.go文件，定义下你最终想用的实例初始化函数例如initApp（即 Injector），定好它返回的东西*App，在方法里用panic(wire.Build(NewRedis, SomeProviderSet, NewApp))罗列出它依赖哪些实例的初始化方法（即 Provider）/或者哪些组初始化方法（ProviderSet）
2. 定义 ProviderSet（如果有的话） ProviderSet 就是一组初始化函数，是为了少写一些代码，能够更清晰的组织各个模块的依赖才出现的。也可以不用，但 Injector 里面的东西就需要写一堆。 像这样 var SomeProviderSet = wire.NewSet(NewES,NewDB)定义 ProviderSet 里面包含哪些 Provider
3. 实现各个 Provider Provider 就是初始化方法，你需要自己实现，比如 NewApp，NewRedis，NewMySQL，GetConfig 等，注意他们们各自的输入输出
4. 生成代码 执行 wire 命令生成代码，工具会扫描你的代码，依照你的 Injector 定义来组织各个 Provider 的执行顺序，并自动按照 Provider 们的类型需求来按照顺序执行和安排参数传递，如果有哪些 Provider 的要求没有满足，会在终端报出来，持续修复执行 wire，直到成功生成wire_gen.go文件。接下来就可以正常使用initApp来写你后续的代码了。
如果需要替换实现，对 Injector 进行相应的修改，实现必须的 Provider，重新生成即可。
它生成的代码其实就是类似我们之前需要手写的这个
func initApp() *App { // injector c := GetRedisConf() // provider r := NewRedis(c) // provider app := NewApp(r) // provider return app } 由于我们的例子比较简单，通过 wire 生成体现不出优势，但如果我们的软件复杂，有很多层级的依赖，使用 wire 自动生成注入逻辑，无疑更加方便和准确。
5. 高级用法 wire 还有更多功能，比如 cleanup, bind 等等，请参考官方文档来使用。
最后，其实多折腾几次，就会使用了，希望本文能对您起到一定程度上的帮助。
文章转自 https://go-kratos.dev/blog/go-project-wire</content></entry><entry><title>从kratos分析breaker熔断器源码实现</title><url>https://www.zhaohaiyu.com/post/microservice/breaker/</url><categories><category>microservice</category><category>go</category></categories><tags/><content type="html"> 为什么要用熔断 前面我们讲过限流保证服务的可用性，不被突如其来的流量打爆。但是两种情况是限流解决不了的。
如果我们服务只能处理1000QPS，但是有10wQPS打过来，服务还是会炸。因为拒绝请求也需要成本。 服务但是io型的，会把mysql，redis，mq等中间件打挂。 所以，我们遵循一个思路，可不可以client端在失败的多的时候就不调用了，直接返回错误呢？
什么是熔断 熔断器是为了当依赖的服务已经出现故障时，主动阻止对依赖服务的请求。保证自身服务的正常运行不受依赖服务影响，防止雪崩效应。
源码分析 源码地址 https://github.com/go-kratos/aegis/tree/main/circuitbreaker CircuitBreaker 接口 type CircuitBreaker interface { Allow() error MarkSuccess() MarkFailed() } Allow() 判断熔断器是否允许通过 MarkSuccess() 熔断器成功的回调 MarkFailed() 熔断器失败的回调 Group 结构体 type Group struct { mutex sync.Mutex val atomic.Value New func() CircuitBreaker } mutex 互斥锁，使val这个map不产生数据竞争 val map，存储name -> CircuitBreaker New 生成一个CircuitBreaker Get方法 // Get . func (g *Group) Get(name string) CircuitBreaker { m, ok := g.val.Load().(map[string]CircuitBreaker) if ok { breaker, ok := m[name] if ok { return breaker // 很具name从val拿出 breaker 如果存在返回 } } // slowpath for group don`t have specified name breaker. g.mutex.Lock() nm := make(map[string]CircuitBreaker, len(m)+1) for k, v := range m { nm[k] = v } breaker := g.New() nm[name] = breaker // 如果不存在 生成一个 并放入map 并返回 g.val.Store(nm) g.mutex.Unlock() return breaker } Breaker 结构体 // Breaker is a sre CircuitBreaker pattern. type Breaker struct { stat window.RollingCounter r *rand.Rand // rand.New(...) returns a non thread safe object randLock sync.Mutex // Reducing the k will make adaptive throttling behave more aggressively, // Increasing the k will make adaptive throttling behave less aggressively. k float64 request int64 state int32 } stat 滑动窗口，记录成功失败 r 随机数 randLock 读写锁 k 成功系数 total(总数) = success * k request 请求数 当总数 &lt; request时，不判断是否熔断 state 熔断器状态 打开或者关闭 Allow()方法 // Allow request if error returns nil. func (b *Breaker) Allow() error { success, total := b.summary() // 从活动窗口获取成功数和总数 k := b.k * float64(success) // 根据k成功系数 获取 // check overflow requests = K * success if total &lt; b.request || float64(total) &lt; k { // 如果总数&lt;request 或者 总数 &lt; k if atomic.LoadInt32(&amp;b.state) == StateOpen { atomic.CompareAndSwapInt32(&amp;b.state, StateOpen, StateClosed) // 如果state是打开 关闭 } return nil } if atomic.LoadInt32(&amp;b.state) == StateClosed { atomic.CompareAndSwapInt32(&amp;b.state, StateClosed, StateOpen) // 如果state是关闭 打开 } dr := math.Max(0, (float64(total)-k)/float64(total+1)) // 获取系数，当k越大 dr越小 drop := b.trueOnProba(dr) // trueOnProba 获取水机数 // 返回是否&lt;dr if drop { // 如果是 拒绝请求 return circuitbreaker.ErrNotAllowed } return nil } func (b *Breaker) trueOnProba(proba float64) (truth bool) { b.randLock.Lock() truth = b.r.Float64() &lt; proba b.randLock.Unlock() return } 使用trueOnProba的原因是，当熔断器关闭时，随机让一部分请求通过，当success越大，请求的通过的数量就越多。用这些数据成功与否，放入窗口统计，当成功数达到要求时，就可以关闭熔断器了。
MarkSuccess()以及MarkFailed()方法 // MarkSuccess mark requeest is success. func (b *Breaker) MarkSuccess() { b.stat.Add(1) // 成功数+1 } // MarkFailed mark request is failed. func (b *Breaker) MarkFailed() { // NOTE: when client reject requets locally, continue add counter let the // drop ratio higher. b.stat.Add(0) // 失败数+1 } 流程图</content></entry><entry><title>从kratos分析BBR限流源码实现</title><url>https://www.zhaohaiyu.com/post/microservice/overload/</url><categories><category>microservice</category><category>go</category></categories><tags/><content type="html"> 什么是自适应限流 自适应限流从整体维度对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。
核心目标：
自动嗅探负载和 qps，减少人工配置 削顶，保证超载时系统不被拖垮，并能以高水位 qps 继续运行 限流规则 计算吞吐量：利特尔法则 L = λ * W
如上图所示，如果我们开一个小店，平均每分钟进店 2 个客人(λ)，每位客人从等待到完成交易需要 4 分钟(W)，那我们店里能承载的客人数量就是 2 * 4 = 8 个人
同理，我们可以将 λ 当做 QPS， W 呢是每个请求需要花费的时间，那我们的系统的吞吐就是 L = λ * W ，所以我们可以使用利特尔法则来计算系统的吞吐量。
指标介绍 指标名称 指标含义 cpu 最近 1s 的 CPU 使用率均值，使用滑动平均计算，采样周期是 250ms inflight 当前处理中正在处理的请求数量 pass 请求处理成功的量 rt 请求成功的响应耗时 滑动窗口 在自适应限流保护中，采集到的指标的时效性非常强，系统只需要采集最近一小段时间内的 qps、rt 即可，对于较老的数据，会自动丢弃。为了实现这个效果，kratos 使用了滑动窗口来保存采样数据。
如上图，展示了一个具有两个桶（bucket）的滑动窗口（rolling window）。整个滑动窗口用来保存最近 1s 的采样数据，每个小的桶用来保存 500ms 的采样数据。 当时间流动之后，过期的桶会自动被新桶的数据覆盖掉，在图中，在 1000-1500ms 时，bucket 1 的数据因为过期而被丢弃，之后 bucket 3 的数据填到了窗口的头部。
限流公式 判断是否丢弃当前请求的算法如下：
cpu > 800 AND (Now - PrevDrop) &lt; 1s AND (MaxPass * MinRt * windows / 1000) &lt; InFlight MaxPass 表示最近 5s 内，单个采样窗口中最大的请求数。 MinRt 表示最近 5s 内，单个采样窗口中最小的响应时间。 windows 表示一秒内采样窗口的数量，默认配置中是 5s 50 个采样，那么 windows 的值为 10。
源码分析 代码地址： https://github.com/go-kratos/aegis/tree/main/ratelimit/bbr BBR struct type BBR struct { cpu cpuGetter passStat window.RollingCounter rtStat window.RollingCounter inFlight int64 bucketPerSecond int64 bucketSize time.Duration // prevDropTime defines previous start drop since initTime prevDropTime atomic.Value maxPASSCache atomic.Value minRtCache atomic.Value opts *options } cpu cpu的指标函数，CPU的使用率， 这里为了减小误差，把数字扩大化，乘以1000，比赛使用率60%，也就是0.6 cpu的值就为600 passStat 请求数的采样数据，使用滑动窗口进行统计 rtStat 响应时间的采样数据，同样使用滑动窗口进行统计 inFlight 当前系统中的请求数，数据得来方法是：中间件原理在处理前+1，处理handle之后不管成功失败都减去1 bucketPerSecond 一个 bucket 的时间 bucketSize 桶的数量 prevDropTime 上次触发限流时间 maxPASSCache 单个采样窗口中最大的请求数的缓存数据 minRtCache 单个采样窗口中最小的响应时间的缓存数据 Allow接口 // Allow checks all inbound traffic. // Once overload is detected, it raises limit.ErrLimitExceed error. func (l *BBR) Allow(ctx context.Context) (func(), error) { if l.shouldDrop() { // shouldDrop 判断是否需要限流，如果true表示拒绝 之后重点讲 return nil, ErrLimitExceed } atomic.AddInt64(&amp;l.inFlight, 1) // 之前说的，正在处理数+1 stime := time.Since(initTime) // 现在时间减去程序初始化时间 表示程序开始执行时刻 return func() { // allow返回函数 在中间件（拦截器）中handle执行完成后调用 rt := int64((time.Since(initTime) - stime) / time.Millisecond) // 执行完handle的时间减去stime 表示 程序执行的总时间 单位ms l.rtStat.Add(rt) // 把处理时间放进采样数据window atomic.AddInt64(&amp;l.inFlight, -1) // 正在处理数-1 便是处理完成 l.passStat.Add(1) // 成功了，把通过数的采样数据window加1 }, nil } shouldDrop方法 func (l *BBR) shouldDrop() bool { curTime := time.Since(initTime) if l.cpu() &lt; l.opts.CPUThreshold { // current cpu payload below the threshold prevDropTime, _ := l.prevDropTime.Load().(time.Duration) if prevDropTime == 0 { // haven't start drop, // accept current request return false } if curTime-prevDropTime &lt;= time.Second { // just start drop one second ago, // check current inflight count inFlight := atomic.LoadInt64(&amp;l.inFlight) return inFlight > 1 &amp;&amp; inFlight > l.maxInFlight() } l.prevDropTime.Store(time.Duration(0)) return false } // current cpu payload exceeds the threshold inFlight := atomic.LoadInt64(&amp;l.inFlight) drop := inFlight > 1 &amp;&amp; inFlight > l.maxInFlight() if drop { prevDrop, _ := l.prevDropTime.Load().(time.Duration) if prevDrop != 0 { // already started drop, return directly return drop } // store start drop time l.prevDropTime.Store(curTime) } return drop } maxInFlight()方法代表过去的负载
int64(math.Floor(float64(l.maxPASS()*l.minRT()*l.bucketPerSecond)/1000.0) + 0.5) 参考算法：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81
maxPass * bucketPerSecond / 1000 为每毫秒处理的请求数 l.minRT() 为 单个采样窗口中最小的响应时间 T ≈ QPS * Avg(RT) + 0.5为向上取整 流程图 压测报告 场景1，请求以每秒增加1个的速度不停上升，压测效果如下：
左测是没有限流的压测效果，右侧是带限流的压测效果。 可以看到，没有限流的场景里，系统在 700qps 时开始抖动，在 1k qps 时被拖垮，几乎没有新的请求能被放行，然而在使用限流之后，系统请求能够稳定在 600 qps 左右，rt 没有暴增，服务也没有被打垮，可见，限流有效的保护了服务。
参考文章：
https://v1.go-kratos.dev/#/ratelimit https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81</content></entry><entry><title>mysql redo log和binlog</title><url>https://www.zhaohaiyu.com/post/database/mysql-redolog-binlog/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> 更新语句执行流程 下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：
create table T(ID int primary key, c int); 如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：
update T set c=c+1 where ID=2; 前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。
通过连接器，客户端与 MySQL 建立连接 update 语句会把 T 表上的所有查询缓存结果清空 分析器会通过词法分析和语法分析识别这是一条更新语句 优化器会决定使用 ID 这个索引（聚簇索引） 执行器负责具体执行，找到匹配的一行，然后更新 更新过程中还会涉及 redo log（重做日志）和 binlog（归档日志）的操作 其中，这两种日志默认在数据库的 data 目录下，redo log 是 ib_logfile0 格式的，binlog 是 xxx-bin.000001 格式的。
接下来让我们分别去研究下日志模块中的 redo log 和 binlog。
日志模块：redo log 在 MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就采用了日志（redo log）来提升更新效率。
而日志和磁盘配合的整个过程，其实就是 MySQL 里的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。
具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（redolog buffer）里面，并更新内存（buffer pool），这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候（如系统空闲时），将这个操作记录更新到磁盘里面（刷脏页）。
redo log 是 InnoDB 存储引擎层的日志，又称重做日志文件，redo log 是循环写的，redo log 不是记录数据页更新之后的状态，而是记录这个页做了什么改动。
redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么日志总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下图所示。
图中展示了一组 4 个文件的 redo log 日志，checkpoint 是当前要擦除的位置，擦除记录前需要先把对应的数据落盘（更新内存页，等待刷脏页）。write pos 到 checkpoint 之间的部分可以用来记录新的操作，如果 write pos 和 checkpoint 相遇，说明 redolog 已满，这个时候数据库停止进行数据库更新语句的执行，转而进行 redo log 日志同步到磁盘中。checkpoint 到 write pos 之间的部分等待落盘（先更新内存页，然后等待刷脏页）。
有了 redo log 日志，那么在数据库进行异常重启的时候，可以根据 redo log 日志进行恢复，也就达到了 crash-safe。
redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
日志模块：binlog MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。
为什么要有两份日志系统？
因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。
redo log 和 binlog 区别：
redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是在某个数据页上做了什么修改；binlog 是逻辑日志，记录的是这个语句的原始逻辑。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。追加写是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 有了对这两个日志的概念性理解后，再来看执行器和 InnoDB 引擎在执行这个 update 语句时的内部流程。
执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存（InnoDB Buffer Pool）中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。
两阶段提交 MySQL 使用两阶段提交主要解决 binlog 和 redo log 的数据一致性的问题。
由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。
仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？
**先写 redo log 后写 binlog。**假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 **先写 binlog 后写 redo log。**如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。
参考文章 https://time.geekbang.org/column/article/68633</content></entry><entry><title>SQL查询语句执行流程</title><url>https://www.zhaohaiyu.com/post/database/mysql-exec-order/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> msyql执行流程 你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：：
select * from T where ID=10； 我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。
下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。
大体上，MySQL 分为 Server 层和存储引擎层两部分。
Server 层包括连接器、查询缓存、分析器、执行器等，以及所有的内置函数（如日期、时间、数学和加密函数等）和跨存储引擎的功能（如存储过程、触发器、视图）。
存储引擎层负责数据的存储和提取，支持 InnoDB、MyISAM、Memory 等多个存储引擎。MySQL 5.5.5 版本后默认存储存储引擎是 InnoDB。
连接器 验证账号密码是否正确 到权限表里面查出你拥有的权限，之后的执行语句，都会依赖这个权限数据。 查询缓存 在建立连接后，就开始执行 select 语句了，执行前首先会查询缓存。
MySQL 拿到查询请求后，会先查询缓存，看是不是执行过这条语句。执行过的语句及其结果会以 key-value 对的形式保存在一定的内存区域中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个value 就会被直接返回给客户端。
如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，会提升效率。
但是查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。如果业务中需要有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。MySQL 提供了这种按需使用的方式。可以将参数 query_cache_type 设置成 DEMAND，对于默认的 SQL 语句都将不使用查询缓存。
MySQL 8.0 版本将查询缓存的功能删除了。
分析器 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。
分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。
如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。
elect * from t where ID=1; /* ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1 */ 优化器 经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。
优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：
select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。 执行器 MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。
开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。
select * from T where ID=10; /* ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T' */ 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。
比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：
调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 对于有索引的表，第一次调用的是取满足条件的第一行这个接口，之后循环取满足条件的下一行这个接口。
数据库的慢查询日志中有 rows_examined 字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。
总结 主要通过对一个 SQL 语句完整执行过程进行讲解，介绍 MySQL 的逻辑架构，MySQL 主要包括连接器、查询缓存、分析器、优化器、执行器这几个模块。
参考文章 https://time.geekbang.org/column/article/68319</content></entry><entry><title>mysql事务</title><url>https://www.zhaohaiyu.com/post/database/mysql-transaction/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> 事务是什么 事务就是指逻辑上的一组SQL语句操作，组成这组操作的各个SQL语句，执行时要么全成功要么全失败。
在 MySQL 中，事务支持是在引擎层实现的。MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。
比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一
事务的四大特性 原子性(Atomicity) 事务是一个不可分割的单位，事务中的所有SQL等操作要么都发生，要么都不发生。 一致性(Consistency) 事务发生前和发生后，数据的完整性必须保持一致。 隔离性(Isolation) 当并发访问数据库时，一个正在执行的事务在执行完毕前，对于其他的会话是不可见的，多个并发事务之间的数据是相互隔离的。也就是其他人的操作在这个事务的执行过程中是看不到这个事务的执行结果的，也就是他们拿到的是这个事务执行之前的内容，等这个事务执行完才能拿到新的数据。 持久性(Durability) 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。如果出了错误，事务也不允撤销，只能通过&rsquo;补偿性事务&rsquo;。 事务的开启 开启:
begin/start transaction 执行第一个语句是开启事务
start transaction with consistent snapshot 直接开启事务
隐性事务：set autocommit=0，这个命令会将这个线程的自动提交关掉。
意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。
提交:commit
回滚:rollback
在事务中混合使用存储引擎 MySQL服务器层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中，使用多种存储引擎是不可靠的。
如果在事务中混合使用了事务型和非事务型的表（例如innodb和myisam表），在正常提交的情况下不会有什么问题。
但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致的状态，这种情况很难修复，事务的最终结果将无法确定。
所以，为每张表选择合适的存储引擎非常重要。
在非事务型的表上执行事务相关操作的时候，MySQL通常不会发出提醒，也不会报错。有时候只有回滚的时候才会发出一个警告：&ldquo;某些非事务型的表上的变更不能被回滚&rdquo;。
但大多数情况下，对非事务型表的操作都不会有提示。
脏读 幻读 不可重复读 脏读 所谓脏读是指一个事务中访问到了另外一个事务未提交的数据，如下图：
s1 s2 begin begin update test set number = 100 where id = 1; select number from test where id = 1; commit commit 如果会话 2 更新 number 为 100，但是在 number 之前，会话 1 希望得到 number，那么会获得的值就是更新前的值。或者如果会话 2 更新了值但是执行了 rollback，而会话 1 拿到的仍是 100。这就是脏读。 不可重复读 一个事务查询同一条记录2次，得到的结果不一致：
S1 S2 begin begin; select number from test where id = 1; update test set number = 200 where id = 1; commit select number from test where id = 1; commit; 由于在读取中间变更了数据，所以会话 1 事务查询期间的得到的结果就不一样了。 幻读 一个事务查询2次，得到的记录条数不一致：
S1 S2 begin begin select number from test where id &lt; 5; insert into test value(2,3); commit select number from test where id &lt; 5; commit 幻读是不可重复读的一种特殊场景。 事务的隔离级别 MySQL 里有四个隔离级别：
READ UNCOMMITTED（读未提交） 在read uncommitted级别，事务中的修改 ，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也被称为脏读。
这个级别会导致很多问题，从性能上来说，read uncommitted不会比其他的级别好太多，但却缺乏其他级别的很多好处，除非真个有非常必要的理由，在实际应用中一般很少使用。
READ COMMITTED（提已提交） 大多数数据库系统的默认隔离级别都是READ COMMITTED（但MySQL不是）。
READ COMMITTED满足前面提到的隔离性的简单定义：一个事务开始时，只能看见已经提交的事务所做的修改。
换句话说，一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的，这个级别有时候也叫做不可重复读。
不可重复读现象：当事务内相同的记录被检索两次，且两次得到的结果不同时，此现象成为不可重复读。
REPEATABLE READ（读可重复读） REPEATABLE READ解决了脏读的问题。该级别保证了在同一个事务中多次读取同样记录的结果是一致的。但是理论上，可重复读隔离级别还是无法解决另外一个幻读的问题。
所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。
可重复读是MySQL的默认事务隔离级别。
SERIZLIZABLE（可串行化） SERIZLIZABLE是最高的隔离级别。它通过强制事务串行执行，避免了前面说的幻读的问题。
简单来说，SERIZLIZABLE会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用的问题。
实际应用中也很少用到这个隔离级别，只有在非常需要确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。
不同事务隔离级别的效果： 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED（未提交读） ✅ ✅ ✅ READ COMMITTED（提已提交） ❎ ✅ ✅ REPEATABLE READ（可重复读） ❎ ❎ ✅ SERIZLIZABLE（可串行化） ❎ ❎ ✅ 在 InnoDB 中，默认为 Repeatable 级别，InnoDB 中使用一种被称为 next-key locking 的策略来避免幻读（phantom）现象的产生。
隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。
事务隔离的实现 隔离级别为默认可重复读
在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。 记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。
当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。 如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4， 同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。 对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现， 即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的
参考文章 https://time.geekbang.org/column/article/70562</content></entry><entry><title>mysql锁</title><url>https://www.zhaohaiyu.com/post/database/mysql-lock/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> MySQL中的锁 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。
根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类
全局锁 全局锁就是对整个数据库实例加锁。
MySQL提供了一个加全局读锁的方法，命令是Flush tables with read lock。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句
全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都select出来存成文本
但是让整个库都只读，可能出现以下问题：
如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的binlog，会导致主从延迟 在可重复读隔离级别下开启一个事务能够拿到一致性视图
官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。single-transaction只适用于所有的表使用事务引擎的库
既然要全库只读，为什么不使用set global readonly=true的方式？
在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此修改global变量的方式影响面更大 在异常处理机制上有差异。如果执行Flush tables with read lock命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高
表级锁 MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。
在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。
如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。
事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。
行锁 MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。
不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。
当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。
两阶段锁 这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。
事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
死锁和死锁检测 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁
事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。
当出现死锁以后，有两种策略：
一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。
你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。那如果是我们上面说到的所有事务都要更新同一行的场景呢？
每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。
间隙锁 为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。
顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。
这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。
也就是说，跟行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。
举个例子：
这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。
next-key lock 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。
备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。
这个 supremum 从哪儿来的呢？这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”。
参考文章 https://time.geekbang.org/column/article/69862</content></entry><entry><title>Kratos日志库的使用姿势</title><url>https://www.zhaohaiyu.com/post/microservice/kratos-log/</url><categories><category>microservice</category><category>go</category></categories><tags/><content type="html"> 什么是日志 所谓日志（Log）是指系统所指定对象的某些操作和其操作结果按时间有序的集合。log文件就是日志文件，log文件记录了系统和系统的用户之间交互的信息，是自动捕获人与系统终端之间交互的类型、内容或时间的数据收集方法。
日志是用来记录，用户操作，系统状态，错误信息等等内容的文件，是一个软件系统的重要组成部分。一个良好的日志规范，对于系统运行状态的分析，以及线上问题的解决具有重大的意义。
日志规范 在开发软件打印日志时，需要注意一些问题，举例可能不全，可以自行百度相关文章或查看文章底部文献：
重要功能日志尽可能的完善。 不要随意打印无用的日志，过多无用的日志会增加分析日志的难度。 日志要区分等级 如 debug，warn，info，error 等。 捕获到未处理错误时最好打印错误堆栈信息 Go 语言常用的日志库 Go 语言标准库中就为我们提供了一个日志库 log，除了这个以外还有很多日志库，如 logrus，glog，logx，Uber 的 zap 等等，例如 zap 就有很多的优点：
高性能
配置项丰富
多种日志级别
支持Hook
丰富的工具包
提供了sugar log
多种日志打印格式
&hellip;
简单使用 package main import ( "errors" "go.uber.org/zap" ) var logger *zap.Logger func init() { logger, _ = zap.NewProduction() } func main() { logger.Error( "My name is baobao", zap.String("from", "Hulun Buir"), zap.Error(errors.New("no good"))) logger.Info("Worked in the Ministry of national development of China!", zap.String("key", "eat🍚"), zap.String("key", "sleep😴")) defer logger.Sync() } Kratos 日志库原理解析 在私下与 Tony老师 沟通时关于日志库的实现理念时，Tony老师 说：由于目前日志库非常多并且好用，在 Kratos 的日志中，主要考虑以下几个问题：
统一日志接口设计 组织结构化日志 并且需要有友好的日志级别使用 支持多输出源对接需求，如log-agent 或者 3rd 日志库 kratos 的日志库，不强制具体实现方式，只提供适配器，用户可以自行实现日志功能，只需要实现kratos/log 的 Logger interface 即可接入自己喜欢的日志系统。
kratos 的日志库，在设计阶段，参考了很多优秀的开源项目和大厂的日志系统实现，经历了多次改动后才呈现给大家。
log库的组成 kratos 的 log 库主要由以下几个文件组成
level.go 定义日志级别
log.go 日志核心
helper.go log的helper
value.go 实现动态值
源码分析 kratos 的 log 库中, 核心部分就是 log.go 代码非常简洁，符合 kratos 的设计理念。 log.go 中声明了 Logger interface，用户只需要实现接口，即可引入自己的日志实现，主要代码如下：
log.go package log import ( "context" "log" ) var ( // DefaultLogger is default logger. DefaultLogger Logger = NewStdLogger(log.Writer()) ) // Logger 接口, 后面实现自定义日志库的时候，就是要实现这个接口。 type Logger interface { Log(level Level, keyvals ...interface{}) error } type logger struct { logs []Logger // logger 数组 prefix []interface{} // 一些默认打印的值,例如通过 With 绑定的 Valuer hasValuer bool // 是否包含 Valuer ctx context.Context // 上下文 } func (c *logger) Log(level Level, keyvals ...interface{}) error { kvs := make([]interface{}, 0, len(c.prefix)+len(keyvals)) kvs = append(kvs, c.prefix...) // 判断是否存在 valuer if c.hasValuer { // 绑定 valuer bindValues(c.ctx, kvs) } kvs = append(kvs, keyvals...) // 遍历 logs，调用所有的 logger 进行日志打印。 for _, l := range c.logs { if err := l.Log(level, kvs...); err != nil { return err } } return nil } // With with logger fields. func With(l Logger, kv ...interface{}) Logger { // 判断是否能 把传入的 logger 断言成 *logger if c, ok := l.(*logger); ok { // 预分配内存,make了一个空间长度为 c.prefix + keyvals长度的 interface数组 kvs := make([]interface{}, 0, len(c.prefix)+len(kv)) // 处理打印的内容 kvs = append(kvs, kv...) kvs = append(kvs, c.prefix...) // containsValuer()用来判断 kvs 里面是否存在 valuer return &amp;logger{ logs: c.logs, prefix: kvs, hasValuer: containsValuer(kvs), ctx: c.ctx, } } return &amp;logger{logs: []Logger{l}, prefix: kv, hasValuer: containsValuer(kv)} } // WithContext 绑定 ctx,注意 ctx 必须非空 func WithContext(ctx context.Context, l Logger) Logger { if c, ok := l.(*logger); ok { return &amp;logger{ logs: c.logs, prefix: c.prefix, hasValuer: c.hasValuer, ctx: ctx, } } return &amp;logger{logs: []Logger{l}, ctx: ctx} } // MultiLogger 包装多个logger，简单说就是同时使用多个logger打印 func MultiLogger(logs ...Logger) Logger { return &amp;logger{logs: logs} } value.go // 返回 valuer 函数. func Value(ctx context.Context, v interface{}) interface{} { if v, ok := v.(Valuer); ok { return v(ctx) } return v } // ...省略一些内置的 valuer 实现 // 绑定 valuer func bindValues(ctx context.Context, keyvals []interface{}) { for i := 1; i &lt; len(keyvals); i += 2 { if v, ok := keyvals[i].(Valuer); ok { keyvals[i] = v(ctx) } } } // 是否包含 valuer func containsValuer(keyvals []interface{}) bool { for i := 1; i &lt; len(keyvals); i += 2 { if _, ok := keyvals[i].(Valuer); ok { return true } } return false } helper.go package log import ( "context" "fmt" ) // Helper is a logger helper. type Helper struct { logger Logger } // 创建一个 logger helper 实例 func NewHelper(logger Logger) *Helper { return &amp;Helper{ logger: logger, } } // 通过 WithContext() 返回包含 ctx 的一个日志的帮助类，包含一些定义好的按级别打印日志的方法 func (h *Helper) WithContext(ctx context.Context) *Helper { return &amp;Helper{ logger: WithContext(ctx, h.logger), } } func (h *Helper) Log(level Level, keyvals ...interface{}) { h.logger.Log(level, keyvals...) } func (h *Helper) Debug(a ...interface{}) { h.logger.Log(LevelDebug, "msg", fmt.Sprint(a...)) } func (h *Helper) Debugf(format string, a ...interface{}) { h.logger.Log(LevelDebug, "msg", fmt.Sprintf(format, a...)) } // ...省略一些重复的方法 通过单元测试了解调用逻辑 func TestInfo(t *testing.T) { logger := DefaultLogger logger = With(logger, "ts", DefaultTimestamp, "caller", DefaultCaller) logger.Log(LevelInfo, "key1", "value1") } 单测中首先声明了一个 logger ，用的默认的 DefaultLogger
调用 log.go 中的 With() 函数， 传入了 logger ,和两个动态值， DefaultTimestamp 和 DefaultCaller。
With方法被调用，判断是否能将参数 l 类型转换成 *logger
如果可以转换，将传入的KV，赋值给 logger.prefix 上，然后调用 value.go 中的 containsValuer() 判断传入的KV中是否存在 Valuer类型的值，将结果赋值给 context.hasValuer，最后返回 Logger 对象
否则则直接返回一个 &amp;logger{logs: []Logger{l}, prefix: kv, hasValuer: containsValuer(kv)}
然后打印日志时，logger struct 的 Log 方法被调用
Log() 方法首先预分配了 keyvals 的空间，然后判断 hasValuer，如果为 true，则调用 valuer.go 中的 bindValuer() 并传入了 ctx 然后获取 valuer 的值`if v, ok := v.(Valuer); ok {
return v() }`
8.最后遍历 logger.logs 打印日志
使用方法 使用 Logger 打印日志 logger := log.DefaultLogger logger.Log(LevelInfo, "key1", "value1") 使用 Helper 打印日志 log := log.NewHelper(DefaultLogger) log.Debug("test debug") log.Info("test info") log.Warn("test warn") log.Error("test error") 使用 valuer logger := DefaultLogger logger = With(logger, "ts", DefaultTimestamp, "caller", DefaultCaller) logger.Log(LevelInfo, "msg", "helloworld") 同时打印多个 logger out := log.NewStdLogger(os.Stdout) err := log.NewStdLogger(os.Stderr) l := log.With(MultiLogger(out, err)) l.Log(LevelInfo, "msg", "test") 使用 context logger := log.With(NewStdLogger(os.Stdout), "trace", Trace(), ) log := log.NewHelper(logger) ctx := context.WithValue(context.Background(), "trace_id", "2233") log.WithContext(ctx).Info("got trace!") 使用 filter 过滤日志 如果需要过滤日志中某些不应该被打印明文的字段如 password 等，可以通过 log.NewFilter() 来实现过滤功能。
通过 level 过滤日志 l := log.NewHelper(log.NewFilter(log.DefaultLogger, log.FilterLevel(log.LevelWarn))) l.Log(LevelDebug, "msg1", "te1st debug") l.Debug("test debug") l.Debugf("test %s", "debug") l.Debugw("log", "test debug") l.Warn("warn log") 通过 key 过滤日志 l := log.NewHelper(log.NewFilter(log.DefaultLogger, log.FilterKey("password"))) l.Debugw("password", "123456") 通过 value 过滤日志 l := log.NewHelper(log.NewFilter(log.DefaultLogger, log.FilterValue("kratos"))) l.Debugw("name", "kratos") 通过 hook func 过滤日志 l := log.NewHelper(log.NewFilter(log.DefaultLogger, log.FilterFunc(testFilterFunc))) l.Debug("debug level") l.Infow("password", "123456") func testFilterFunc(level Level, keyvals ...interface{}) bool { if level == LevelWarn { return true } for i := 0; i &lt; len(keyvals); i++ { if keyvals[i] == "password" { keyvals[i+1] = "***" } } return false } 用 Zap 实现 kratos 的日志接口 实现的代码十分简单，仅有不到100 行代码，仅供大家参考。
实现 // kratos/examples/log/zap.go package logger import ( "fmt" "os" "github.com/go-kratos/kratos/v2/log" "go.uber.org/zap" "go.uber.org/zap/zapcore" "gopkg.in/natefinch/lumberjack.v2" ) var _ log.Logger = (*ZapLogger)(nil) // Zap 结构体 type ZapLogger struct { log *zap.Logger Sync func() error } // 创建一个 ZapLogger 实例 func NewZapLogger(encoder zapcore.EncoderConfig, level zap.AtomicLevel, opts ...zap.Option) *ZapLogger { writeSyncer := getLogWriter() // 设置 zapcore core := zapcore.NewCore( zapcore.NewConsoleEncoder(encoder), zapcore.NewMultiWriteSyncer( zapcore.AddSync(os.Stdout), ), level) // new 一个 *zap.Logger zapLogger := zap.New(core, opts...) return &amp;ZapLogger{log: zapLogger, Sync: zapLogger.Sync} } // Log 方法实现了 kratos/log/log.go 中的 Logger interface func (l *ZapLogger) Log(level log.Level, keyvals ...interface{}) error { if len(keyvals) == 0 || len(keyvals)%2 != 0{ l.log.Warn(fmt.Sprint("Keyvalues must appear in pairs: ", keyvals)) return nil } // 按照 KV 传入的时候,使用的 zap.Field var data []zap.Field for i := 0; i &lt; len(keyvals); i += 2 { data = append(data, zap.Any(fmt.Sprint(keyvals[i]), fmt.Sprint(keyvals[i+1]))) } switch level { case log.LevelDebug: l.log.Debug("", data...) case log.LevelInfo: l.log.Info("", data...) case log.LevelWarn: l.log.Warn("", data...) case log.LevelError: l.log.Error("", data...) } return nil } // 日志自动切割，采用 lumberjack 实现的 func getLogWriter() zapcore.WriteSyncer { lumberJackLogger := &amp;lumberjack.Logger{ Filename: "./test.log", MaxSize: 10, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } 使用方法 // kratos/examples/log/zap_test.go package logger import ( "testing" "github.com/go-kratos/kratos/v2/log" "go.uber.org/zap" "go.uber.org/zap/zapcore" ) func TestZapLogger(t *testing.T) { encoder := zapcore.EncoderConfig{ TimeKey: "t", LevelKey: "level", NameKey: "logger", CallerKey: "caller", MessageKey: "msg", StacktraceKey: "stack", EncodeTime: zapcore.ISO8601TimeEncoder, LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, EncodeDuration: zapcore.SecondsDurationEncoder, EncodeCaller: zapcore.FullCallerEncoder, } logger := NewZapLogger( encoder, zap.NewAtomicLevelAt(zapcore.DebugLevel), zap.AddStacktrace( zap.NewAtomicLevelAt(zapcore.ErrorLevel)), zap.AddCallerSkip(2), zap.Development(), ) zlog := log.NewHelper(logger) zlog.Infow("name","go 语言进阶") defer logger.Sync() } 参考文献 关于 log 库的讨论 issue Uber 的日志库 Zap uber/zap 日志割接库 lumberjack 基于 zap 的日志demo log example</content></entry><entry><title>RabbitMQ消息队列</title><url>https://www.zhaohaiyu.com/post/database/rabbitmq/</url><categories><category>database</category></categories><tags><tag>mq</tag></tags><content type="html"> 消息队列 本篇文章主要介绍了 RabbitMQ 这种消息队列，从消息队列的概念、应用场景、安装方式到它的核心概念、五种工作模式。在安装的时候推荐使用 Docker 方式进行安装。重点需要理解的就是消息队列的应用场景、核心概念和 RabbitMQ 的五种工作模式，其中用的比较多的就是发布订阅模式、主题模式。
队列 (Queue) 是一种常见的数据结构，其最大的特性就是先进先出(Firist In First Out)，作为最基础的数据结构，队列应用很广泛，比如我们熟知的 Redis 基础数据类型 List，其底层数据结构就是队列。
消息队列 (Messaeg Queue) 是一种使用队列 (Queue) 作为底层存储数据结构，可用于解决不同进程与应用之间通讯的分布式消息容器，也称为消息中间件。
目前使用得比较多的消息队列有 ActiveMQ，RabbitMQ，Kafka，RocketMQ 等。本文主要讲述的是 RabbitMQ，RabbitMQ 是用 Erlang 语言开发的一个实现了 AMQP 协议的消息队列服务器，相比其他同类型的消息队列，最大的特点在保证可观的单机吞吐量的同时，延时方面非常出色。
RabbitMQ 支持多种客户端，比如：GO、Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等。
AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。这里是 AMQP 官网 amqp.org 消息队列使用广泛，其应用场景有很多，下面我们列举比较常见的四个场景：
1、消息通讯 消息队列最主要功能收发消息，其内部有高效的通讯机制，因此非常适合用于消息通讯。
我们可以基于消息队列开发点对点聊天系统，也可以开发广播系统，用于将消息广播给大量接收者。
2、异步处理 一般我们写的程序都是顺序执行 (同步执行)，比如一个用户注册函数，其执行顺序如下：
1、写入用户注册数据。 2、发送注册邮件。 3、发送注册成功的短信通知。 4、更新统计数据。 按照上面的执行顺序，要全部执行完毕，才能返回成功，但其实在第 1 步执行成功后，其他的步骤完全可以异步执行，我们可以将后面的逻辑发给消息队列，再由其他程序异步执行。使用消息队列进行异步处理，可以更快地返回结果，加快服务器的响应速度，提升了服务器的性能。
3、服务解耦 在我们的系统中，应用与应用之间的通讯是很常见的，一般我们应用之间直接调用，比如说应用 A 调用应用 B 的接口，这时候应用之间的关系是强耦合的。
如果应用 B 处于不可用的状态，那么应用 A 也会受影响。
在应用 A 与应用 B 之间引入消息队列进行服务解耦，如果应用 B 挂掉，也不会影响应用 A 的使用。
4、流量削峰 对于高并发的系统来说，在访问高峰时，突发的流量就像洪水般向应用系统涌过来，尤其是一些高并发写操作，随时会导致数据库服务器瘫痪，无法继续提供服务。
而引入消息队列则可以减少突发流量对应用系统的冲击。消息队列就像水库一样，拦蓄上游的洪水，削减进入下游河道的洪峰流量，从而达到减免洪水灾害的目的。而在旱季水流量小的时候又可以把水放出来灌溉庄稼。
这方面最常见的例子就是秒杀系统，一般秒杀活动瞬间流量很高，如果流量全部涌向秒杀系统，会压垮秒杀系统，通过引入消息队列，可以有效缓冲突发流量，达到削峰填谷的作用。
安装 Docker 安装方式如下：
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management RabbitMQ 有属于自己的一套核心概念，对这些概念的理解很重要，只有理解了这些核心概念，才有可能建立对 RabbitMQ 的全面理解：
RabbitMQ核心概念 Broker Broker 概念比较简单，我们可以把 Broker 理解为一个 RabitMQ Server。
Producer 与 Consumer 生产者与消费者相对于 RabbitMQ 服务器来说，都是 RabbitMQ 服务器的客户端。
生产者 (Producer)：连到 RabbitMQ 服务器，将消息发送到 RabbitMQ 服务器的队列，是消息的发送方。 消费者 (Consumer)：连接到 RabbitMQ 则是为了消费队列中的消息，是消息的接收方。 生产者与消费者一般由我们的应用程序充当。
Connection Connection 是 RabbitMQ 内部对象之一，用于管理每个到 RabbitMQ 的 TCP 网络连接。
Channel Channel 是我们与 RabbitMQ 打交道的最重要的一个接口，我们大部分的业务操作是在 Channel 这个接口中完成的，包括定义 Queue、定义 Exchange、绑定 Queue 与 Exchange、发布消息等。
Exchnage 消息交换机，作用是接收来自生产者的消息，并根据路由键转发消息到所绑定的队列。
生产者发送上的消息，就是先通过 Exchnage 按照绑定 (binding) 规则转发到队列的。
交换机类型 (Exchange Type) 有四种：fanout、direct、topic，headers，其中 headers 并不常用。
fanout：这种类型不处理路由键 (RoutingKey)，很像子网广播，每台子网内的主机都获得了一份复制的消息，发布 / 订阅模式就是指使用 fanout 交换机类型，fanout 类型交换机转发消息是最快的。 direct：模式处理路由键，需要路由键完全匹配的队列才能收到消息，路由模式使用的是 direct 类型的交换机。 topic：将路由键和某模式进行匹配。主题模式使用的是 topic 类型的交换机。 路由模式，发布订阅模式，主题模式，这些工作模式我们下面会讲。
Queue Queue 即队列，RabbitMQ 内部用于存储消息的对象，是真正用存储消息的结构，在生产端，生产者的消息最终发送到指定队列，而消费者也是通过订阅某个队列，达到获取消息的目的。
Binding Binding 是一种操作，其作用是建立消息从 Exchange 转发到 Queue 的规则，在进行 Exchange 与 Queue 的绑定时，需要指定一个 BindingKey，Binding 操作一般用于 RabbitMQ 的路由工作模式和主题工作模式。
BindingKey 的概念，下面在讲 RabbitMQ 的工作模式会详细讲解。
Virtual Host Virutal host 也叫虚拟主机，一个 VirtualHost 下面有一组不同 Exchnage 与 Queue，不同的 Virtual host 的 Exchnage 与 Queue 之间互相不影响。应用隔离与权限划分，Virtual host 是 RabbitMQ 中最小颗粒的权限单位划分。
如果要类比的话，我们可以把 Virtual host 比作 MySQL 中的数据库，通常我们在使用 MySQL 时，会为不同的项目指定不同的数据库，同样的，在使用 RabbitMQ 时，我们可以为不同的应用程序指定不同的 Virtual host。
请参考：www.rabbitmq.com/getstarted.… 简单 (simple) 模式 simple 模式，是 RabbitMQ 几种模式中最简单的一种模式，其结构如下图所示：
从上面的示意图，我们可以看出simple模式有以下几个特征：
只有一个生产者、一个消费者和一个队列。 生产者和消费者在发送和接收消息时，只需要指定队列名，而不需要指定发送到哪个 Exchange，RabbitMQ 服务器会自动使用 Virtual host 的默认的 Exchange，默认 Exchange 的 type 为 direct。 package main // 引入amqo包 import ( "fmt" "github.com/streadway/amqp" "log" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func Pushlish() { // 创建链接 url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() // 打开一个通道 ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() // 生成一个交换机（交换机不存在的情况下） err = ch.ExchangeDeclare("test","direct", true,false,false, false, nil) failOnError(err, "Failed to declare an exchange") // 生成一个队列队列（队列不存在的情况下） _, err = ch.QueueDeclare("test1", true, false, false, false, nil) failOnError(err, "Failed to declare an queue") //列队与交换机绑定 err = ch.QueueBind("test1", "zhaohaiyu", "test", false, nil) failOnError(err, "Bind queue to exchange failure") //指定交换机发布消息 err = ch.Publish("test", "zhaohaiyu", false, false, amqp.Publishing{ ContentType: "text/plain", Body: []byte("生产者测试1"), }) failOnError(err, "Message publish failure") } func Get() { // 创建链接 url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() // 打开一个通道 ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() // 指定队列获取消息 msg, ok, err := ch.Get("test1", true) failOnError(err, "Message empty") fmt.Println(string(msg.Body), ok) } func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { Pushlish() Get() } /* 结果：产者测试1 true */ 工作 (work) 模式 在 simple 模式下只有一个生产者和消费者，当生产者生产消息的速度大于消费者的消费速度时，我们可以添加一个或多个消费者来加快消费速度，这种在 simple 模式下增加消费者的模式，称为 work 模式，如下图所示：
work 模式有以下两个特征：
可以有多个消费者，但一条消息只能被一个消费者获取。 发送到队列中的消息，由服务器平均分配给不同消费者进行消费 package main // 引入amqo包 import ( "fmt" "github.com/streadway/amqp" "log" "time" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func Pushlish() { // 创建链接 url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() // 打开一个通道 ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() // 生成一个交换机（交换机不存在的情况下） err = ch.ExchangeDeclare("test","direct", true,false,false, false, nil) failOnError(err, "Failed to declare an exchange") // 生成一个队列队列（队列不存在的情况下） _, err = ch.QueueDeclare("test1", true, false, false, false, nil) failOnError(err, "Failed to declare an queue") //列队与交换机绑定 err = ch.QueueBind("test1", "zhaohaiyu", "test", false, nil) failOnError(err, "Bind queue to exchange failure") //指定交换机发布消息 for { time.Sleep(time.Second) err = ch.Publish("test", "zhaohaiyu", false, false, amqp.Publishing{ ContentType: "text/plain", Body: []byte("生产者测试1"), }) failOnError(err, "Message publish failure") } } func Get1() { // 创建链接 url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() // 打开一个通道 ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() // 指定队列获取消息 for { time.Sleep(time.Second) msg, ok, err := ch.Get("test1", true) failOnError(err, "Message empty") fmt.Println("Get1", string(msg.Body), ok) } } func Get2() { // 创建链接 url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() // 打开一个通道 ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() // 指定队列获取消息 for { time.Sleep(time.Second) msg, ok, err := ch.Get("test1", true) failOnError(err, "Message empty") fmt.Println("Get2", string(msg.Body), ok) } } func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { go Pushlish() go Get1() go Get2() time.Sleep(time.Second * 20) } /* 结果：Get1 false Get2 生产者测试1 true Get2 false Get1 生产者测试1 true Get1 false Get2 生产者测试1 true Get2 false Get1 生产者测试1 true Get1 生产者测试1 true Get2 false Get2 false Get1 生产者测试1 true Get2 false Get1 生产者测试1 true Get2 false Get1 生产者测试1 true Get1 生产者测试1 true Get2 false Get2 false Get1 生产者测试1 true Get1 生产者测试1 true Get2 false Get1 生产者测试1 true Get2 false Get2 false Get1 生产者测试1 true Get2 false Get1 生产者测试1 true Get1 生产者测试1 true Get2 false Get1 生产者测试1 true Get2 false Get2 生产者测试1 true Get1 false Get2 false Get1 生产者测试1 true Get1 生产者测试1 true Get2 false */ 发布 / 订阅 (pub/sub) 模式 work 模式可以将消息转到多个消费者，但每条消息只能由一个消费者获取，如果我们想一条消息可以同时给多个消费者消费呢？
这时候就需要发布 / 订阅模式，其示意图如下所示：
从上面的示意图我们可以看出来，在发布 / 订阅模式下，需要指定发送到哪个 Exchange 中，上面图中的 X 表示 Exchange。
发布 / 订阅模式中，Echange 的 type 为 fanout。 生产者发送消息时，不需要指定具体的队列名，Exchange 会将收到的消息转发到所绑定的队列。 消息被 Exchange 转到多个队列，一条消息可以被多个消费者获取。 在上图中，oneQueue 中的消息要么被 CustomerA 获取，要么被 CustomerB 获取。也就是同一条消息，要么是 CustomerA + CustomerC 消费、要么是 CustomerB + CustomerC 消费。
生产者：
package main import ( "fmt" "github.com/streadway/amqp" "log" "os" "strings" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) //url := fmt.Sprintf() func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { conn, err := amqp.Dial(fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST)) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare( "logs", // name "fanout", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare an exchange") body := bodyFrom(os.Args) err = ch.Publish( "logs", // exchange "", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: "text/plain", Body: []byte(body), }) failOnError(err, "Failed to publish a message") log.Printf(" [x] Sent %s", body) } func bodyFrom(args []string) string { var s string if (len(args) &lt; 2) || os.Args[1] == "" { s = "hello" } else { s = strings.Join(args[1:], " ") } return s } 不同的 Exchange 之间互不影响，相同 Exchange，相同队列的情况下，消息均等消费：
package main import ( "fmt" "github.com/streadway/amqp" "log" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { conn, err := amqp.Dial(fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST)) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare( "logs", // name "fanout", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare an exchange") q, err := ch.QueueDeclare( "", // name false, // durable false, // delete when unused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare a queue") err = ch.QueueBind( q.Name, // queue name "", // routing key "logs", // exchange false, nil, ) failOnError(err, "Failed to bind a queue") msgs, err := ch.Consume( q.Name, // queue "", // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, "Failed to register a consumer") forever := make(chan bool) go func() { for d := range msgs { log.Printf(" [x] %s", d.Body) } }() log.Printf(" [*] Waiting for logs. To exit press CTRL+C") &lt;-forever } 相同 Exchange，不同队列的情况下，一条消息可以被多个消费者获取。
路由 (routing) 模式 前面几种模式，消息的目标队列无法由生产者指定，而在路由模式下，消息的目标队列，可以由生产者指定，其示意图如下所示：
路由模式下Exchange的 type 为direct。 消息的目标队列可以由生产者按照routingKey规则指定。 消费者通过BindingKey绑定自己所关心的队列。 一条消息队可以被多个消息者获取。 只有RoutingKey与BidingKey相匹配的队列才会收到消息。 RoutingKey用于生产者指定Exchange最终将消息路由到哪个队列，BindingKey用于消费者绑定到某个队列。
生产者：
package main import ( "fmt" "log" "os" "strings" "github.com/streadway/amqp" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { conn, err := amqp.Dial(fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST)) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare( "logs_direct", // name "direct", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare an exchange") body := bodyFrom(os.Args) err = ch.Publish( "logs_direct", // exchange severityFrom(os.Args), // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: "text/plain", Body: []byte(body), }) failOnError(err, "Failed to publish a message") log.Printf(" [x] Sent %s", body) } func bodyFrom(args []string) string { var s string if (len(args) &lt; 3) || os.Args[2] == "" { s = "hello" } else { s = strings.Join(args[2:], " ") } return s } func severityFrom(args []string) string { var s string if (len(args) &lt; 2) || os.Args[1] == "" { s = "info" } else { s = os.Args[1] } return s } 消费者：
package main import ( "fmt" "log" "os" "github.com/streadway/amqp" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { conn, err := amqp.Dial(fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST)) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare( "logs_direct", // name "direct", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare an exchange") q, err := ch.QueueDeclare( "", // name false, // durable false, // delete when unused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare a queue") if len(os.Args) &lt; 2 { log.Printf("Usage: %s [info] [warning] [error]", os.Args[0]) os.Exit(0) } for _, s := range os.Args[1:] { log.Printf("Binding queue %s to exchange %s with routing key %s", q.Name, "logs_direct", s) err = ch.QueueBind( q.Name, // queue name s, // routing key "logs_direct", // exchange false, nil) failOnError(err, "Failed to bind a queue") } msgs, err := ch.Consume( q.Name, // queue "", // consumer true, // auto ack false, // exclusive false, // no local false, // no wait nil, // args ) failOnError(err, "Failed to register a consumer") forever := make(chan bool) go func() { for d := range msgs { log.Printf(" [x] %s", d.Body) } }() log.Printf(" [*] Waiting for logs. To exit press CTRL+C") &lt;-forever } 主题 (Topic) 模式 主题模式是在路由模式的基础上，将路由键和某模式进行匹配。其中#表示匹配多个词，*表示匹配一个词，消费者可以通过某种模式的 BindKey 来达到订阅某个主题消息的目的，如示意图如下所示：
主题模式 Exchange 的 type 取值为 topic。 一条消息可以被多个消费者获取。 package main import ( "fmt" "github.com/streadway/amqp" "log" "time" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func publish() { url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare("testTopic", amqp.ExchangeTopic, true, false, false, false, nil) failOnError(err, "Failed to declare an exchange") for i := 0; i &lt; 10; i++ { err = ch.Publish("testTopic", "yuemoxi", false, false, amqp.Publishing{ ContentType: "text/plain", Body: []byte(fmt.Sprintf("time:%v", time.Now())), }) if err == nil { fmt.Println("发布成功!") } time.Sleep(time.Second) } } func get1() { url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare("testTopic", amqp.ExchangeTopic, true, false, false, false, nil) failOnError(err, "Failed to declare an exchange") q, err := ch.QueueDeclare("testTopic_get1", false, false, false, false, nil) failOnError(err, "Failed to declare a queue") err = ch.QueueBind(q.Name, "yuemox*", "testTopic", false, nil) failOnError(err, "Failed to bind a queue") msgs, err := ch.Consume(q.Name, "get1", true, false, false, false, nil) failOnError(err, "Failed to register a consumer") for msg := range msgs { log.Printf("get1: %s", msg.Body) time.Sleep(time.Millisecond * 500) } } func get2() { url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare("testTopic", amqp.ExchangeTopic, true, false, false, false, nil) failOnError(err, "Failed to declare an exchange") q, err := ch.QueueDeclare("testTopic_get2", false, false, false, false, nil) failOnError(err, "Failed to declare a queue") err = ch.QueueBind(q.Name, "#", "testTopic", false, nil) failOnError(err, "Failed to bind a queue") msgs, err := ch.Consume(q.Name, "get2", true, false, false, false, nil) failOnError(err, "Failed to register a consumer") for msg := range msgs { log.Printf("get2: %s", msg.Body) time.Sleep(time.Millisecond * 500) } } func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { go publish() go get1() go get2() time.Sleep(time.Second * 20) } /* 结果： 发布成功! 2021/08/31 22:45:09 get1: time:2021-08-31 22:45:09.017664 +0800 CST m=+0.012626409 发布成功! 2021/08/31 22:45:10 get2: time:2021-08-31 22:45:10.022005 +0800 CST m=+1.016996649 2021/08/31 22:45:10 get1: time:2021-08-31 22:45:10.022005 +0800 CST m=+1.016996649 发布成功! 2021/08/31 22:45:11 get2: time:2021-08-31 22:45:11.023542 +0800 CST m=+2.018558384 2021/08/31 22:45:11 get1: time:2021-08-31 22:45:11.023542 +0800 CST m=+2.018558384 发布成功! 2021/08/31 22:45:12 get1: time:2021-08-31 22:45:12.028649 +0800 CST m=+3.023687209 2021/08/31 22:45:12 get2: time:2021-08-31 22:45:12.028649 +0800 CST m=+3.023687209 发布成功! 2021/08/31 22:45:13 get2: time:2021-08-31 22:45:13.033497 +0800 CST m=+4.028553608 2021/08/31 22:45:13 get1: time:2021-08-31 22:45:13.033497 +0800 CST m=+4.028553608 发布成功! 2021/08/31 22:45:14 get1: time:2021-08-31 22:45:14.03647 +0800 CST m=+5.031571881 2021/08/31 22:45:14 get2: time:2021-08-31 22:45:14.03647 +0800 CST m=+5.031571881 发布成功! 2021/08/31 22:45:15 get2: time:2021-08-31 22:45:15.036783 +0800 CST m=+6.031867631 2021/08/31 22:45:15 get1: time:2021-08-31 22:45:15.036783 +0800 CST m=+6.031867631 发布成功! 2021/08/31 22:45:16 get2: time:2021-08-31 22:45:16.041189 +0800 CST m=+7.036283180 2021/08/31 22:45:16 get1: time:2021-08-31 22:45:16.041189 +0800 CST m=+7.036283180 发布成功! 2021/08/31 22:45:17 get1: time:2021-08-31 22:45:17.043382 +0800 CST m=+8.038484117 2021/08/31 22:45:17 get2: time:2021-08-31 22:45:17.043382 +0800 CST m=+8.038484117 发布成功! 2021/08/31 22:45:18 get1: time:2021-08-31 22:45:18.04643 +0800 CST m=+9.041536815 2021/08/31 22:45:18 get2: time:2021-08-31 22:45:18.04643 +0800 CST m=+9.041536815 */ 延迟队列 什么是延迟队列 延时队列，首先，它是一种队列，队列意味着内部的元素是有序的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。
其次，延时队列，最重要的特性就体现在它的延时属性上，跟普通的队列不一样的是，普通队列中的元素总是等着希望被早点取出处理，而延时队列中的元素则是希望被在指定时间得到取出和处理，所以延时队列中的元素是都是带时间属性的，通常来说是需要被处理的消息或者任务。
简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。
使用场景 订单在十分钟之内未支付则自动取消。 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 账单在一周内未支付，则自动结算。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。 rabbitMQ中的TTL 在介绍延时队列之前，还需要先介绍一下RabbitMQ中的一个高级特性——TTL（Time To Live）。
TTL是什么呢？TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。
如何利用rabbitMQ实现延迟队列 想想看，延时队列，不就是想要消息延迟多久被处理吗，TTL则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就万事大吉了，因为里面的消息都是希望被立即处理的消息。
从下图可以大致看出消息的流向：
生产者生产一条延时消息，根据需要延时时间的不同，利用不同的routingkey将消息路由到不同的延时队列，每个队列都设置了不同的TTL属性，并绑定在同一个死信交换机中，消息过期后，根据routingkey的不同，又会被路由到不同的死信队列中，消费者只需要监听对应的死信队列进行处理即可。
go实现
package main import ( "fmt" "github.com/streadway/amqp" "log" "time" ) const ( LOGIN string = "zhaohaiyu" PASSWORD string = "zhy.1996" HOST string = "127.0.0.1" PORT string = "5672" VIRTUALHOST string = "/" ) func publish() { url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare("testTopic", amqp.ExchangeTopic, true, false, false, false, nil) failOnError(err, "Failed to declare an exchange") for i := 0; i &lt; 10; i++ { err = ch.Publish("testTopic", "yuemoxi", false, false, amqp.Publishing{ ContentType: "text/plain", Body: []byte(fmt.Sprintf("time:%v", time.Now())), Expiration: "600000", }) if err == nil { fmt.Println("发布成功!") } time.Sleep(time.Second) } } func get2() { url := fmt.Sprintf("amqp://%s:%s@%s:%s%s", LOGIN, PASSWORD, HOST, PORT, VIRTUALHOST) conn, err := amqp.Dial(url) failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() err = ch.ExchangeDeclare("testTopic", amqp.ExchangeTopic, true, false, false, false, nil) failOnError(err, "Failed to declare an exchange") q, err := ch.QueueDeclare("testTopic_get2", false, false, false, false, nil) failOnError(err, "Failed to declare a queue") //声明延时队列队列，该队列中消息如果过期，就将消息发送到交换器上，交换器就分发消息到普通队列 q1, err := ch.QueueDeclare( "test_delay", //队列名 true, //持久化 false, //不用时是否自动删除 true, false, amqp.Table{ //当消息过期时把消息发送到logs这个交换器 "x-dead-letter-exchange": "ttlTopic", "x-dead-letter-routing-key": "ttlKey", }, ) failOnError(err, "Failed to bind a queue") err = ch.QueueBind(q.Name, "#", "testTopic", false, nil) failOnError(err, "Failed to bind a queue") err = ch.QueueBind( q1.Name, "ttlKey", "ttlTopic", false, nil, ) msgs, err := ch.Consume(q.Name, "get2", true, false, false, false, nil) failOnError(err, "Failed to register a consumer") for msg := range msgs { log.Printf("get2: %s", msg.Body) time.Sleep(time.Millisecond * 500) } } func failOnError(err error, msg string) { if err != nil { log.Fatalf("%s: %s", msg, err) } } func main() { go publish() go get2() time.Sleep(time.Second * 20) } 参考文章 https://juejin.cn/post/6916148736414466061 rabbitmq官网 https://www.cnblogs.com/mfrank/p/11260355.html</content></entry><entry><title>grpc超时控制</title><url>https://www.zhaohaiyu.com/post/microservice/grpc-timeout/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>protobuf</tag><tag>grpc</tag></tags><content type="html"> 什么是超时控制？ 超时控制，使我们的服务之间调用可以快速抛错。比如API接口设置1s超时API调用A服务用了500ms，服务A调用和服务B用了600ms，n那么现在已经超时，还要调用服务C等等，再返回超时错误吗？这回事使服务C后面的链路做了无用功，浪费服务器资源。
GRPC的截止时间 截止时间以请求开始的绝对时间来表示（即使 API 将它们表示为持续时间偏移），并且应 用于多个服务调用。发起请求的应用程序设置截止时间，整个请求链需要在截止时间之前 进行响应。 gRPC API 支持为 RPC 使用截止时间，出于多种原因，在 gRPC 应用程序中使 用截止时间始终是一种最佳实践。由于 gRPC 通信是在网络上发生的，因此在 RPC 和响应 之间会有延迟。另外，在一些特定的场景中， gRPC 服务本身可能要花费更多的时间来响 应，这取决于服务的业务逻辑。如果客户端应用程序在开发时没有指定截止时间，那么它 们会无限期地等待自己所发起的 RPC 请求的响应，而资源都会被正在处理的请求所占用。 这会让服务和客户端都面临资源耗尽的风险，增加服务的延迟，甚至可能导致整个 gRPC 服务崩溃。
客户端应用程序的截止时间设置为 50 毫秒（截止时间 = 当前时间 + 偏移量）。客户端和 ProductMgt 服务之间的网络延迟为 0 毫秒， ProductMgt 服务的处理延迟为 20 毫秒。 商 品管理服务（ ProductMgt 服务）必须将截止时间的偏移量设置为 30 毫秒。 因为库存服 务（ Inventory 服务）需要 30 毫秒来响应， 所以截止时间的事件会在两个客户端上发生 （ ProductMgt 调用 Inventory 服务和客户端应用程序）。
ProductMgt 服务的业务逻辑将延迟时间增加了 20 毫秒。 随后， ProductMgt 服务的调用逻 辑触发了超出截止时间的场景，并且传播回客户端应用程序。因此，在使用截止时间时， 要明确它们适用于所有服务场景。
conn, err := grpc.Dial(address, grpc.WithInsecure()) if err != nil { log.Fatalf("did not connect: %v", err) } defer conn.Close() client := pb.NewOrderManagementClient(conn) clientDeadline := time.Now().Add( time.Duration(2 * time.Second)) ctx, cancel := context.WithDeadline(context.Background(), clientDeadline) defer cancel() // 调用方法传入ctx</content></entry><entry><title>grpc服务发现与负载均衡</title><url>https://www.zhaohaiyu.com/post/microservice/grpc-servicediscovery-loadbalancing/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>protobuf</tag><tag>grpc</tag></tags><content type="html"> 前言 在后台服务开发中，高可用性是构建中核心且重要的一环。服务发现（Service discovery）和负载均衡（Load Balance）一直都是我关注的话题。今天来谈一下我在实际中是如何理解及落地的。
负载均衡 &amp;&amp; 服务发现 基础 负载均衡 ，顾名思义，是通过某种手段将流量 / 请求分配到不通的服务器上去，保证后台的每个服务收到的请求都尽可能保持平衡 服务发现 ，就是指客户端按照某种约定的方式主动去（注册中心）寻找服务，然后再连接相应的服务 关于负载均衡的构建与实现，可以看下这几篇文章：
gRPC 服务发现 &amp; 负载均衡 gRPC Load Balancing Load Balancing in gRPC 服务发现概念 我们说的服务发现，一般理解为客户端如何发现 (并连接到) 服务，这里一般包含三个组件：
服务消费者：一般指客户端（可以是简单的 TCP-Client 或者是 RPC-Client ） 服务提供者：一般指服务提供方，如传统服务，微服务等 服务注册中心：用来存储（Key-Value）服务提供者的服务，一般以 DNS/HTTP/RPC 等方式对外暴露接口 负载均衡概念 我们把 LB 看作一个组件，根据组件位置的不同，大致上分为三种：
集中式 LB（Proxy Model） 独立的 LB, 可以是硬件实现，如 F5，或者是 nginx 这种内置 Proxy-pass 或者 upstream 功能的网关，亦或是 LVS/HAPROXY，之前也使用 DPDK 开发过类似的专用网关。
进程内 LB（Balancing-aware Client） 进程内 LB（集成到客户端），此方案将 LB 的功能集成到服务消费方进程里，也被称为软负载或者客户端负载方案。服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，相当于健康检查，服务消费方要访问某个服务时，它通过内置的 LB 组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求。LB 和服务发现能力被分散到每一个服务消费者的进程内部，同时服务消费方和服务提供方之间是直接调用，没有额外开销，性能比较好。
独立 LB 进程（External Load Balancing Service） 该方案是针对上一种方案的不足而提出的一种折中方案，原理和第二种方案基本类似。不同之处是将 LB 和服务发现功能从进程内移出来，变成主机上的一个独立进程。主机上的一个或者多个服务要访问目标服务时，他们都通过同一主机上的独立 LB 进程做服务发现和负载均衡。该方案也是一种分布式方案没有单点问题，一个 LB 进程挂了只影响该主机上的服务调用方，服务调用方和 LB 之间是进程内调用性能好，同时该方案还简化了服务调用方，不需要为不同语言开发客户库，LB 的升级不需要服务调用方改代码。 公司的 L5 是这种方式，每台机器上都安装了 L5 的 agent，供其他服务调用。该方案主要问题：部署较复杂，环节多，出错调试排查问题不方便。
gRPC 内置的方案 gRPC 的内置方案如下图所示：
gRPC 在官网文档中提供了实现 LB 的思路，并在不同语言的 gRPC 代码 API 中已提供了命名解析和负载均衡接口供扩展。默认提供了 DNS-resolver 的实现，接口相当规范，实现起来也不复杂，只需要实现服务注册（Registry）和服务监听 + 解析（Watcher+Resolver）的逻辑就行了，这里简单介绍其基本实现过程：
构建注册中心，这里注册中心一般要求具备分布式一致性（满足 CAP 定理的 AP 或 CP）的高可用的组件集群，如 Zookeeper、Consul、Etcd 等 构建 gRPC 服务端的注册逻辑，服务启动后定时向注册中心注册自身的关键信息（一般开启新的 groutine 来完成），至少包含 IP 和端口，其他可选信息，如自身的负载信息（CPU 和 Memory）、当前实时连接数等，这些辅助信息有助于帮助系统更好的执行 LB 算法 gRPC 客户端向注册中心发出服务解析请求，注册中心将请求中关联的所有服务的信息返回给 gRPC 客户端，客户端与所有在线的服务建立起 HTTP2 长连接 gRPC 客户端发起 RPC 调用，根据 LB 均衡器中实现的负载均衡策略（gRPC 中默认提供的算法是 RoundRobin），选择其中一 HTTP2 长连接进行通信，即 LB 策略决定哪个子通道 - 即哪个 gRPC 服务器将接收请求 gRPC 负载均衡的运行机制 gRPC 提供了负载均衡实现的用户侧接口，我们可以非常方便的定制化业务的负载均衡策略，为了理解 gRPC 的负载均衡的实现机制，后续博客中我会分析下 gRPC 实现负载均衡的代码。
Resolver 解析器，用于从注册中心实时获取当前服务端的列表，同步发送给 Balancer Balancer 平衡器，一是接收从 Resolver 发送的服务端列表，建立并维护（长）连接状态；二是每次当 Client 发起 Rpc 调用时，按照一定算法从连接池中选择一个连接进行 Rpc 调用 Register 注册，用于服务端初始化和在线时，将自己信息上报到注册中心，主要信息有 Ip，端口等 负载均衡的算法及实现 在实践中，如何选取负载均衡策略是一个很有趣的话题，例如 Nginx 的 upstream 机制中就有很多经典的 LB 策略，如带权重的轮询 Weight-RoundRobin ，一般常用的负载均衡方法有如下几种：
RoundRobin（轮询） Weight-RoundRobin（加权轮询） 不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。 Random（随机） Weight-Random（加权随机） 通过系统的随机算法，根据后端服务器的列表随机选取其中的一台服务器进行访问 源地址哈希法 源地址哈希的思想是根据获取客户端的 IP 地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一 IP 地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问 最小连接数法 最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器 一致性哈希算法 常见的是 Ketama 算法，该算法是用来解决 cache 失效导致的缓存穿透的问题的，当然也可以适用于 gRPC 长连接的场景 gRPC 服务治理的优势 在现网环境中，后端服务就是采用了 gRPC 与 Etcd 的服务治理方案，总结下有这么几个优点；
采用了 gRPC 实现负载均衡策略，模块之间通信采用长连接方式，避免每次 RPC 调用时新建连接的开销，充分发挥 HTTP2 的优势 扩容和缩容都及其方便，例如扩容，只要部署上服务，运行后，服务成功注册到 Etcd 便大功告成 灵活的自定义的 LB 算法，使得后端压力更为均衡 客户端加入重试逻辑，使得网络抖动情况下，可以通过重试连接上另外一台服务 Resolver 暴露的三个接口 前文说过，gRPC 内置的服务治理功能，对开发者暴露了服务发现的 interface{}，resolver.Builder 和 resolver.ClientConn 和 resolver.Resolver，相关代码 。开发者在实例化这三个接口之后，就可以实现从指定的 scheme 中获取服务列表，通知 balancer 并与这些服务端建立 RPC 长连接。
resolver.Builder resolver.ClientConn resolver.Resolver resolver.Builder Builder 用于 gRPC 内部创建 Resolver 接口的实现，但注意内部声明的 Build() 方法将接口 ClientConn 作为参数传入了，在前文的分析中，我们了解到 ClientConn结库 是非常重要的结构，其成员 conns map[*addrConn]struct{} 中维护了所有从注册中心获取到的服务端列表。 // Builder creates a resolver that will be used to watch name resolution updates. type Builder interface { // Build creates a new resolver for the given target. // // gRPC dial calls Build synchronously, and fails if the returned error is // not nil. Build(target Target, cc ClientConn, opts BuildOption) (Resolver, error) // Scheme returns the scheme supported by this resolver. // Scheme is defined at https://github.com/grpc/grpc/blob/master/doc/naming.md. Scheme() string } resolver.ClientConn ClientConn 接口中，UpdateState 方法需要传入 State 结构，NewAddress 方法需要传入 Address 结构，看代码可以发现其中包含了 Addresses []Address // Resolved addresses for the target，可以看出是需要将服务发现得到的 Address 对象列表告诉 ClientConn 的对象。 // ClientConn contains the callbacks for resolver to notify any updates // to the gRPC ClientConn. // // This interface is to be implemented by gRPC. Users should not need a // brand new implementation of this interface. For the situations like // testing, the new implementation should embed this interface. This allows // gRPC to add new methods to this interface. type ClientConn interface { // UpdateState updates the state of the ClientConn appropriately. UpdateState(State) // NewAddress is called by resolver to notify ClientConn a new list // of resolved addresses. // The address list should be the complete list of resolved addresses. // // Deprecated: Use UpdateState instead. NewAddress(addresses []Address) // NewServiceConfig is called by resolver to notify ClientConn a new // service config. The service config should be provided as a json string. // // Deprecated: Use UpdateState instead. NewServiceConfig(serviceConfig string) } resolver.Resolver Resolver 提供了 ResolveNow 用于被 gRPC 尝试重新进行服务发现 // Resolver watches for the updates on the specified target. // Updates include address updates and service config updates. type Resolver interface { // ResolveNow will be called by gRPC to try to resolve the target name // again. It's just a hint, resolver can ignore this if it's not necessary. // // It could be called multiple times concurrently. ResolveNow(ResolveNowOption) // Close closes the resolver. Close() } 梳理 Resolver 过程 通过这三个接口，再次梳理下 gRPC 的服务发现实现逻辑
通过 Builder.Build() 进行 Reslover 的创建，在 Build() 的过程中将服务发现的地址信息丢给 ClientConn 用于内部连接创建（通过 ClientConn.UpdateState() 实现）等逻辑； 当 client 在 Dial 时会根据 target 解析的 scheme 获取对应的 Builder，代码位置 func DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) { ... ... // Determine the resolver to use. cc.parsedTarget = parseTarget(cc.target) grpclog.Infof("parsed scheme: %q", cc.parsedTarget.Scheme) resolverBuilder := cc.getResolver(cc.parsedTarget.Scheme) // 通过 scheme(名字) 获取对应的 resolver if resolverBuilder == nil { // If resolver builder is still nil, the parsed target's scheme is // not registered. Fallback to default resolver and set Endpoint to // the original target. grpclog.Infof("scheme %q not registered, fallback to default scheme", cc.parsedTarget.Scheme) cc.parsedTarget = resolver.Target{ Scheme: resolver.GetDefaultScheme(), Endpoint: target, } resolverBuilder = cc.getResolver(cc.parsedTarget.Scheme) if resolverBuilder == nil { return nil, fmt.Errorf("could not get resolver for default scheme: %q", cc.parsedTarget.Scheme) } } ... ... // Build the resolver. rWrapper, err := newCCResolverWrapper(cc, resolverBuilder) // 通过 gRPC 提供的 Wrapper，应用我们实现的 resolver 逻辑 if err != nil { return nil, fmt.Errorf("failed to build resolver: %v", err) } cc.mu.Lock() cc.resolverWrapper = rWrapper cc.mu.Unlock() ... ... } 当 Dial 成功会创建出结构体 ClientConn 的对象 官方代码位置 (注意不是上面的 ClientConn 接口)，可以看到结构体 ClientConn 内的成员 resolverWrapper 又实现了接口 ClientConn 的方法 官方代码位置 func DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) { // 初始化 CC cc := &amp;ClientConn{ target: target, csMgr: &amp;connectivityStateManager{}, conns: make(map[*addrConn]struct{}), dopts: defaultDialOptions(), blockingpicker: newPickerWrapper(), czData: new(channelzData), firstResolveEvent: grpcsync.NewEvent(), } ... ... ... ... return cc, nil } 当 resolverWrapper 被初始化时就会调用 Build 方法 官方代码位置 ，其中参数为接口 ClientConn 传入的是 ccResolverWrapper // newCCResolverWrapper uses the resolver.Builder to build a Resolver and // returns a ccResolverWrapper object which wraps the newly built resolver. func newCCResolverWrapper(cc *ClientConn, rb resolver.Builder) (*ccResolverWrapper, error) { ccr := &amp;ccResolverWrapper{ cc: cc, done: grpcsync.NewEvent(), } var credsClone credentials.TransportCredentials if creds := cc.dopts.copts.TransportCredentials; creds != nil { credsClone = creds.Clone() } rbo := resolver.BuildOptions{ DisableServiceConfig: cc.dopts.disableServiceConfig, DialCreds: credsClone, CredsBundle: cc.dopts.copts.CredsBundle, Dialer: cc.dopts.copts.Dialer, } var err error // We need to hold the lock here while we assign to the ccr.resolver field // to guard against a data race caused by the following code path, // rb.Build-->ccr.ReportError-->ccr.poll-->ccr.resolveNow, would end up // accessing ccr.resolver which is being assigned here. ccr.resolverMu.Lock() defer ccr.resolverMu.Unlock() ccr.resolver, err = rb.Build(cc.parsedTarget, ccr, rbo) if err != nil { return nil, err } return ccr, nil } 当用户基于 Builder 的实现进行 UpdateState 调用时，则会触发结构体 ClientConn 的 updateResolverState 方法 官方代码位置 ，updateResolverState 则会对传入的 Address 进行初始化等逻辑 官方代码位置 func (cc *ClientConn) updateResolverState(s resolver.State, err error) error { defer cc.firstResolveEvent.Fire() cc.mu.Lock() // Check if the ClientConn is already closed. Some fields (e.g. // balancerWrapper) are set to nil when closing the ClientConn, and could // cause nil pointer panic if we don't have this check. if cc.conns == nil { cc.mu.Unlock() return nil } if err != nil { // May need to apply the initial service config in case the resolver // doesn't support service configs, or doesn't provide a service config // with the new addresses. cc.maybeApplyDefaultServiceConfig(nil) if cc.balancerWrapper != nil { cc.balancerWrapper.resolverError(err) } // No addresses are valid with err set; return early. cc.mu.Unlock() return balancer.ErrBadResolverState } var ret error if cc.dopts.disableServiceConfig || s.ServiceConfig == nil { cc.maybeApplyDefaultServiceConfig(s.Addresses) // TODO: do we need to apply a failing LB policy if there is no // default, per the error handling design? } else { if sc, ok := s.ServiceConfig.Config.(*ServiceConfig); s.ServiceConfig.Err == nil &amp;&amp; ok { cc.applyServiceConfigAndBalancer(sc, s.Addresses) } else { ret = balancer.ErrBadResolverState if cc.balancerWrapper == nil { var err error if s.ServiceConfig.Err != nil { err = status.Errorf(codes.Unavailable, "error parsing service config: %v", s.ServiceConfig.Err) } else { err = status.Errorf(codes.Unavailable, "illegal service config type: %T", s.ServiceConfig.Config) } cc.blockingpicker.updatePicker(base.NewErrPicker(err)) cc.csMgr.updateState(connectivity.TransientFailure) cc.mu.Unlock() return ret } } } var balCfg serviceconfig.LoadBalancingConfig if cc.dopts.balancerBuilder == nil &amp;&amp; cc.sc != nil &amp;&amp; cc.sc.lbConfig != nil { balCfg = cc.sc.lbConfig.cfg } cbn := cc.curBalancerName bw := cc.balancerWrapper cc.mu.Unlock() if cbn != grpclbName { // Filter any grpclb addresses since we don't have the grpclb balancer. for i := 0; i &lt;len(s.Addresses); { if s.Addresses[i].Type == resolver.GRPCLB { copy(s.Addresses[i:], s.Addresses[i+1:]) s.Addresses = s.Addresses[:len(s.Addresses)-1] continue } i++ } } uccsErr := bw.updateClientConnState(&amp;balancer.ClientConnState{ResolverState: s, BalancerConfig: balCfg}) if ret == nil { ret = uccsErr // prefer ErrBadResolver state since any other error is // currently meaningless to the caller. } return ret } 至此整个服务发现过程就结束了。从中也可以看出 gRPC 官方提供的三个接口还是很灵活的，但也正因为灵活要实现稍微麻烦一些，而 Address官方代码位置 如果直接被业务拿来用于服务节点信息的描述结构则显得有些过于简单。 所以 warden 包装了 gRPC 的整个服务发现实现逻辑，代码分别位于 pkg/naming/naming.go 和 warden/resolver/resolver.go，其中：
naming.go 内定义了用于描述业务实例的 Instance 结构、用于服务注册的 Registry 接口、用于服务发现的 Resolver 接口 resolver.go 内实现了 gRPC 官方的 resolver.Builder 和 resolver.Resolver 接口，但也暴露了 naming.go 内的 naming.Builder 和 naming.Resolver 接口 文章转自： 基于 gRPC 的服务发现与负载均衡（基础篇） - 熊喵君的博客 | PANDAYCHEN gRPC 应用篇之 Resolver 接口封装 - 熊喵君的博客 | PANDAYCHEN</content></entry><entry><title>Go Gin框架介绍及使用</title><url>https://www.zhaohaiyu.com/post/go/go-gin/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>http</tag></tags><content type="html"> Gin框架介绍 基于httprouter 开发的Web框架。 中文文档 ，齐全。 简单易用的轻量级框架。 Gin框架安装 go get -u github.com/gin-gonic/gin 实例:
package main import ( "fmt" "github.com/gin-gonic/gin" ) func main() { r := gin.Default() // 创建一个默认的路由引擎 // 也可以用gin.New() gin.Default()多用了日志和panic的recover中间件 r.GET("/helloworld", func(c *gin.Context) { c.JSON(200, gin.H{ // c.JSON：返回JSON格式的数据 "msg": "Hello world!", }) }) err := r.Run("127.0.0.1:8001") // 启动HTTP服务，默认在127.0.0.1:8001启动服务 if err != nil { fmt.Println("run gin field") return } } RESTful API REST与技术无关，代表的是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移”或“表现层状态转化”。
简单来说，REST的含义就是客户端与Web服务器之间进行交互的时候，使用HTTP协议中的4个请求方法代表不同的动作。
GET用来获取资源 POST用来新建资源 PUT用来更新资源 DELETE用来删除资源。 只要API程序遵循了REST风格，那就可以称其为RESTful API。目前在前后端分离的架构中，前后端基本都是通过RESTful API来进行交互。
例如，我们现在要编写一个管理书籍的系统，我们可以查询对一本书进行查询、创建、更新和删除等操作，我们在编写程序的时候就要设计客户端浏览器与我们Web服务端交互的方式和路径。按照经验我们通常会设计成如下模式：
请求方法 URL 含义 GET /book 查询书籍信息 POST /create_book 创建书籍记录 POST /update_book 更新书籍信息 POST /delete_book 删除书籍信息 同样的需求我们按照RESTful API设计如下：
请求方法 URL 含义 GET /book 查询书籍信息 POST /book 创建书籍记录 PUT /book 更新书籍信息 DELETE /book 删除书籍信息 Gin框架支持开发RESTful API的开发。
func main() { r := gin.Default() r.GET("/book", func(c *gin.Context) { c.JSON(200, gin.H{ "message": "GET", }) }) r.POST("/book", func(c *gin.Context) { c.JSON(200, gin.H{ "message": "POST", }) }) r.PUT("/book", func(c *gin.Context) { c.JSON(200, gin.H{ "message": "PUT", }) }) r.DELETE("/book", func(c *gin.Context) { c.JSON(200, gin.H{ "message": "DELETE", }) }) } 开发RESTful API的时候我们通常使用Postman 来作为客户端的测试工具。
Gin渲染 HTML渲染 我们首先定义一个存放模板文件的templates文件夹，然后在其内部按照业务分别定义一个posts文件夹和一个users文件夹。posts/index.html文件的内容如下：
{{define "posts/index.html"}} posts/index {{.title}} {{end}} users/index.html文件的内容如下：
{{define "users/index.html"}} users/index {{.title}} {{end}} Gin框架中使用LoadHTMLGlob()或者LoadHTMLFiles()方法进行HTML模板渲染。
func main() { r := gin.Default() r.LoadHTMLGlob("templates/**/*") //r.LoadHTMLFiles("templates/posts/index.html", "templates/users/index.html") r.GET("/posts/index", func(c *gin.Context) { c.HTML(http.StatusOK, "posts/index.html", gin.H{ "title": "posts/index", }) }) r.GET("users/index", func(c *gin.Context) { c.HTML(http.StatusOK, "users/index.html", gin.H{ "title": "users/index", }) }) r.Run(":8080") } 静态文件处理 当我们渲染的HTML文件中引用了静态文件时，我们只需要按照以下方式在渲染页面前调用gin.Static方法即可。
func main() { r := gin.Default() r.Static("/static", "./static") r.LoadHTMLGlob("templates/**/*") ... r.Run(":8080") } 补充文件路径处理 关于模板文件和静态文件的路径，我们需要根据公司/项目的要求进行设置。可以使用下面的函数获取当前执行程序的路径。
func getCurrentPath() string { if ex, err := os.Executable(); err == nil { return filepath.Dir(ex) } return "./" } JSON渲染 func main() { r := gin.Default() // gin.H 是map[string]interface{}的缩写 r.GET("/someJSON", func(c *gin.Context) { // 方式一：自己拼接JSON c.JSON(http.StatusOK, gin.H{"message": "Hello world!"}) }) r.GET("/moreJSON", func(c *gin.Context) { // 方法二：使用结构体 var msg struct { Name string `json:"user"` Message string Age int } msg.Name = "zhy" msg.Message = "Hello world!" msg.Age = 18 c.JSON(http.StatusOK, msg) }) r.Run(":8080") } XML渲染 注意需要使用具名的结构体类型。
func main() { r := gin.Default() // gin.H 是map[string]interface{}的缩写 r.GET("/someXML", func(c *gin.Context) { // 方式一：自己拼接JSON c.XML(http.StatusOK, gin.H{"message": "Hello world!"}) }) r.GET("/moreXML", func(c *gin.Context) { // 方法二：使用结构体 type MessageRecord struct { Name string Message string Age int } var msg MessageRecord msg.Name = "小王子" msg.Message = "Hello world!" msg.Age = 18 c.XML(http.StatusOK, msg) }) r.Run(":8080") } YMAL渲染 r.GET("/someYAML", func(c *gin.Context) { c.YAML(http.StatusOK, gin.H{"message": "ok", "status": http.StatusOK}) }) protobuf渲染 // protobuf文件 syntax = "proto3"; package models; message hello { string content = 1; } package main import ( "net/http" "test/models" "github.com/gin-gonic/gin" ) func main() { r := gin.Default() r.GET("/hello",func (c *gin.Context) { res := &amp;models.Hello{ Content: "你好", } c.ProtoBuf(http.StatusOK,res) }) _ = r.Run("127.0.0.1:8001") } 获取参数 获取querystring参数 querystring指的是URL中?后面携带的参数，例如：/user?username=赵海宇&amp;address=地球一角。
c.DefaultQuery有默认值 如果没有传去默认值 c.Query没有默认值 如果没传 为空 package main import ( "net/http" "github.com/gin-gonic/gin" ) func main() { r := gin.Default() r.GET("/user", func(c *gin.Context) { username := c.DefaultQuery("username", "zhy") address := c.Query("address") c.JSON(http.StatusOK, gin.H{ "username": username, "address": address, }) }) _ = r.Run("127.0.0.1:8001") } 获取form参数 请求的数据通过form表单来提交，例如向/user发送一个POST请求，获取请求数据的方式如下：c.PostForm
package main import ( "net/http" "github.com/gin-gonic/gin" ) func main() { r := gin.Default() r.POST("/user", func(c *gin.Context) { username := c.PostForm("username") address := c.PostForm("address") c.JSON(http.StatusOK, gin.H{ "username": username, "address": address, }) }) _ = r.Run("127.0.0.1:8001") } 获取path参数 请求的参数通过URL路径传递，例如：/user/zhaohaiyu/地球一角/路由:/user/:username/:address方法:c.Param
package main import ( "net/http" "github.com/gin-gonic/gin" ) func main() { r := gin.Default() r.GET("/user/:username/:address", func(c *gin.Context) { username := c.Param("username") address := c.Param("address") c.JSON(http.StatusOK, gin.H{ "username": username, "address": address, }) }) _ = r.Run("127.0.0.1:8001") } 参数绑定 为了能够更方便的获取请求相关参数，提高开发效率，我们可以基于请求的content-type识别请求数据类型并利用反射机制自动提取请求中querystring、form表单、JSON、XML等参数到结构体中。
package main import ( "fmt" "net/http" "github.com/gin-gonic/gin" ) // Binding from JSON type Login struct { User string `form:"user" json:"user" binding:"required"` Password string `form:"password" json:"password" binding:"required"` } func main() { r := gin.Default() // 绑定JSON的示例 ({"user": "root", "password": "123"}) r.POST("/loginJSON", func(c *gin.Context) { var login Login if err := c.ShouldBindJSON(&amp;login); err == nil { fmt.Printf("login info:%#v\n", login) c.JSON(http.StatusOK, login) } else { c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()}) } }) // 绑定form表单示例 (user=root&amp;password=123) r.POST("/loginForm", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(&amp;login); err == nil { c.JSON(http.StatusOK, login) } else { c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()}) } }) // 绑定querystring示例 (user=root&amp;password=123) r.GET("/loginForm", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(&amp;login); err == nil { c.JSON(http.StatusOK, login) } else { c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()}) } }) _ = r.Run("127.0.0.1:8001") } 文件上传 func main() { router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 &lt;&lt; 20 // 8 MiB router.POST("/upload", func(c *gin.Context) { // 单个文件 file, err := c.FormFile("file") if err != nil { c.JSON(http.StatusInternalServerError, gin.H{"message": err.Error()}) return } log.Println(file.Filename) dst := fmt.Sprintf("C:/tmp/%s", file.Filename) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) c.JSON(http.StatusOK, gin.H{"message": fmt.Sprintf("'%s' uploaded!", file.Filename)}) }) router.Run() } 多个文件上传 func main() { router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 &lt;&lt; 20 // 8 MiB router.POST("/upload", func(c *gin.Context) { // Multipart form form, _ := c.MultipartForm() files := form.File["file"] for index, file := range files { log.Println(file.Filename) dst := fmt.Sprintf("C:/tmp/%s_%d", file.Filename, index) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) } c.JSON(http.StatusOK, gin.H{ "message": fmt.Sprintf("%d files uploaded!", len(files)), }) }) router.Run() } Gin中间件 Gin框架允许开发者在处理请求的过程中，加入用户自己的钩子（Hook）函数。这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如登录校验、日志打印、耗时统计等。
Gin中的中间件必须是一个gin.HandlerFunc类型。例如我们像下面的代码一样定义一个中间件。
// StatCost 是一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Set("name", "小王子") // 执行其他中间件 c.Next() // 计算耗时 cost := time.S***art) log.Println(cost) } } 然后注册中间件的时候，可以在全局注册。
func main() { // 新建一个没有任何默认中间件的路由 r := gin.New() // 注册一个全局中间件 r.Use(StatCost()) r.GET("/test", func(c *gin.Context) { name := c.MustGet("name").(string) log.Println(name) c.JSON(http.StatusOK, gin.H{ "message": "Hello world!", }) }) r.Run() } 也可以给某个路由单独注册中间件。
// 给/test2路由单独注册中间件（可注册多个） r.GET("/test2", StatCost(), func(c *gin.Context) { name := c.MustGet("name").(string) log.Println(name) c.JSON(http.StatusOK, gin.H{ "message": "Hello world!", }) }) 重定向 HTTP重定向 HTTP 重定向很容易。 内部、外部重定向均支持。
r.GET("/test", func(c *gin.Context) { c.Redirect(http.StatusMovedPermanently, "http://www.google.com/") }) 路由重定向 路由重定向，使用HandleContext：
r.GET("/test", func(c *gin.Context) { // 指定重定向的URL c.Request.URL.Path = "/test2" r.HandleContext(c) }) r.GET("/test2", func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"hello": "world"}) }) Gin路由 普通路由 r.GET("/index", func(c *gin.Context) {...}) r.GET("/login", func(c *gin.Context) {...}) r.POST("/login", func(c *gin.Context) {...}) 此外，还有一个可以匹配所有请求方法的Any方法如下：
r.Any("/test", func(c *gin.Context) {...}) 为没有配置处理函数的路由添加处理程序。默认情况下它返回404代码。
r.NoRoute(func(c *gin.Context) { c.HTML(http.StatusNotFound, "views/404.html", nil) }) 路由组 我们可以将拥有共同URL前缀的路由划分为一个路由组。
func main() { r := gin.Default() userGroup := r.Group("/user") { userGroup.GET("/index", func(c *gin.Context) {...}) userGroup.GET("/login", func(c *gin.Context) {...}) userGroup.POST("/login", func(c *gin.Context) {...}) } shopGroup := r.Group("/shop") { shopGroup.GET("/index", func(c *gin.Context) {...}) shopGroup.GET("/cart", func(c *gin.Context) {...}) shopGroup.POST("/checkout", func(c *gin.Context) {...}) } r.Run() } 通常我们将路由分组用在划分业务逻辑或划分API版本时。
路由分文件 在route中初始化route和切片路由组 在各个文件写路由 在main中把路由函数放入函数路由组 // route中go package route import "github.com/gin-gonic/gin" type Option func(*gin.Engine) var options = []Option{} // 路由函数组 // 注册app的路由配置 func Include(opts ...Option) { options = append(options, opts...) // 路由函数组添加函数 } // 初始化 func Init() *gin.Engine { r := gin.New() for _, function := range options { function(r) // 执行路由函数组中所有函数 } return r } // shop中的文件 package shop import "github.com/gin-gonic/gin" func Routers(e *gin.Engine) {// 路由函数 e.GET("/post", func(c *gin.Context) { c.String(200,"psot shop") }) e.GET("/comment", func(c *gin.Context) { c.String(200,"comment shop") }) } // main.go package main import ( "test/demo1/route" "test/demo1/shop" ) func main() { route.Include(shop.Routers) // 初始化路由 r := route.Init() _ = r.Run() } 路由原理 Gin框架中的路由使用的是httprouter 这个库。
其基本原理就是构造一个路由地址的前缀树。
参考文章 https://www.liwenzhou.com/posts/Go/Gin_framework/</content></entry><entry><title>Go gc垃圾回收</title><url>https://www.zhaohaiyu.com/post/go/go-gc/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的对象，让出存储器资源，无需程序员手动执行。
Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，Golang进行了多次的迭代优化来解决这个问题。
Go V1.3之前的标记-清除(mark and sweep)算法 此算法主要有两个主要的步骤：
标记(Mark phase) 清除(Sweep phase) 第一步，暂停程序业务逻辑, 找出不可达的对象，然后做上标记。第二步，回收标记好的对象。
操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿。
第二步, 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：
第三步, 标记完了之后，然后开始清除未标记的对象. 结果如下.
第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。
标记-清扫(mark and sweep)的缺点 STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。 标记需要扫描整个heap 清除数据会产生heap碎片 所以Go V1.3版本之前就是以上来实施的, 流程是
Go V1.3 做了简单的优化,将STW提前, 减少STW暂停的时间范围.如下所示
这里面最重要的问题就是：mark-and-sweep 算法会暂停整个程序 。
Go是如何面对并这个问题的呢？接下来G V1.5版本 就用三色并发标记法来优化这个问题.
Go V1.5的三色并发标记法 三色标记法 实际上就是通过三个阶段的标记来确定清楚的对象都有哪些. 我们来看一下具体的过程.
第一步 , 就是只要是新创建的对象,默认的颜色都是标记为“白色”.
这里面需要注意的是, 所谓“程序”, 则是一些对象的跟节点集合.
所以上图,可以转换如下的方式来表示.
第二步, 每次GC回收开始, 然后从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合。
第三步, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合
第四步, 重复第三步, 直到灰色中无任何对象.
第五步: 回收所有的白色标记表的对象. 也就是回收垃圾.
以上便是三色并发标记法, 不难看出,我们上面已经清楚的体现三色的特性, 那么又是如何实现并行的呢?
Go是如何解决标记-清除(mark and sweep)算法中的卡顿(stw，stop the world)问题的呢？
没有STW的三色标记法 我们还是基于上述的三色并发标记法来说, 他是一定要依赖STW的. 因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性。我们举一个场景. 如果三色标记法, 标记过程不使用STW将会发生什么事情?
可以看出，有两个问题, 在三色标记法中,是不希望被发生的
条件1: 一个白色对象被黑色对象引用**(白色被挂在黑色下)** 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏**(灰色同时丢了该白色)** 当以上两个条件同时满足时, 就会出现对象丢失现象!
当然, 如果上述中的白色对象3, 如果他还有很多下游对象的话, 也会一并都清理掉.
为了防止这种现象的发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是**STW的过程有明显的资源浪费，对所有的用户程序都有很大影响**，如何能在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？ 答案就是, 那么我们只要使用一个机制,来破坏上面的两个条件就可以了. 屏障机制 我们让GC回收器,满足下面两种情况之一时,可保对象不丢失. 所以引出两种方式.
“强-弱” 三色不变式 强三色不变式 不存在黑色对象引用到白色对象的指针。
弱三色不变式 所有被黑色对象引用的白色对象都处于灰色保护状态.
为了遵循上述的两个方式,Golang团队初步得到了如下具体的两种屏障方式“插入屏障”, “删除屏障”.
插入屏障 具体操作: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)
满足: 强三色不变式. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)
伪码如下:
添加下游对象(当前下游对象slot, 新下游对象ptr) { //1 标记灰色(新下游对象ptr) //2 当前下游对象slot = 新下游对象ptr } 场景：
A.添加下游对象(nil, B) //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色 A.添加下游对象(C, B) //A 将下游对象C 更换为B， B被标记为灰色 这段伪码逻辑就是写屏障,. 我们知道,黑色对象的内存槽有两种位置, `栈`和`堆`. 栈空间的特点是容量小,但是要求相应速度快,因为函数调用弹出频繁使用, 所以“插入屏障”机制,在**栈空间的对象操作中不使用**. 而仅仅使用在堆空间对象的操作中. 接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。 但是如果栈不添加,当全部三色标记扫描之后,栈上有可能依然存在白色对象被引用的情况(如上图的对象9). 所以要对栈重新进行三色标记扫描, 但这次为了对象不丢失, 要对本次标记扫描启动STW暂停. 直到栈空间的三色标记结束.
最后将栈和堆空间 扫描剩余的全部 白色节点清除. 这次STW大约的时间在10~100ms间.
删除屏障 具体操作: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。
满足: 弱三色不变式. (保护灰色对象到白色对象的路径不会断)
伪代码：
添加下游对象(当前下游对象slot， 新下游对象ptr) { //1 if (当前下游对象slot是灰色 || 当前下游对象slot是白色) { 标记灰色(当前下游对象slot) //slot为被删除对象， 标记为灰色 } //2 当前下游对象slot = 新下游对象ptr } 场景：
A.添加下游对象(B, nil) //A对象，删除B对象的引用。 B被A删除，被标记为灰(如果B之前为白) A.添加下游对象(B, C) //A对象，更换下游B变成C。 B被A删除，被标记为灰(如果B之前为白) 接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。
这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。
Go V1.8的混合写屏障(hybrid write barrier)机制 插入写屏障和删除写屏障的短板：
插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； 删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。
混合写屏障规则 具体操作:
1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，
2、GC期间，任何在栈上创建的新对象，均为黑色。
3、被删除的对象标记为灰色。
4、被添加的对象标记为灰色。
满足: 变形的弱三色不变式.
伪代码：
添加下游对象(当前下游对象slot, 新下游对象ptr) { //1 标记灰色(当前下游对象slot) //只要当前下游对象被移走，就标记灰色 //2 标记灰色(新下游对象ptr) //3 当前下游对象slot = 新下游对象ptr } 这里我们注意， 屏障技术是不在栈上应用的，因为要保证栈的运行效率。
混合写屏障的具体场景分析 接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。
注意混合写屏障是Gc的一种屏障机制，所以只是当程序执行GC的时候，才会触发这种机制。
GC开始：扫描栈区，将可达对象全部标记为黑 场景一： 对象被一个堆对象删除引用，成为栈对象的下游 伪代码
//前提：堆对象4->对象7 = 对象7； //对象7 被 对象4引用 栈对象1->对象7 = 堆对象7； //将堆对象7 挂在 栈对象1 下游 堆对象4->对象7 = null； //对象4 删除引用 对象7 场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游 伪代码
new 栈对象9； 对象8->对象3 = 对象3； //将栈对象3 挂在 栈对象9 下游 对象2->对象3 = null； //对象2 删除引用 对象3 场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游 伪代码
堆对象10->对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 堆对象4->对象7 = null； //对象4 删除引用 对象7 场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游 伪代码
堆对象10->对象7 = 堆对象7； //将堆对象7 挂在 堆对象10 下游 堆对象4->对象7 = null； //对象4 删除引用 对象7 Golang中的混合写屏障满足`弱三色不变式`，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。 总结 以上便是Golang的GC全部的标记-清除逻辑及场景演示全过程。 GoV1.3- 普通标记清除法，整体过程需要启动STW，效率极低。
GoV1.5- 三色标记法， 堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通
GoV1.8-三色标记法，混合写屏障机制， 栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。
文章转自 https://www.jianshu.com/p/4c5a303af470</content></entry><entry><title>Go web源码解析</title><url>https://www.zhaohaiyu.com/post/go/go-net-http/</url><categories><category>go</category><category>network</category></categories><tags><tag>golang</tag><tag>http</tag></tags><content type="html"> Go的web工作原理 在Go中使用及其简单的代码即可开启一个web服务。如下：
//开启web服务 func test(){ http.HandleFunc("/", sayHello) err := http.ListenAndServe(":9090",nil) if err!=nil { log.Fatal("ListenAndServer:",err) } } func sayHello(w http.ResponseWriter, r *http.Request){ r.ParseForm() fmt.Println("path",r.URL.Path) fmt.Println("scheme",r.URL.Scheme) fmt.Fprintf(w, "Hello Guest!") } 在使用ListenAndServe这个方法时，系统就会给我们指派一个路由器，DefaultServeMux是系统默认使用的路由器，如果ListenAndServe这个方法的第2个参数传入nil，系统就会默认使用DefaultServeMux。当然，这里也可以传入自定义的路由器。
先来看http.HandleFunc("/", sayHello)，从HandleFunc方法点进去，如下：
func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 在这里调用了DefaultServeMux的HandleFunc方法，这个方法有两个参数，pattern是匹配的路由规则，handler表示这个路由规则对应的处理方法，并且这个处理方法有两个参数。
在我们书写的代码示例中，pattern对应/，handler对应sayHello，当我们在浏览器中输入http://localhost:9090时，就会触发sayHello方法。
我们再顺着DefaultServeMux的HandleFunc方法继续点下去，如下：
func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { mux.Handle(pattern, HandlerFunc(handler)) } 在这个方法中，路由器又调用了Handle方法，注意这个Handle方法的第2个参数，将之前传入的handler这个响应方法强制转换成了HandlerFunc类型。
这个HandlerFunc类型到底是个什么呢？如下：
type HandlerFunc func(ResponseWriter, *Request) 看来和我们定义的SayHello方法的类型都差不多。但是！！！ 这个HandlerFunc默认实现了ServeHTTP接口！这样HandlerFunc对象就有了ServeHTTP方法！如下：
// ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 这个细节是十分重要的，因为这一步关乎到当路由规则匹配时，相应的响应方法是否会被调用的问题！这个方法的调用时机会在下一小节中讲到。
接下来，我们返回去继续看mux的Handle方法，也就是这段代码mux.Handle(pattern, HandlerFunc(handler))。这段代码做了哪些事呢？源码如下：
func (mux *ServeMux) Handle(pattern string, handler Handler) { mux.mu.Lock() defer mux.mu.Unlock() if pattern == "" { panic("http: invalid pattern " + pattern) } if handler == nil { panic("http: nil handler") } if mux.m[pattern].explicit { panic("http: multiple registrations for " + pattern) } if mux.m == nil { mux.m = make(map[string]muxEntry) } mux.m[pattern] = muxEntry{explicit: true, h: handler, pattern: pattern} if pattern[0] != '/' { mux.hosts = true } // Helpful behavior: // If pattern is /tree/, insert an implicit permanent redirect for /tree. // It can be overridden by an explicit registration. n := len(pattern) if n > 0 &amp;&amp; pattern[n-1] == '/' &amp;&amp; !mux.m[pattern[0:n-1]].explicit { // If pattern contains a host name, strip it and use remaining // path for redirect. path := pattern if pattern[0] != '/' { // In pattern, at least the last character is a '/', so // strings.Index can't be -1. path = pattern[strings.Index(pattern, "/"):] } url := &amp;url.URL{Path: path} mux.m[pattern[0:n-1]] = muxEntry{h: RedirectHandler(url.String(), StatusMovedPermanently), pattern: pattern} } } 代码挺多，其实主要就做了一件事，向DefaultServeMux的map[string]muxEntry中增加对应的路由规则和handler。
map[string]muxEntry是个什么鬼？
map是一个字典对象，它保存的是key-value。 [string]表示这个字典的key是string类型的，这个key值会保存我们的路由规则。 muxEntry是一个实例对象，这个对象内保存了路由规则对应的处理方法。 找到相应代码，如下：
//路由器 type ServeMux struct { mu sync.RWMutex m map[string]muxEntry //路由规则，一个string对应一个mux实例对象，map的key就是注册的路由表达式(string类型的) hosts bool // whether any patterns contain hostnames } //muxEntry type muxEntry struct { explicit bool h Handler //这个路由表达式对应哪个handler pattern string } //路由响应方法 type Handler interface { ServeHTTP(ResponseWriter, *Request) //handler的路由实现器 } ServeMux就是这个系统默认的路由器。
最后，总结一下这个部分：
调用http.HandleFunc("/", sayHello) 调用DefaultServeMux的HandleFunc()，把我们定义的sayHello()包装成HandlerFunc类型 继续调用DefaultServeMux的Handle()，向DefaultServeMux的map[string]muxEntry中增加路由规则和对应的handler OK，这部分代码做的事就这么多，第一部分结束。
第二部分主要就是研究这句代码err := http.ListenAndServe(":9090",nil)，也就是ListenAndServe这个方法。从这个方法点进去，如下：
func ListenAndServe(addr string, handler Handler) error { server := &amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 在这个方法中，初始化了一个server对象，然后调用这个server对象的ListenAndServe方法，在这个方法中，如下：
func (srv *Server) ListenAndServe() error { addr := srv.Addr if addr == "" { addr = ":http" } ln, err := net.Listen("tcp", addr) if err != nil { return err } return srv.Serve(tcpKeepAliveListener{ln.(*net.TCPListener)}) } 在这个方法中，调用了net.Listen("tcp", addr)，也就是底层用TCP协议搭建了一个服务，然后监控我们设置的端口。
代码的最后，调用了srv的Serve方法，如下：
func (srv *Server) Serve(l net.Listener) error { defer l.Close() if fn := testHookServerServe; fn != nil { fn(srv, l) } var tempDelay time.Duration // how long to sleep on accept failure if err := srv.setupHTTP2_Serve(); err != nil { return err } srv.trackListener(l, true) defer srv.trackListener(l, false) baseCtx := context.Background() // base is always background, per Issue 16220 ctx := context.WithValue(baseCtx, ServerContextKey, srv) ctx = context.WithValue(ctx, LocalAddrContextKey, l.Addr()) for { rw, e := l.Accept() if e != nil { select { case &lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok &amp;&amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay > max { tempDelay = max } srv.logf("http: Accept error: %v; retrying in %v", e, tempDelay) time.Sleep(tempDelay) continue } return e } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) } } 最后3段代码比较重要，也是Go语言支持高并发的体现，如下：
c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) 上面那一大坨代码，总体意思是进入方法后，首先开了一个for循环，在for循环内时刻Accept请求，请求来了之后，会为每个请求创建一个Conn，然后单独开启一个goroutine，把这个请求的数据当做参数扔给这个Conn去服务：go c.serve()。用户的每一次请求都是在一个新的goroutine去服务，每个请求间相互不影响。
在conn的serve方法中，有一句代码很重要，如下：
serverHandler{c.server}.ServeHTTP(w, w.req) 表示serverHandler也实现了ServeHTTP接口，ServeHTTP方法实现如下：
func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == "*" &amp;&amp; req.Method == "OPTIONS" { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) } 在这里如果handler为空（这个handler就可以理解为是我们自定义的路由器），就会使用系统默认的DefaultServeMux，代码的最后调用了DefaultServeMux的ServeHTTP()
func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == "*" { if r.ProtoAtLeast(1, 1) { w.Header().Set("Connection", "close") } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) //这里返回的h是Handler接口对象 h.ServeHTTP(w, r) //调用Handler接口对象的ServeHTTP方法实际上就调用了我们定义的sayHello方法 } 路由器接收到请求之后，如果是*那么关闭链接，如果不是*就调用mux.Handler(r)返回该路由对应的处理Handler，然后执行该handler的ServeHTTP方法，也就是这句代码h.ServeHTTP(w, r)，mux.Handler(r)做了什么呢？如下：
func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { if r.Method != "CONNECT" { if p := cleanPath(r.URL.Path); p != r.URL.Path { _, pattern = mux.handler(r.Host, p) url := *r.URL url.Path = p return RedirectHandler(url.String(), StatusMovedPermanently), pattern } } return mux.handler(r.Host, r.URL.Path) } func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), "" } return } func (mux *ServeMux) match(path string) (h Handler, pattern string) { var n = 0 for k, v := range mux.m { //mux.m就是系统默认路由的map if !pathMatch(k, path) { continue } if h == nil || len(k) > n { n = len(k) h = v.h pattern = v.pattern } } return } 它会根据用户请求的URL到路由器里面存储的map中匹配，匹配成功就会返回存储的handler，调用这个handler的ServeHTTP()就可以执行到相应的处理方法了，这个处理方法实际上就是我们刚开始定义的sayHello()，只不过这个sayHello()被HandlerFunc又包了一层，因为HandlerFunc实现了ServeHTTP接口，所以在调用HandlerFunc对象的ServeHTTP()时，实际上在ServeHTTP ()的内部调用了我们的sayHello()。
总结一下：
调用http.ListenAndServe(":9090",nil) 实例化server 调用server的ListenAndServe() 调用server的Serve方法，开启for循环，在循环中Accept请求 对每一个请求实例化一个Conn，并且开启一个goroutine为这个请求进行服务go c.serve() 读取每个请求的内容c.readRequest() 调用serverHandler的ServeHTTP()，如果handler为空，就把handler设置为系统默认的路由器DefaultServeMux 调用handler的ServeHTTP() =>实际上是调用了DefaultServeMux的ServeHTTP() 在ServeHTTP()中会调用路由对应处理handler 在路由对应处理handler中会执行sayHello() 有一个需要注意的点： DefaultServeMux和路由对应的处理方法handler都实现了ServeHTTP接口，他们俩都有ServeHTTP方法，但是方法要达到的目的不同，在DefaultServeMux的ServeHttp()里会执行路由对应的处理handler的ServeHttp()。
文章转自 https://juejin.cn/post/6844903550993039374</content></entry><entry><title>Http Https</title><url>https://www.zhaohaiyu.com/post/network/http-https/</url><categories><category>network</category></categories><tags><tag>http</tag></tags><content type="html"> HTTP协议是什么？ HTTP协议是超文本传输协议的缩写，英文是Hyper Text Transfer Protocol。它是从WEB服务器传输超文本标记语言(HTML)到本地浏览器的传送协议。 设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 HTPP有多个版本，目前广泛使用的是HTTP/1.1版本。 HTTP原理 HTTP是一个基于TCP/IP通信协议来传递数据的协议，传输的数据类型为HTML 文件,、图片文件, 查询结果等。
HTTP协议一般用于B/S架构（）。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。
我们以访问百度为例：
访问百度流程
http1.*和http2 这个Akamai公司建立的一个官方的演示，使用HTTP/1.1和HTTP/2同时请求379张图片，观察请求的时间，明显看出HTTP/2性能占优势。
多路复用：通过单一的HTTP/2连接请求发起多重的请求-响应消息，多个请求stream共享一个TCP连接，实现多流并行而不是依赖建立多个TCP连接。
HTTP报文格式
HTTP特点 http协议支持客户端/服务端模式，也是一种请求/响应模式的协议。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。 灵活：HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。 无连接：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接，为了弥补这种不足，产生了两项记录http状态的技术，一个叫做Cookie,一个叫做Session。 无状态：无状态是指协议对于事务处理没有记忆，后续处理需要前面的信息，则必须重传。 为什么要用https？ 实际使用中，绝大说的网站现在都采用的是https协议，这也是未来互联网发展的趋势。下面是通过wireshark抓取的一个博客网站的登录请求过程。
博客登录抓包
可以看到访问的账号密码都是明文传输， 这样客户端发出的请求很容易被不法分子截取利用，因此，HTTP协议不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信息非常不安全。
一般http中存在如下问题：
请求信息明文传输，容易被窃听截取。 数据的完整性未校验，容易被篡改 没有验证对方身份，存在冒充危险 什么是HTTPS? 为了解决上述HTTP存在的问题，就用到了HTTPS。
HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL/TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。
那么SSL又是什么？
SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。
TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。
SSL发展史（互联网加密通信）
1994年NetSpace公司设计SSL协议（Secure Sockets Layout）1.0版本，但未发布。 1995年NetSpace发布SSL/2.0版本，很快发现有严重漏洞 1996年发布SSL/3.0版本，得到大规模应用 1999年，发布了SSL升级版TLS/1.0版本，目前应用最广泛的版本 2006年和2008年，发布了TLS/1.1版本和TLS/1.2版本 浏览器在使用HTTPS传输数据的流程是什么？ HTTPS数据传输流程
首先客户端通过URL访问服务器建立SSL连接。 服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端。 客户端的服务器开始协商SSL连接的安全等级，也就是信息加密的等级。 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 服务器利用自己的私钥解密出会话密钥。 服务器利用会话密钥加密与客户端之间的通信。 HTTPS的缺点 HTTPS协议多次握手，导致页面的加载时间延长近50%； HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗； 申请SSL证书需要钱，功能越强大的证书费用越高。 SSL涉及到的安全算***消耗 CPU 资源，对服务器资源消耗较大。 总结HTTPS和HTTP的区别 HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL/TLS协议进行了加密处理。 http和https使用连接方式不同，默认端口也不一样，http是80，https是443。 参考文章:
https://zhuanlan.zhihu.com/p/72616216 https://baijiahao.baidu.com/s?id=1673721127616042356</content></entry><entry><title>分布式ID和锁</title><url>https://www.zhaohaiyu.com/post/microservice/distributed_id_lock/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag></tags><content type="html"> 分布式id生成器 有时我们需要能够生成类似MySQL自增ID这样不断增大，同时又不会重复的id。以支持业务中的高并发场景。比较典型的，电商促销时，短时间内会有大量的订单涌入到系统，比如每秒10w+。明星出轨时，会有大量热情的粉丝发微博以表心意，同样会在短时间内产生大量的消息。
在插入数据库之前，我们需要给这些消息、订单先打上一个ID，然后再插入到我们的数据库。对这个id的要求是希望其中能带有一些时间信息，这样即使我们后端的系统对消息进行了分库分表，也能够以时间顺序对这些消息进行排序。
Twitter的snowflake算法是这种场景下的一个典型解法。先来看看snowflake是怎么一回事：
snowflake中的比特位分布
首先确定我们的数值是64位，int64类型，被划分为四部分，不含开头的第一个bit，因为这个bit是符号位。用41位来表示收到请求时的时间戳，单位为毫秒，然后五位来表示数据中心的id，然后再五位来表示机器的实例id，最后是12位的循环自增id（到达1111,1111,1111后会归0）。
这样的机制可以支持我们在同一台机器上，同一毫秒内产生2 ^ 12 = 4096条消息。一秒共409.6万条消息。从值域上来讲完全够用了。
数据中心加上实例id共有10位，可以支持我们每数据中心部署32台机器，所有数据中心共1024台实例。
表示timestamp的41位，可以支持我们使用69年。当然，我们的时间毫秒计数不会真的从1970年开始记，那样我们的系统跑到2039/9/7 23:47:35就不能用了，所以这里的timestamp实际上只是相对于某个时间的增量，比如我们的系统上线是2018-08-01，那么我们可以把这个timestamp当作是从2018-08-01 00:00:00.000的偏移量。
worker_id分配 timestamp，datacenter_id，worker_id和sequence_id这四个字段中，timestamp和sequence_id是由程序在运行期生成的。但datacenter_id和worker_id需要我们在部署阶段就能够获取得到，并且一旦程序启动之后，就是不可更改的了（想想，如果可以随意更改，可能被不慎修改，造成最终生成的id有冲突）。
一般不同数据中心的机器，会提供对应的获取数据中心id的API，所以datacenter_id我们可以在部署阶段轻松地获取到。而worker_id是我们逻辑上给机器分配的一个id，这个要怎么办呢？比较简单的想法是由能够提供这种自增id功能的工具来支持，比如MySQL:
mysql> insert into a (ip) values("10.1.2.101"); Query OK, 1 row affected (0.00 sec) mysql> select last_insert_id(); +------------------+ | last_insert_id() | +------------------+ | 2 | +------------------+ 1 row in set (0.00 sec) 从MySQL中获取到worker_id之后，就把这个worker_id直接持久化到本地，以避免每次上线时都需要获取新的worker_id。让单实例的worker_id可以始终保持不变。
当然，使用MySQL相当于给我们简单的id生成服务增加了一个外部依赖。依赖越多，我们的服务的可运维性就越差。
考虑到集群中即使有单个id生成服务的实例挂了，也就是损失一段时间的一部分id，所以我们也可以更简单暴力一些，把worker_id直接写在worker的配置中，上线时，由部署脚本完成worker_id字段替换。
开源实例 标准snowflake实现 github.com/bwmarrin/snowflake 是一个相当轻量化的snowflake的Go实现。其文档对各位使用的定义见图 6-2所示。
图 6-2 snowflake库
和标准的snowflake完全一致。使用上比较简单：
package main import ( "fmt" "os" "github.com/bwmarrin/snowflake" ) func main() { n, err := snowflake.NewNode(1) if err != nil { println(err) os.Exit(1) } for i := 0; i &lt; 3; i++ { id := n.Generate() fmt.Println("id", id) fmt.Println( "node: ", id.Node(), "step: ", id.Step(), "time: ", id.Time(), "\n", ) } } 当然，这个库也给我们留好了定制的后路，其中预留了一些可定制字段：
// Epoch is set to the twitter snowflake epoch of Nov 04 2010 01:42:54 UTC // You may customize this to set a different epoch for your application. Epoch int64 = 1288834974657 // Number of bits to use for Node // Remember, you have a total 22 bits to share between Node/Step NodeBits uint8 = 10 // Number of bits to use for Step // Remember, you have a total 22 bits to share between Node/Step StepBits uint8 = 12 Epoch就是本节开头讲的起始时间，NodeBits指的是机器编号的位长，StepBits指的是自增序列的位长。
sonyflake sonyflake是Sony公司的一个开源项目，基本思路和snowflake差不多，不过位分配上稍有不同，见图 6-3：
图 6-3 sonyflake
这里的时间只用了39个bit，但时间的单位变成了10ms，所以理论上比41位表示的时间还要久(174年)。
Sequence ID和之前的定义一致，Machine ID其实就是节点id。sonyflake与众不同的地方在于其在启动阶段的配置参数：
func NewSonyflake(st Settings) *Sonyflake Settings数据结构如下：
type Settings struct { StartTime time.Time MachineID func() (uint16, error) CheckMachineID func(uint16) bool } StartTime选项和我们之前的Epoch差不多，如果不设置的话，默认是从2014-09-01 00:00:00 +0000 UTC开始。
MachineID可以由用户自定义的函数，如果用户不定义的话，会默认将本机IP的低16位作为machine id。
CheckMachineID是由用户提供的检查MachineID是否冲突的函数。这里的设计还是比较巧妙的，如果有另外的中心化存储并支持检查重复的存储，那我们就可以按照自己的想法随意定制这个检查MachineID是否冲突的逻辑。如果公司有现成的Redis集群，那么我们可以很轻松地用Redis的集合类型来检查冲突。
redis 127.0.0.1:6379> SADD base64_encoding_of_last16bits MzI0Mgo= (integer) 1 redis 127.0.0.1:6379> SADD base64_encoding_of_last16bits MzI0Mgo= (integer) 0 使用起来也比较简单，有一些逻辑简单的函数就略去实现了：
package main import ( "fmt" "os" "time" "github.com/sony/sonyflake" ) func getMachineID() (uint16, error) { var machineID uint16 var err error machineID = readMachineIDFromLocalFile() if machineID == 0 { machineID, err = generateMachineID() if err != nil { return 0, err } } return machineID, nil } func checkMachineID(machineID uint16) bool { saddResult, err := saddMachineIDToRedisSet() if err != nil || saddResult == 0 { return true } err := saveMachineIDToLocalFile(machineID) if err != nil { return true } return false } func main() { t, _ := time.Parse("2006-01-02", "2018-01-01") settings := sonyflake.Settings{ StartTime: t, MachineID: getMachineID, CheckMachineID: checkMachineID, } sf := sonyflake.NewSonyflake(settings) id, err := sf.NextID() if err != nil { fmt.Println(err) os.Exit(1) } fmt.Println(id) } 分布式锁 在单机程序并发或并行修改全局变量时，需要对修改行为加锁以创造临界区。为什么需要加锁呢？我们看看在不加锁的情况下并发计数会发生什么情况：
package main import ( "sync" ) // 全局变量 var counter int func main() { var wg sync.WaitGroup for i := 0; i &lt; 1000; i++ { wg.Add(1) go func() { defer wg.Done() counter++ }() } wg.Wait() println(counter) } 多次运行会得到不同的结果：
❯❯❯ go run local_lock.go 945 ❯❯❯ go run local_lock.go 937 ❯❯❯ go run local_lock.go 959 基于Redis的setnx 在分布式场景下，我们也需要这种“抢占”的逻辑，这时候怎么办呢？我们可以使用Redis提供的setnx命令：
package main import ( "fmt" "time" "github.com/go-redis/redis" "github.com/gofrs/uuid" ) // 声明一个全局的rdb变量 var rdb *redis.Client // 初始化连接 func initClient() (err error) { rdb = redis.NewClient(&amp;redis.Options{ Addr: "localhost:6379", Password: "zhy1996", // no password set DB: 0, // use default DB }) _, err = rdb.Ping().Result() if err != nil { return err } return nil } var unlock_lua = ` if redis.call("get",KEYS[1]) == ARGV[1] then return redis.call("del",KEYS[1]) else return 0 end ` func Lock(key, value string, expiration time.Duration) (bool, error) { is, err := rdb.SetNX(key, value, expiration).Result() if err != nil { return false, fmt.Errorf("redis setnx failed") } return is, nil } func UnLock(key, value string) (bool, error) { res, err := rdb.Eval(unlock_lua, []string{key}, value).Result() if err != nil { return false, err } v, ok := res.(int64) if !ok { return false, fmt.Errorf("lua script return is not int") } if v == 0 { return false, nil } return true, nil } func main() { err := initClient() if err != nil { fmt.Println(err) } ul, _ := uuid.NewV4() value := ul.String() for i := 0; i &lt; 10; i++ { is, err := Lock("lock_1", value, time.Second) if err != nil { fmt.Println(err) return } fmt.Println("是否拿到锁:", is) } res, err := UnLock("lock_1", value) if err != nil { fmt.Println(err) return } fmt.Println("解锁:", res) } 看看运行结果：
是否拿到锁: true 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 是否拿到锁: false 解锁: true 通过代码和执行结果可以看到，我们远程调用setnx实际上和单机的trylock非常相似，如果获取锁失败，那么相关的任务逻辑就不应该继续向前执行。
setnx很适合在高并发场景下，用来争抢一些“唯一”的资源。比如交易撮合系统中卖家发起订单，而多个买家会对其进行并发争抢。这种场景我们没有办法依赖具体的时间来判断先后，因为不管是用户设备的时间，还是分布式场景下的各台机器的时间，都是没有办法在合并后保证正确的时序的。哪怕是我们同一个机房的集群，不同的机器的系统时间可能也会有细微的差别。
所以，我们需要依赖于这些请求到达Redis节点的顺序来做正确的抢锁操作。如果用户的网络环境比较差，那也只能自求多福了。
基于etcd etcd是分布式系统中，功能上与ZooKeeper类似的组件，这两年越来越火了。上面基于ZooKeeper我们实现了分布式阻塞锁，基于etcd，也可以实现类似的功能：
package main import ( "log" "github.com/zieckey/etcdsync" ) func main() { m, err := etcdsync.New("/lock", 10, []string{"http://127.0.0.1:2379"}) if m == nil || err != nil { log.Printf("etcdsync.New failed") return } err = m.Lock() if err != nil { log.Printf("etcdsync.Lock failed") return } log.Printf("etcdsync.Lock OK") log.Printf("Get the lock. Do something here.") err = m.Unlock() if err != nil { log.Printf("etcdsync.Unlock failed") } else { log.Printf("etcdsync.Unlock OK") } } etcd中没有像ZooKeeper那样的Sequence节点。所以其锁实现和基于ZooKeeper实现的有所不同。在上述示例代码中使用的etcdsync的Lock流程是：
先检查/lock路径下是否有值，如果有值，说明锁已经被别人抢了 如果没有值，那么写入自己的值。写入成功返回，说明加锁成功。写入时如果节点被其它节点写入过了，那么会导致加锁失败，这时候到 3 watch /lock下的事件，此时陷入阻塞 当/lock路径下发生事件时，当前进程被唤醒。检查发生的事件是否是删除事件（说明锁被持有者主动unlock），或者过期事件（说明锁过期失效）。如果是的话，那么回到 1，走抢锁流程。 值得一提的是，在etcdv3的API中官方已经提供了可以直接使用的锁API，读者可以查阅etcd的文档做进一步的学习。
参考文章：《go语言高级编程》</content></entry><entry><title>thrift的介绍及其使用</title><url>https://www.zhaohaiyu.com/post/microservice/thrift/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>Thrift</tag></tags><content type="html"> 什么是thrift Thrift是Facebook于2007年开发的跨语言的rpc服框架，提供多语言的编译功能，并提供多种服务器工作模式；用户通过Thrift的IDL（接口定义语言）来描述接口函数及数据类型，然后通过Thrift的编译环境生成各种语言类型的接口文件，用户可以根据自己的需要采用不同的语言开发客户端代码和服务器端代码。
例如，我想开发一个快速计算的RPC服务，它主要通过接口函数getInt对外提供服务，这个RPC服务的getInt函数使用用户传入的参数，经过复杂的计算，计算出一个整形值返回给用户；服务器端使用java语言开发，而调用客户端可以是java、c、python等语言开发的程序，在这种应用场景下，我们只需要使用Thrift的IDL描述一下getInt函数（以.thrift为后缀的文件），然后使用Thrift的多语言编译功能，将这个IDL文件编译成C、java、python几种语言对应的“特定语言接口文件”（每种语言只需要一条简单的命令即可编译完成），这样拿到对应语言的“特定语言接口文件”之后，就可以开发客户端和服务器端的代码了，开发过程中只要接口不变，客户端和服务器端的开发可以独立的进行。
Thrift为服务器端程序提供了很多的工作模式，例如：线程池模型、非阻塞模型等等，可以根据自己的实际应用场景选择一种工作模式高效地对外提供服务；
Thrift的官方网站：http://thrift.apache.org/
thrift的协议结构 Thrift是一种c/s的架构体系。TServer主要任务是高效的接受客户端请求，并将请求转发给Processor处理。
最上层是用户自行实现的业务逻辑代码； Processor是由thrift编译器自动生成的代码，它封装了从输入数据流中读数据和向数据流中写数据的操作，它的主要工作是：从连接中读取数据，把处理交给用户实现impl，最后把结果写到连接上。 TProtocol是用于数据类型解析的，将结构化数据转化为字节流给TTransport进行传输。从TProtocol以下部分是thirft的传输协议和底层I/O通信。 TTransport是与底层数据传输密切相关的传输层，负责以字节流方式接收和发送消息体，不关注是什么数据类型。 底层IO负责实际的数据传输，包括socket、文件和压缩数据流等。 下载 下载thrift编译软件:
MacOs:brew install thrift Windows:Thrift官方下载地址：http://thrift.apache.org/download golang下载: go get github.com/apache/thrift/lib/go/thrift
python下载: sudo pip install thrift
IDL文件编写 thrift 采用IDL（Interface Definition Language）来定义通用的服务接口，并通过生成不同的语言代理实现来达到跨语言、平台的功能。在thrift的IDL中可以定义以下一些类型：基本数据类型，结构体，容器，异常、服务
基本类型 bool: 布尔值 (true or false), one byte byte: 有符号字节 i16: 16位有符号整型 i32: 32位有符号整型 i64: 64位有符号整型 double: 64位浮点型 string: Encoding agnostic text or binary string 基本类型中基本都是有符号数，因为有些语言没有无符号数，所以Thrift不支持无符号整型。
特殊类型 binary: Blob (byte array) a sequence of unencoded bytes
这是string类型的一种变形，主要是为Java 使用，目前我主要使用C++的语言，所以java的这个类型没有用过
struct thrift中struct是定义为一种对象，和面向对象语言的class差不多.,但是struct有以下一些约束：
struct不能继承，但是可以嵌套，不能嵌套自己。 其成员都是有明确类型 成员是被正整数编号过的，其中的编号使不能重复的，这个是为了在传输过程中编码使用。 成员分割符可以是逗号（,）或是分号（;），而且可以混用，但是为了清晰期间，建议在定义中只使用一种，比如C++学习者可以就使用分号（;）。 字段会有optional和required之分和protobuf一样，但是如果不指定则为无类型—可以不填充该值，但是在序列化传输的时候也会序列化进去，optional是不填充则部序列化，required是必须填充也必须序列化。 每个字段可以设置默认值 同一文件可以定义多个struct，也可以定义在不同的文件，进行include引入。 数字标签作用非常大，但是随着项目开发的不断发展，也许字段会有变化，但是建议不要轻易修改这些数字标签，修改之后如果没有同步客户端和服务器端会让一方解析出问题。
struct Report { 1: required string msg, //改字段必须填写 2: optional i32 type = 0; //默认值 3: i32 time //默认字段类型为optional } 规范的struct定义中的每个域均会使用required或者 optional关键字进行标识。如果required标识的域没有赋值，Thrift将给予提示；如果optional标识的域没有赋值，该域将不会被序列化传输；如果某个optional标识域有缺省值而用户没有重新赋值，则该域的值一直为缺省值；如果某个optional标识域有缺省值或者用户已经重新赋值，而不设置它的__isset为true，也不会被序列化传输。
容器（Containers） Thrift容器与目前流行编程语言的容器类型相对应，有3种可用容器类型：
list: 元素类型为t的有序表，容许元素重复。对应c++的vector，java的ArrayList或者其他语言的数组（官方文档说是ordered list不知道如何理解？排序的？c++的vector不排序） set:元素类型为t的无序表，不容许元素重复。对应c++中的set，java中的HashSet,python中的set，php中没有set，则转换为list类型了 map&lt;t,t>: 键类型为t，值类型为t的kv对，键不容许重复。对用c++中的map, Java的HashMap, PHP 对应 array, Python/Ruby 的dictionary。 容器中元素类型可以是除了service外的任何合法Thrift类型（包括结构体和异常）。为了最大的兼容性，map的key最好是thrift的基本类型，有些语言不支持复杂类型的key，JSON协议只支持那些基本类型的key。
容器都是同构容器，不失异构容器。
例子
struct Test { 1: map&lt;Numberz, UserId> user_map, 2: set&lt;Numberz> num_sets, 3: list&lt;Stusers> users } 枚举（enmu） 很多语言都有枚举，意义都一样。比如，当定义一个消息类型时，它只能是预定义的值列表中的一个，可以用枚举实现。说明：
编译器默认从0开始赋值 可以赋予某个常量某个整数 允许常量是十六进制整数 末尾没有分号 给常量赋缺省值时，使用常量的全称 注意，不同于protocal buffer，thrift不支持枚举类嵌套，枚举常量必须是32位的正整数
enum EnOpType {CMD_OK = 0, // (0) CMD_NOT_EXIT = 2000, // (2000) CMD_EXIT = 2001, // (2001) CMD_ADD = 2002 // (2002) } struct StUser { 1: required i32 userId; 2: required string userName; 3: optional EnOpType cmd_code = EnOpType.CMD_OK; // (0) 4: optional string language = “english” } 常量定义和类型定义 Thrift允许定义跨语言使用的常量，复杂的类型和结构体可使用JSON形式表示。
const i32 INT_CONST = 1234; const EnOpType myEnOpType = EnOpType.CMD_EXIT; //2001 说明：分号可有可无。支持16进制。　Thrift支持C/C++类型定义。
typedef i32 MyInteger // a typedef StUser ReU // b typedef i64 UserId 说明：a.末尾没有逗号。b. Struct也可以使用typedef。
异常（Exceptions） Thrift结构体在概念上类似于（similar to）C语言结构体类型—将相关属性封装在一起的简便方式。Thrift结构体将会被转换成面向对象语言的类。
异常在语法和功能上类似于结构体，差别是异常使用关键字exception，而且异常是继承每种语言的基础异常类。
exception Extest { 1: i32 errorCode, 2: string message, 3: StUser userinfo } 服务（Services） 服务的定义方法在语义(semantically)上等同于面向对象语言中的接口。Thrift编译器会产生执行这些接口的client和server stub。具体参见下一节。
在流行的序列化/反序列化框架（如protocal buffer）中，Thrift是少有的提供多语言间RPC服务的框架。这是Thrift的一大特色。
Thrift编译器会根据选择的目标语言为server产生服务接口代码，为client产生stubs。
service SeTest { void ping(), bool postTweet(1: StUser user); StUser searchTweets(1:string name); oneway void zip() }　首先所有的方法都是纯虚汗数，也就是继承类必须实现这些方法 返回值不是基本类型的都把返回值放到了函数参数中第一个参数，命名_return 所有的参数（除返回值）都是const类型，意味这函数一般参数无法作为返回值携带者。只会有一个返回参数，如果返回值有多个，那只能封装复杂类型作为返回值参数。 oneway的返回值一定是void 当然服务是支持继承。 服务不支持重载 名字空间（Namespace） Thrift中的命名空间类似于C++中的namespace和java中的package，它们提供了一种组织（隔离）代码的简便方式。名字空间也可以用于解决类型定义中的名字冲突。
由于每种语言均有自己的命名空间定义方式（如Python 中有module）, thrift允许开发者针对特定语言定义namespace：
namespace go com.example.test namespace py com.example.test namespace php com.example.test 注释（Comment） Thrift支持C多行风格和Java/C++单行风格。
/* * This is a multi-line comment. * Just like in C. */ // C++/Java style single-line comments work just as well. 11Includes 便于管理、重用和提高模块性/组织性，我们常常分割Thrift定义在不同的文件中。包含文件搜索方式与c++一样。Thrift允许文件包含其它thrift文件，用户需要使用thrift文件名作为前缀访问被包含的对象，如：
include "test.thrift" ... struct StSearchResult { 1: in32 uid; ... } thrift文件名要用双引号包含，末尾没有逗号或者分号
Thrift支持的传输及服务模型 支持的传输格式： 参数: 描述: TBinaryProtocol 二进制格式 TCompactProtocol 压缩格式 TJSONProtocol JSON格式 TSimpleJSONProtocol 提供JSON只写协议, 生成的文件很容易通过脚本语言解析 TDebugProtocol 使用易懂的可读的文本格式，以便于debug 支持的数据传输方式： 参数: 描述: TSocket 阻塞式socker TFramedTransport 以frame为单位进行传输，非阻塞式服务中使用 TFileTransport 以文件形式进行传输 TMemoryTransport 将内存用于I/O. java实现时内部实际使用了简单的ByteArrayOutputStream TZlibTransport 使用zlib进行压缩， 与其他传输方式联合使用。当前无java实现 支持的服务模型： 参数: 描述: TSimpleServer 简单的单线程服务模型，常用于测试 TThreadPoolServer 多线程服务模型，使用标准的阻塞式IO TNonblockingServer 多线程服务模型，使用非阻塞式IO（需使用TFramedTransport数据传输方式） 代码实现 编写*.thrift文件 namespace go example struct Data { 1: string text } service format_data { Data do_format(1:Data data), } 解析成go代码:thrift --out . --gen go example.thrift
解析成python代码:thrift --out . --gen py example.thrift
golang服务端 服务端的实现:
Handler 服务端业务处理逻辑。这里就是业务代码，比如 计算两个字符串 相似度 Processor 从Thrift框架 转移到 业务处理逻辑。因此是RPC调用，客户端要把 参数发送给服务端，而这一切由Thrift封装起来了，由Processor将收到的“数据”转交给业务逻辑去处理 Protocol 数据的序列化与反序列化。客户端提供的是“字符串”，而数据传输是一个个的字节，因此会用到序列化与反序列化。 Transport 传输层的数据传输。 TServer 服务端的类型。服务器以何种方式来处理客户端请求 TSimpleServer —— 单线程服务器端使用标准的阻塞式 I/O TThreadPoolServer —— 多线程服务器端使用标准的阻塞式 I/O TNonblockingServer —— 多线程服务器端使用非阻塞式 I/O /* server.go */ package main import ( "context" "fmt" "log" "test/example" "github.com/apache/thrift/lib/go/thrift" ) type FormatDataImpl struct{} func (fdi *FormatDataImpl) DoFormat(ctx context.Context) (r string, err error) { return "不好", nil } const ( HOST = "127.0.0.1" PORT = "8080" ) func main() { handler := &amp;FormatDataImpl{} processor := example.NewFormatDataProcessor(handler) serverTransport, err := thrift.NewTServerSocket(HOST + ":" + PORT) if err != nil { log.Fatalln("Error:", err) } transportFactory := thrift.NewTBufferedTransportFactory(10000000) protocolFactory := thrift.NewTBinaryProtocolFactoryDefault() server := thrift.NewTSimpleServer4(processor, serverTransport, transportFactory, protocolFactory) fmt.Println("Running at:", HOST+":"+PORT) err = server.Serve() if err != nil { log.Fatalln("Error:", err) } } python服务端 from thrift.protocol import TBinaryProtocol from thrift.server import TServer from thrift.transport import TSocket, TTransport from example import format_data __HOST = '127.0.0.1' __PORT = 8080 class FormatDataImpl: def do_format(self): return "你好" if __name__ == '__main__': handler = FormatDataImpl() processor = format_data.Processor(handler) transport = TSocket.TServerSocket('127.0.0.1', 8080) tfactory = TTransport.TBufferedTransportFactory() pfactory = TBinaryProtocol.TBinaryProtocolFactory() server = TServer.TSimpleServer(processor, transport, tfactory, pfactory) print("Starting python server...") server.serve() print("done!") golang客户端 package main import ( "context" "fmt" "log" "net" "test/example" "github.com/apache/thrift/lib/go/thrift" ) const ( HOST = "127.0.0.1" PORT = "8080" ) func main() { tSocket, err := thrift.NewTSocket(net.JoinHostPort(HOST, PORT)) if err != nil { log.Fatalln("tSocket error:", err) } transport := thrift.NewTBufferedTransport(tSocket,10000000) // transport, err := transportFactory.Gwt(tSocket) // if err != nil { // log.Fatalln("GetTransport error:", err) // } protocolFactory := thrift.NewTBinaryProtocolFactoryDefault() client := example.NewFormatDataClientFactory(transport, protocolFactory) if err := transport.Open(); err != nil { log.Fatalln("Error opening:", HOST+":"+PORT) } defer transport.Close() // data := example.Data{Text: "hello,world!as赵海宇"} d, err := client.DoFormat(context.TODO() ) fmt.Println(d) } 5.python客户端
from example import format_data from thrift import Thrift from thrift.transport import TSocket from thrift.transport import TTransport from thrift.protocol import TBinaryProtocol try: # Make socket transport = TSocket.TSocket('127.0.0.1', 8080) # Buffering is critical. Raw sockets are very slow transport = TTransport.TBufferedTransport(transport) # Wrap in a protocol protocol = TBinaryProtocol.TBinaryProtocol(transport) # Create a client to use the protocol encoder client = format_data.Client(protocol) # Connect! transport.open() # data = format_data.Data(text="sada") d = client.do_format() print(d) transport.close() except Thrift.TException as tx: print(tx.message) 常见的坑 golang中倒入包路径有github.com/apache/thrift/lib/go/thrift和git.apache.org/thrift.git/lib/go/thrift 要统一用一个,不然会出问题 golang中 thrift的新版实现的结构体多一个ctx context.Context参数.(老版本没有,网上很多的demo代码用新版的thrift会报错) 客户端以及服务端对应好传输及服务模型协议,不同会报错. 参考文章 https://www.cnblogs.com/hapjin/p/8075721.html https://blog.csdn.net/houjixin/article/details/42778335 https://www.jianshu.com/p/4723ce380b0e</content></entry><entry><title>Go zap高性能日志</title><url>https://www.zhaohaiyu.com/post/go/go-zap/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 摘要 日志在整个工程实践中的重要性不言而喻，在选择日志组件的时候也有多方面的考量。详细、正确和及时的反馈是必不可少的，但是整个性能表现是否也是必要考虑的点呢？在长期的实践中发现有的日志组件对于计算资源的消耗十分巨大，这将导致整个服务成本的居高不下。此文从设计原理深度分析了 zap 的设计与实现上的权衡，也希望整个的选择、考量的过程能给其他的技术团队在开发高性能的 Go 组件时带来一定的借鉴意义。
前言 日志作为整个代码行为的记录，是程序执行逻辑和异常最直接的反馈。对于整个系统来说，日志是至关重要的组成部分。通过分析日志我们不仅可以发现系统的问题，同时日志中也蕴含了大量有价值可以被挖掘的信息，因此合理地记录日志是十分必要的。
我们的业务通常会记录大量的 Debug 日志，但在实际测试过程中，发现我们使用的日志库 seelog 性能存在严重的瓶颈，在我们的对比结果中发现：zap 表现非常突出，单线程 Qps 也是 logrus、seelog 的数倍。
在分析源码后 zap 设计与实现上的考量让我感到受益颇多，在这里我们主要分享一下以下几个方面：
zap 为何有这么高的性能 对于我们自己的开发有什么值得借鉴的地方 如何正确的使用 Go 开发高性能的组件 为什么选择使用ZAP 它同时提供了结构化日志记录和printf风格的日志记录 它非常的快 根据Uber-go Zap的文档，它的性能比类似的结构化日志包更好——也比标准库更快。 以下是Zap发布的基准测试信息
记录一条消息和10个字段:
Package Time Time % to zap Objects Allocated ⚡️ zap 862 ns/op +0% 5 allocs/op ⚡️ zap (sugared) 1250 ns/op +45% 11 allocs/op zerolog 4021 ns/op +366% 76 allocs/op go-kit 4542 ns/op +427% 105 allocs/op apex/log 26785 ns/op +3007% 115 allocs/op logrus 29501 ns/op +3322% 125 allocs/op log15 29906 ns/op +3369% 122 allocs/op 记录一个静态字符串，没有任何上下文或printf风格的模板：
Package Time Time % to zap Objects Allocated ⚡️ zap 118 ns/op +0% 0 allocs/op ⚡️ zap (sugared) 191 ns/op +62% 2 allocs/op zerolog 93 ns/op -21% 0 allocs/op go-kit 280 ns/op +137% 11 allocs/op standard library 499 ns/op +323% 2 allocs/op apex/log 1990 ns/op +1586% 10 allocs/op logrus 3129 ns/op +2552% 24 allocs/op log15 3887 ns/op +3194% 23 allocs/op 安装 go get -u go.uber.org/zap 示例 简单示例 格式化输出 package main import ( "go.uber.org/zap" "time" ) func main() { // zap.NewDevelopment 格式化输出 logger, _ := zap.ewDevelopment() defer logger.Sync() logger.Info("无法获取网址", zap.String("url", "http://www.baidu.com"), zap.Int("attempt", 3), zap.Duration("backoff", time.Second), ) } 格式化输出打印结果：
2019-01-02T15:01:13.923+0800 INFO spikeProxy/main.go:17 failed to fetch URL {"url": "http://www.baidu.com", "attempt": 3, "backoff": "1s"} json 序列化输出 package main import ( "go.uber.org/zap" "time" ) func main() { // zap.NewProduction json序列化输出 logger, _ := zap.NewProduction() defer logger.Sync() logger.Info("无法获取网址", zap.String("url", "http://www.baidu.com"), zap.Int("attempt", 3), zap.Duration("backoff", time.Second), ) } json序列化输出打印结果：
{"level":"info","ts":1546413239.1466308,"caller":"spikeProxy/main.go:16","msg":"无法获取网址","url":"http://www.baidu.com","attempt":3,"backoff":1} 自定义示例 选择一个日志库除了高性能是考量的一个标准，高扩展也非常重要，例如：json key 自定义、时间格式化、日志级别等。
package main import ( "go.uber.org/zap" "go.uber.org/zap/zapcore" "fmt" "time" ) func main() { encoderConfig := zapcore.EncoderConfig{ TimeKey: "time", LevelKey: "level", NameKey: "logger", CallerKey: "caller", MessageKey: "msg", StacktraceKey: "stacktrace", LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, // 小写编码器 EncodeTime: zapcore.ISO8601TimeEncoder, // ISO8601 UTC 时间格式 EncodeDuration: zapcore.SecondsDurationEncoder, EncodeCaller: zapcore.FullCallerEncoder, // 全路径编码器 } // 设置日志级别 atom := zap.NewAtomicLevelAt(zap.DebugLevel) config := zap.Config{ Level: atom, // 日志级别 Development: true, // 开发模式，堆栈跟踪 Encoding: "json", // 输出格式 console 或 json EncoderConfig: encoderConfig, // 编码器配置 InitialFields: map[string]interface{}{"serviceName": "spikeProxy"}, // 初始化字段，如：添加一个服务器名称 OutputPaths: []string{"stdout", "./logs/spikeProxy.log"}, // 输出到指定文件 stdout（标准输出，正常颜色） stderr（错误输出，红色） ErrorOutputPaths: []string{"stderr"}, } // 构建日志 logger, err := config.Build() if err != nil { panic(fmt.Sprintf("log 初始化失败: %v", err)) } logger.Info("log 初始化成功") logger.Info("无法获取网址", zap.String("url", "http://www.baidu.com"), zap.Int("attempt", 3), zap.Duration("backoff", time.Second), ) } 打印结果：
{"level":"info","time":"2019-01-02T15:38:33.778+0800","caller":"/Users/lcl/go/src/spikeProxy/main.go:54","msg":"log 初始化成功","serviceName":"spikeProxy"} {"level":"info","time":"2019-01-02T15:38:33.778+0800","caller":"/Users/lcl/go/src/spikeProxy/main.go:56","msg":"无法获取网址","serviceName":"spikeProxy","url":"http://www.baidu.com","attempt":3,"backoff":1} 写入归档文件示例 安装 lumberjack go get gopkg.in/natefinch/lumberjack.v2 lumberjack介绍 Lumberjack是一个Go包，用于将日志写入滚动文件。 zap 不支持文件归档，如果要支持文件按大小或者时间归档，需要使用lumberjack，lumberjack也是zap官方推荐 的。
示例 package main import ( "go.uber.org/zap" "go.uber.org/zap/zapcore" "time" "gopkg.in/natefinch/lumberjack.v2" "os" ) func main() { hook := lumberjack.Logger{ Filename: "./logs/spikeProxy1.log", // 日志文件路径 MaxSize: 128, // 每个日志文件保存的最大尺寸 单位：M MaxBackups: 30, // 日志文件最多保存多少个备份 MaxAge: 7, // 文件最多保存多少天 Compress: true, // 是否压缩 } encoderConfig := zapcore.EncoderConfig{ TimeKey: "time", LevelKey: "level", NameKey: "logger", CallerKey: "linenum", MessageKey: "msg", StacktraceKey: "stacktrace", LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.LowercaseLevelEncoder, // 小写编码器 EncodeTime: zapcore.ISO8601TimeEncoder, // ISO8601 UTC 时间格式 EncodeDuration: zapcore.SecondsDurationEncoder, // EncodeCaller: zapcore.FullCallerEncoder, // 全路径编码器 EncodeName: zapcore.FullNameEncoder, } // 设置日志级别 atomicLevel := zap.NewAtomicLevel() atomicLevel.SetLevel(zap.InfoLevel) core := zapcore.NewCore( zapcore.NewJSONEncoder(encoderConfig), // 编码器配置 zapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout), zapcore.AddSync(&amp;hook)), // 打印到控制台和文件 atomicLevel, // 日志级别 ) // 开启开发模式，堆栈跟踪 caller := zap.AddCaller() // 开启文件及行号 development := zap.Development() // 设置初始化字段 filed := zap.Fields(zap.String("serviceName", "serviceName")) // 构造日志 logger := zap.New(core, caller, development, filed) logger.Info("log 初始化成功") logger.Info("无法获取网址", zap.String("url", "http://www.baidu.com"), zap.Int("attempt", 3), zap.Duration("backoff", time.Second)) } 控制台打印结果：
{"level":"info","time":"2019-01-02T16:14:43.608+0800","linenum":"/Users/lcl/go/src/spikeProxy/main.go:56","msg":"log 初始化成功","serviceName":"serviceName"} {"level":"info","time":"2019-01-02T16:14:43.608+0800","linenum":"/Users/lcl/go/src/spikeProxy/main.go:57","msg":"无法获取网址","serviceName":"serviceName","url":"http://www.baidu.com","attempt":3,"backoff":1} 文件打印结果：
{"level":"info","time":"2019-01-02T16:14:43.608+0800","linenum":"/Users/lcl/go/src/spikeProxy/main.go:56","msg":"log 初始化成功","serviceName":"serviceName"} {"level":"info","time":"2019-01-02T16:14:43.608+0800","linenum":"/Users/lcl/go/src/spikeProxy/main.go:57","msg":"无法获取网址","serviceName":"serviceName","url":"http://www.baidu.com","attempt":3,"backoff":1} gin框架使用zap+lumberjack 初始化zap,lumberjack // viperconfig type Log struct { FileName string `yaml:"filename"` MaxSize int `yaml:"maxsize"` MaxBackups int `yaml:"maxbackups"` MaxAges int `yaml:"maxages"` Compress bool `yaml:"compress"` Level string `yaml:"-"` } // init var ZapLog *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *viperConfig.Log) (err error) { writeSyncer := getLogWriter(cfg.FileName, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAges) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) ZapLog = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(ZapLog) // 替换zap包中全局的logger实例，后续在其他包中只需使用zap.L()调用即可 return } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.TimeKey = "time" encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder encoderConfig.EncodeDuration = zapcore.SecondsDurationEncoder encoderConfig.EncodeCaller = zapcore.ShortCallerEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter(filename string, maxSize, maxBackup, maxAge int) zapcore.WriteSyncer { lumberJackLogger := &amp;lumberjack.Logger{ Filename: filename, MaxSize: maxSize, MaxBackups: maxBackup, MaxAge: maxAge, } return zapcore.AddSync(lumberJackLogger) } gin日志中间件 模仿Logger()和Recovery()的实现，使用我们的日志库来接收gin框架默认输出的日志。
// GinLogger 接收gin框架默认的日志 func GinLogger(logger *zap.Logger) gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.S***art) logger.Info(path, zap.Int("status", c.Writer.Status()), zap.String("method", c.Request.Method), zap.String("path", path), zap.String("query", query), zap.String("ip", c.ClientIP()), zap.String("user-agent", c.Request.UserAgent()), zap.String("errors", c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration("cost", cost), ) } } // GinRecovery recover掉项目可能出现的panic func GinRecovery(logger *zap.Logger, stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), "broken pipe") || strings.Contains(strings.ToLower(se.Error()), "connection reset by peer") { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { logger.Error(c.Request.URL.Path, zap.Any("error", err), zap.String("request", string(httpRequest)), ) // If the connection is dead, we can't write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { logger.Error("[Recovery from panic]", zap.Any("error", err), zap.String("request", string(httpRequest)), zap.String("stack", string(debug.Stack())), ) } else { logger.Error("[Recovery from panic]", zap.Any("error", err), zap.String("request", string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } 使用
// 全局中间件 func InitMiddleWares(eng *gin.Engine) { eng.Use(GinLogger(log.ZapLog), GinRecovery(log.ZapLog, true)) } 参考文章:
https://mp.weixin.qq.com/s/i0bMh_gLLrdnhAEWlF-xDw https://studygolang.com/articles/17394</content></entry><entry><title>Go viper配置管理</title><url>https://www.zhaohaiyu.com/post/go/go-viper/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 安装 go get github.com/spf13/viper viper支持的功能 1、可以设置默认值 2、可以加载多种格式的配置文件，如JSON，TOML，YAML，HCL和Java属性配置文件 3、应用程序运行过程中，保持监听和重新读取配置文件 4、可以从环境变量读取配置 5、可以从远程配置系统读取配置 6、可以读取命令行标志作为配置 7、可以从缓冲区中读取 8、设置显式的值
在GitHub中，作者是这样描述viper对于开发人员的作用：在构建现代化应用程序的过程中，开发人员可以通过使用viper而不必考虑配置文件的格式问题。 viper具体的帮助 1、可以查找、加载和反序列化多种格式的配置文件，如JSON, TOML, YAML, HCL, Java属性配置格式。 2、提供一种为不同配置选项设置默认值的机制 3、提供一种通过命令行标志覆盖指定配置选项值的机制 4、提供了一种别名系统，可以在避免破坏现有代码的前提下，轻松地重命名参数 5、当用户提供的命令行或配置文件的配置选项与默认的配置选项相同时，可以很容易通过选项值结果看出优先级的差异。
viper提供的配置方式的优先级顺序如下(由高到低)： 1.设置显示调用(explicit call to Set) 2.命令行标志(flag) 3.环境变量(env) 4.配置文件(config) 5.远程键/值存储(key/value store) 6.默认值(default)
viper的简单使用 把值存入Viper 建立默认值 一个好的配置系统应该支持默认值。键不需要默认值，但如果没有通过配置文件、环境变量、远程配置或命令行标志（flag）设置键，则默认值非常有用。
例如：
viper.SetDefault("ContentDir", "content") viper.SetDefault("LayoutDir", "layouts") viper.SetDefault("Taxonomies", map[string]string{"tag": "tags", "category": "categories"}) 读取配置文件 Viper需要最少知道在哪里查找配置文件的配置。Viper支持JSON、TOML、YAML、HCL、envfile和Java properties格式的配置文件。Viper可以搜索多个路径，但目前单个Viper实例只支持单个配置文件。Viper不默认任何配置搜索路径，将默认决策留给应用程序。
下面是一个如何使用Viper搜索和读取配置文件的示例。不需要任何特定的路径，但是至少应该提供一个配置文件预期出现的路径。
viper.SetConfigFile("./config.yaml") // 指定配置文件路径 viper.SetConfigName("config") // 配置文件名称(无扩展名) viper.SetConfigType("yaml") // 如果配置文件的名称中没有扩展名，则需要配置此项 viper.AddConfigPath("/etc/appname/") // 查找配置文件所在的路径 viper.AddConfigPath("$HOME/.appname") // 多次调用以添加多个搜索路径 viper.AddConfigPath(".") // 还可以在工作目录中查找配置 err := viper.ReadInConfig() // 查找并读取配置文件 if err != nil { // 处理读取配置文件的错误 panic(fmt.Errorf("Fatal error config file: %s \n", err)) } 在加载配置文件出错时，你可以像下面这样处理找不到配置文件的特定情况：
if err := viper.ReadInConfig(); err != nil { if _, ok := err.(viper.ConfigFileNotFoundError); ok { // 配置文件未找到错误；如果需要可以忽略 } else { // 配置文件被找到，但产生了另外的错误 } } // 配置文件找到并成功解析 注意[自1.6起]： 你也可以有不带扩展名的文件，并以编程方式指定其格式。对于位于用户$HOME目录中的配置文件没有任何扩展名，如.bashrc。
这里补充两个问题供读者解答并自行验证
当你使用如下方式读取配置时，viper会从./conf目录下查找任何以config为文件名的配置文件，如果同时存在./conf/config.json和./conf/config.yaml两个配置文件的话，viper会从哪个配置文件加载配置呢？
viper.SetConfigName("config") viper.AddConfigPath("./conf") 在上面两个语句下搭配使用viper.SetConfigType(&ldquo;yaml&rdquo;)指定配置文件类型可以实现预期的效果吗？
写入配置文件 从配置文件中读取配置文件是有用的，但是有时你想要存储在运行时所做的所有修改。为此，可以使用下面一组命令，每个命令都有自己的用途:
WriteConfig - 将当前的viper配置写入预定义的路径并覆盖（如果存在的话）。如果没有预定义的路径，则报错。 SafeWriteConfig - 将当前的viper配置写入预定义的路径。如果没有预定义的路径，则报错。如果存在，将不会覆盖当前的配置文件。 WriteConfigAs - 将当前的viper配置写入给定的文件路径。将覆盖给定的文件(如果它存在的话)。 SafeWriteConfigAs - 将当前的viper配置写入给定的文件路径。不会覆盖给定的文件(如果它存在的话)。 根据经验，标记为safe的所有方法都不会覆盖任何文件，而是直接创建（如果不存在），而默认行为是创建或截断。
一个小示例：
viper.WriteConfig() // 将当前配置写入“viper.AddConfigPath()”和“viper.SetConfigName”设置的预定义路径 viper.SafeWriteConfig() viper.WriteConfigAs("/path/to/my/.config") viper.SafeWriteConfigAs("/path/to/my/.config") // 因为该配置文件写入过，所以会报错 viper.SafeWriteConfigAs("/path/to/my/.other_config") 监控并重新读取配置文件 Viper支持在运行时实时读取配置文件的功能。
需要重新启动服务器以使配置生效的日子已经一去不复返了，viper驱动的应用程序可以在运行时读取配置文件的更新，而不会错过任何消息。
只需告诉viper实例watchConfig。可选地，你可以为Viper提供一个回调函数，以便在每次发生更改时运行。
确保在调用WatchConfig()之前添加了所有的配置路径。 viper.WatchConfig() viper.OnConfigChange(func(e fsnotify.Event) { // 配置文件发生变更之后会调用的回调函数 fmt.Println("Config file changed:", e.Name) }) 从io.Reader读取配置 Viper预先定义了许多配置源，如文件、环境变量、标志和远程K/V存储，但你不受其约束。你还可以实现自己所需的配置源并将其提供给viper。
viper.SetConfigType("yaml") // 或者 viper.SetConfigType("YAML") // 任何需要将此配置添加到程序中的方法。 var yamlExample = []byte(` Hacker: true name: steve hobbies: - skateboarding - snowboarding - go clothing: jacket: leather trousers: denim age: 35 eyes : brown beard: true `) viper.ReadConfig(bytes.NewBuffer(yamlExample)) viper.Get("name") // 这里会得到 "steve" 覆盖设置 这些可能来自命令行标志，也可能来自你自己的应用程序逻辑。
viper.Set("Verbose", true) viper.Set("LogFile", LogFile) 注册和使用别名 别名允许多个键引用单个值
viper.RegisterAlias("loud", "Verbose") // 注册别名（此处loud和Verbose建立了别名） viper.Set("verbose", true) // 结果与下一行相同 viper.Set("loud", true) // 结果与前一行相同 viper.GetBool("loud") // true viper.GetBool("verbose") // true 使用环境变量 Viper完全支持环境变量。这使Twelve-Factor App开箱即用。有五种方法可以帮助与ENV协作:
AutomaticEnv() BindEnv(string&hellip;) : error SetEnvPrefix(string) SetEnvKeyReplacer(string&hellip;) *strings.Replacer AllowEmptyEnv(bool) 使用ENV变量时，务必要意识到Viper将ENV变量视为区分大小写。
Viper提供了一种机制来确保ENV变量是惟一的。通过使用SetEnvPrefix，你可以告诉Viper在读取环境变量时使用前缀。BindEnv和AutomaticEnv都将使用这个前缀。
BindEnv使用一个或两个参数。第一个参数是键名称，第二个是环境变量的名称。环境变量的名称区分大小写。如果没有提供ENV变量名，那么Viper将自动假设ENV变量与以下格式匹配：前缀+ “_” +键名全部大写。当你显式提供ENV变量名（第二个参数）时，它 不会 自动添加前缀。例如，如果第二个参数是“id”，Viper将查找环境变量“ID”。
在使用ENV变量时，需要注意的一件重要事情是，每次访问该值时都将读取它。Viper在调用BindEnv时不固定该值。
AutomaticEnv是一个强大的助手，尤其是与SetEnvPrefix结合使用时。调用时，Viper会在发出viper.Get请求时随时检查环境变量。它将应用以下规则。它将检查环境变量的名称是否与键匹配（如果设置了EnvPrefix）。
SetEnvKeyReplacer允许你使用strings.Replacer对象在一定程度上重写 Env 键。如果你希望在Get()调用中使用-或者其他什么符号，但是环境变量里使用_分隔符，那么这个功能是非常有用的。可以在viper_test.go中找到它的使用示例。
或者，你可以使用带有NewWithOptions工厂函数的EnvKeyReplacer。与SetEnvKeyReplacer不同，它接受StringReplacer接口，允许你编写自定义字符串替换逻辑。
默认情况下，空环境变量被认为是未设置的，并将返回到下一个配置源。若要将空环境变量视为已设置，请使用AllowEmptyEnv方法。
Env 示例： SetEnvPrefix("spf") // 将自动转为大写 BindEnv("id") os.Setenv("SPF_ID", "13") // 通常是在应用程序之外完成的 id := Get("id") // 13 使用Flags Viper 具有绑定到标志的能力。具体来说，Viper支持Cobra 库中使用的Pflag。
与BindEnv类似，该值不是在调用绑定方法时设置的，而是在访问该方法时设置的。这意味着你可以根据需要尽早进行绑定，即使在init()函数中也是如此。
对于单个标志，BindPFlag()方法提供此功能。
例如：
serverCmd.Flags().Int("port", 1138, "Port to run Application server on") viper.BindPFlag("port", serverCmd.Flags().Lookup("port")) 你还可以绑定一组现有的pflags （pflag.FlagSet）：
举个例子：
pflag.Int("flagname", 1234, "help message for flagname") pflag.Parse() viper.BindPFlags(pflag.CommandLine) i := viper.GetInt("flagname") // 从viper而不是从pflag检索值 在 Viper 中使用 pflag 并不阻碍其他包中使用标准库中的 flag 包。pflag 包可以通过导入这些 flags 来处理flag包定义的flags。这是通过调用pflag包提供的便利函数AddGoFlagSet()来实现的。
例如：
package main import ( "flag" "github.com/spf13/pflag" ) func main() { // 使用标准库 "flag" 包 flag.Int("flagname", 1234, "help message for flagname") pflag.CommandLine.AddGoFlagSet(flag.CommandLine) pflag.Parse() viper.BindPFlags(pflag.CommandLine) i := viper.GetInt("flagname") // 从 viper 检索值 ... } flag接口 如果你不使用Pflag，Viper 提供了两个Go接口来绑定其他 flag 系统。
FlagValue表示单个flag。这是一个关于如何实现这个接口的非常简单的例子：
type myFlag struct {} func (f myFlag) HasChanged() bool { return false } func (f myFlag) Name() string { return "my-flag-name" } func (f myFlag) ValueString() string { return "my-flag-value" } func (f myFlag) ValueType() string { return "string" } 一旦你的 flag 实现了这个接口，你可以很方便地告诉Viper绑定它：
viper.BindFlagValue("my-flag-name", myFlag{}) FlagValueSet代表一组 flags 。这是一个关于如何实现这个接口的非常简单的例子:
type myFlagSet struct { flags []myFlag } func (f myFlagSet) VisitAll(fn func(FlagValue)) { for _, flag := range flags { fn(flag) } } 一旦你的flag set实现了这个接口，你就可以很方便地告诉Viper绑定它：
fSet := myFlagSet{ flags: []myFlag{myFlag{}, myFlag{}}, } viper.BindFlagValues("my-flags", fSet) 远程Key/Value存储支持 在Viper中启用远程支持，需要在代码中匿名导入viper/remote这个包。
import _ "github.com/spf13/viper/remote" Viper将读取从Key/Value存储（例如etcd或Consul）中的路径检索到的配置字符串（如JSON、TOML、YAML、HCL、envfile和Java properties格式）。这些值的优先级高于默认值，但是会被从磁盘、flag或环境变量检索到的配置值覆盖。（译注：也就是说Viper加载配置值的优先级为：磁盘上的配置文件>命令行标志位>环境变量>远程Key/Value存储>默认值。）
Viper使用crypt 从K/V存储中检索配置，这意味着如果你有正确的gpg密匙，你可以将配置值加密存储并自动解密。加密是可选的。
你可以将远程配置与本地配置结合使用，也可以独立使用。
crypt有一个命令行助手，你可以使用它将配置放入K/V存储中。crypt默认使用在http://127.0.0.1:4001 的etcd。
$ go get github.com/bketelsen/crypt/bin/crypt $ crypt set -plaintext /config/hugo.json /Users/hugo/settings/config.json 确认值已经设置：
$ crypt get -plaintext /config/hugo.json 有关如何设置加密值或如何使用Consul的示例，请参见crypt文档。
远程Key/Value存储示例-未加密 etcd viper.AddRemoteProvider("etcd", "http://127.0.0.1:4001","/config/hugo.json") viper.SetConfigType("json") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv" err := viper.ReadRemoteConfig() Consul 你需要 Consul Key/Value存储中设置一个Key保存包含所需配置的JSON值。例如，创建一个keyMY_CONSUL_KEY将下面的值存入Consul key/value 存储：
{ "port": 8080, "hostname": "liwenzhou.com" } viper.AddRemoteProvider("consul", "localhost:8500", "MY_CONSUL_KEY") viper.SetConfigType("json") // 需要显示设置成json err := viper.ReadRemoteConfig() fmt.Println(viper.Get("port")) // 8080 fmt.Println(viper.Get("hostname")) // liwenzhou.com Firestore viper.AddRemoteProvider("firestore", "google-cloud-project-id", "collection/document") viper.SetConfigType("json") // 配置的格式: "json", "toml", "yaml", "yml" err := viper.ReadRemoteConfig() 当然，你也可以使用SecureRemoteProvider。
远程Key/Value存储示例-加密 viper.AddSecureRemoteProvider("etcd","http://127.0.0.1:4001","/config/hugo.json","/etc/secrets/mykeyring.gpg") viper.SetConfigType("json") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv" err := viper.ReadRemoteConfig() 监控etcd中的更改-未加密 // 或者你可以创建一个新的viper实例 var runtime_viper = viper.New() runtime_viper.AddRemoteProvider("etcd", "http://127.0.0.1:4001", "/config/hugo.yml") runtime_viper.SetConfigType("yaml") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv" // 第一次从远程读取配置 err := runtime_viper.ReadRemoteConfig() // 反序列化 runtime_viper.Unmarshal(&amp;runtime_conf) // 开启一个单独的goroutine一直监控远端的变更 go func(){ for { time.Sleep(time.Second * 5) // 每次请求后延迟一下 // 目前只测试了etcd支持 err := runtime_viper.WatchRemoteConfig() if err != nil { log.Errorf("unable to read remote config: %v", err) continue } // 将新配置反序列化到我们运行时的配置结构体中。你还可以借助channel实现一个通知系统更改的信号 runtime_viper.Unmarshal(&amp;runtime_conf) } }() 从Viper获取值 在Viper中，有几种方法可以根据值的类型获取值。存在以下功能和方法:
Get(key string) : interface{} GetBool(key string) : bool GetFloat64(key string) : float64 GetInt(key string) : int GetIntSlice(key string) : []int GetString(key string) : string GetStringMap(key string) : map[string]interface{} GetStringMapString(key string) : map[string]string GetStringSlice(key string) : []string GetTime(key string) : time.Time GetDuration(key string) : time.Duration IsSet(key string) : bool AllSettings() : map[string]interface{} 需要认识到的一件重要事情是，每一个Get方法在找不到值的时候都会返回零值。为了检查给定的键是否存在，提供了IsSet()方法。
例如：
viper.GetString("logfile") // 不区分大小写的设置和获取 if viper.GetBool("verbose") { fmt.Println("verbose enabled") } 访问嵌套的键 访问器方法也接受深度嵌套键的格式化路径。例如，如果加载下面的JSON文件：
{ "host": { "address": "localhost", "port": 5799 }, "datastore": { "metric": { "host": "127.0.0.1", "port": 3099 }, "warehouse": { "host": "198.0.0.1", "port": 2112 } } } Viper可以通过传入.分隔的路径来访问嵌套字段：
GetString("datastore.metric.host") // (返回 "127.0.0.1") 这遵守上面建立的优先规则；搜索路径将遍历其余配置注册表，直到找到为止。(译注：因为Viper支持从多种配置来源，例如磁盘上的配置文件>命令行标志位>环境变量>远程Key/Value存储>默认值，我们在查找一个配置的时候如果在当前配置源中没找到，就会继续从后续的配置源查找，直到找到为止。)
例如，在给定此配置文件的情况下，datastore.metric.host和datastore.metric.port均已定义（并且可以被覆盖）。如果另外在默认值中定义了datastore.metric.protocol，Viper也会找到它。
然而，如果datastore.metric被直接赋值覆盖（被flag，环境变量，set()方法等等…），那么datastore.metric的所有子键都将变为未定义状态，它们被高优先级配置级别“遮蔽”（shadowed）了。
最后，如果存在与分隔的键路径匹配的键，则返回其值。例如：
{ "datastore.metric.host": "0.0.0.0", "host": { "address": "localhost", "port": 5799 }, "datastore": { "metric": { "host": "127.0.0.1", "port": 3099 }, "warehouse": { "host": "198.0.0.1", "port": 2112 } } } GetString("datastore.metric.host") // 返回 "0.0.0.0" 提取子树 从Viper中提取子树。
例如，viper实例现在代表了以下配置：
app: cache1: max-items: 100 item-size: 64 cache2: max-items: 200 item-size: 80 执行后：
subv := viper.Sub("app.cache1") subv现在就代表：
max-items: 100 item-size: 64 假设我们现在有这么一个函数：
func NewCache(cfg *Viper) *Cache {...} 它基于subv格式的配置信息创建缓存。现在，可以轻松地分别创建这两个缓存，如下所示：
cfg1 := viper.Sub("app.cache1") cache1 := NewCache(cfg1) cfg2 := viper.Sub("app.cache2") cache2 := NewCache(cfg2) 反序列化 你还可以选择将所有或特定的值解析到结构体、map等。
有两种方法可以做到这一点：
Unmarshal(rawVal interface{}) : error UnmarshalKey(key string, rawVal interface{}) : error 举个例子：
type config struct { Port int Name string PathMap string `mapstructure:"path_map"` } var C config err := viper.Unmarshal(&amp;C) if err != nil { t.Fatalf("unable to decode into struct, %v", err) } 如果你想要解析那些键本身就包含.(默认的键分隔符）的配置，你需要修改分隔符：
v := viper.NewWithOptions(viper.KeyDelimiter("::")) v.SetDefault("chart::values", map[string]interface{}{ "ingress": map[string]interface{}{ "annotations": map[string]interface{}{ "traefik.frontend.rule.type": "PathPrefix", "traefik.ingress.kubernetes.io/ssl-redirect": "true", }, }, }) type config struct { Chart struct{ Values map[string]interface{} } } var C config v.Unmarshal(&amp;C) Viper还支持解析到嵌入的结构体：
/* Example config: module: enabled: true token: 89h3f98hbwf987h3f98wenf89ehf */ type config struct { Module struct { Enabled bool moduleConfig `mapstructure:",squash"` } } // moduleConfig could be in a module specific package type moduleConfig struct { Token string } var C config err := viper.Unmarshal(&amp;C) if err != nil { t.Fatalf("unable to decode into struct, %v", err) } Viper在后台使用github.com/mitchellh/mapstructure 来解析值，其默认情况下使用mapstructuretag。
注意 当我们需要将viper读取的配置反序列到我们定义的结构体变量中时，一定要使用mapstructuretag哦！
序列化成字符串 你可能需要将viper中保存的所有设置序列化到一个字符串中，而不是将它们写入到一个文件中。你可以将自己喜欢的格式的序列化器与AllSettings()返回的配置一起使用。
import ( yaml "gopkg.in/yaml.v2" // ... ) func yamlStringSettings() string { c := viper.AllSettings() bs, err := yaml.Marshal(c) if err != nil { log.Fatalf("unable to marshal config to YAML: %v", err) } return string(bs) } 使用单个还是多个Viper实例? Viper是开箱即用的。你不需要配置或初始化即可开始使用Viper。由于大多数应用程序都希望使用单个中央存储库管理它们的配置信息，所以viper包提供了这个功能。它类似于单例模式。
在上面的所有示例中，它们都以其单例风格的方法演示了如何使用viper。
使用多个viper实例 你还可以在应用程序中创建许多不同的viper实例。每个都有自己独特的一组配置和值。每个人都可以从不同的配置文件，key value存储区等读取数据。每个都可以从不同的配置文件、键值存储等中读取。viper包支持的所有功能都被镜像为viper实例的方法。
例如：
x := viper.New() y := viper.New() x.SetDefault("ContentDir", "content") y.SetDefault("ContentDir", "foobar") //... 当使用多个viper实例时，由用户来管理不同的viper实例。
使用Viper示例 假设我们的项目现在有一个./conf/config.yaml配置文件，内容如下：
port: 8123 version: "v1.2.3" 接下来通过示例代码演示两种在项目中使用viper管理项目配置信息的方式。
直接使用viper管理配置 这里用一个demo演示如何在gin框架搭建的web项目中使用viper，使用viper加载配置文件中的信息，并在代码中直接使用viper.GetXXX()方法获取对应的配置值。
package main import ( "fmt" "net/http" "github.com/gin-gonic/gin" "github.com/spf13/viper" ) func main() { viper.SetConfigFile("config.yaml") // 指定配置文件 viper.AddConfigPath("./conf/") // 指定查找配置文件的路径 err := viper.ReadInConfig() // 读取配置信息 if err != nil { // 读取配置信息失败 panic(fmt.Errorf("Fatal error config file: %s \n", err)) } // 监控配置文件变化 viper.WatchConfig() r := gin.Default() // 访问/version的返回值会随配置文件的变化而变化 r.GET("/version", func(c *gin.Context) { c.String(http.StatusOK, viper.GetString("version")) }) if err := r.Run( fmt.Sprintf(":%d", viper.GetInt("port"))); err != nil { panic(err) } } 使用结构体变量保存配置信息 除了上面的用法外，我们还可以在项目中定义与配置文件对应的结构体，viper加载完配置信息后使用结构体变量保存配置信息。
package main import ( "fmt" "net/http" "github.com/fsnotify/fsnotify" "github.com/gin-gonic/gin" "github.com/spf13/viper" ) type Config struct { Port int `mapstructure:"port"` Version string `mapstructure:"version"` } var Conf = new(Config) func main() { viper.SetConfigFile("./conf/config.yaml") // 指定配置文件路径 err := viper.ReadInConfig() // 读取配置信息 if err != nil { // 读取配置信息失败 panic(fmt.Errorf("Fatal error config file: %s \n", err)) } // 将读取的配置信息保存至全局变量Conf if err := viper.Unmarshal(Conf); err != nil { panic(fmt.Errorf("unmarshal conf failed, err:%s \n", err)) } // 监控配置文件变化 viper.WatchConfig() // 注意！！！配置文件发生变化后要同步到全局变量Conf viper.OnConfigChange(func(in fsnotify.Event) { fmt.Println("夭寿啦~配置文件被人修改啦...") if err := viper.Unmarshal(Conf); err != nil { panic(fmt.Errorf("unmarshal conf failed, err:%s \n", err)) } }) r := gin.Default() // 访问/version的返回值会随配置文件的变化而变化 r.GET("/version", func(c *gin.Context) { c.String(http.StatusOK, Conf.Version) }) if err := r.Run(fmt.Sprintf(":%d", Conf.Port)); err != nil { panic(err) } } 参考文章 https://www.liwenzhou.com/posts/Go/viper_tutorial https://www.jianshu.com/p/7bb4f7f69280</content></entry><entry><title>Go操作redis</title><url>https://www.zhaohaiyu.com/post/go/go-redis/</url><categories><category>go</category><category>cache</category></categories><tags><tag>golang</tag><tag>redis</tag></tags><content type="html"> 安装 下载第三方包:
go get -u github.com/go-redis/redis/v9 连接 // 定义一个rdis客户端 var redisdb *redis.Client // 初始化 func initClient() (err error) { redisdb = redis.NewClient(&amp;redis.Options{ Addr: "localhost:6379", // post端口 Password: "", // 密码 DB: 0, // 使用redis的库 }) _, err = redisdb.Ping(context.Background()).Result() if err != nil { fmt.Println("连接失败") return } return } 使用 set/get示例 func redisExample() { ctx := context.Background() err := redisdb.Set(ctx, "score", 100, 0).Err() if err != nil { fmt.Printf("set score failed, err:%v\n", err) return } val, err := redisdb.Get(ctx, "score").Result() if err != nil { fmt.Printf("get score failed, err:%v\n", err) return } fmt.Println("score", val) val2, err := redisdb.Get(ctx, "name").Result() if err == redis.Nil { fmt.Println("name does not exist") } else if err != nil { fmt.Printf("get name failed, err:%v\n", err) return } else { fmt.Println("name", val2) } } zset示例 func redisExample2() { ctx := context.Background() zsetKey := "language_rank" languages := []*redis.Z{ &amp;redis.Z{Score: 90.0, Member: "Golang"}, &amp;redis.Z{Score: 98.0, Member: "Java"}, &amp;redis.Z{Score: 95.0, Member: "Python"}, &amp;redis.Z{Score: 97.0, Member: "JavaScript"}, &amp;redis.Z{Score: 99.0, Member: "C/C++"}, } // ZADD num, err := redisdb.ZAdd(ctx, zsetKey, languages...).Result() if err != nil { fmt.Printf("zadd failed, err:%v\n", err) return } fmt.Printf("zadd %d succ.\n", num) // 把Golang的分数加10 newScore, err := redisdb.ZIncrBy(ctx, zsetKey, 10.0, "Golang").Result() if err != nil { fmt.Printf("zincrby failed, err:%v\n", err) return } fmt.Printf("Golang's score is %f now.\n", newScore) // 取分数最高的3个 ret, err := redisdb.ZRevRangeWithScores(ctx, zsetKey, 0, 2).Result() if err != nil { fmt.Printf("zrevrange failed, err:%v\n", err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } // 取95~100分的 op := &amp;redis.ZRangeBy{ Min: "95", Max: "100", } ret, err = redisdb.ZRangeByScoreWithScores(ctx, zsetKey, op).Result() if err != nil { fmt.Printf("zrangebyscore failed, err:%v\n", err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } } 输出结果如下：
$ ./06redis_demo zadd 0 succ. Golang's score is 100.000000 now. Golang 100 C/C++ 99 Java 98 JavaScript 97 Java 98 C/C++ 99 Golang 100</content></entry><entry><title>Docker</title><url>https://www.zhaohaiyu.com/post/operations/docker/</url><categories><category>operations</category></categories><tags><tag>运维</tag><tag>docker</tag></tags><content type="html"> docker的定义 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现。 docker是linux容器的一种封装，提供简单易用的容器使用接口。它是最流行的Linux容器解决方案。 docker的接口相当简单，用户可以方便的创建、销毁容器。 docker将应用程序与程序的依赖，打包在一个文件里面。运行这个文件就会生成一个虚拟容器。 程序运行在虚拟容器里，如同在真实物理机上运行一样，有了docker，就不用担心环境问题了。
docker和虚拟机的区别 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱 系统支持量 单机支持上千个容器 一般几十个 虚拟机也可以制作模板，基于模板创建虚拟机，保证环境问题一致
虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。
虽然用户可以通过虚拟机还原软件的原始环境。但是，这个方案有几个缺点。
资源占用多冗余 步骤多 启动慢 用上docker容器后，可以实现开发、测试和生产环境的统一化和标准化。
镜像作为标准的交付件，可在开发、测试和生产环境上以容器来运行，最终实现三套环境上的应用以及运行所依赖内容的完全一致。
Linux容器不是模拟一个完整的操作系统，而是对进程进行隔离。在正常进程的外面套了一个保护层，对于容器里面进程来说，它接触的资源都是虚拟的，从而实现和底层系统的隔离。
启动快 资源占用少 体积小 docker容器的优势 更高效的利用系统资源 更快速的启动时间 持续交付和部署 更轻松的迁移 docker的三大概念 镜像 image Docker镜像就是一个只读的模板。 镜像可以用来创建Docker容器。 Docker提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 镜像的分层存储
因为镜像包含完整的root文件系统，体积是非常庞大的，因此docker在设计时按照Union FS的技术，将其设计为分层存储的架构。 镜像不是ISO那种完整的打包文件，镜像只是一个虚拟的概念，他不是一个完整的文件，而是由一组文件组成，或者多组文件系统联合组成。 容器 container 容器是镜像运行时的实体 容器可以被创建、启动、停止、删除、暂停 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的，保证安全的平台。 Docker利用容器来运行应用。 仓库 repository 仓库是集中存放镜像文件的场所。有时候把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签(tag)。 仓库分为公开仓库(Public)和私有仓库(Private)两种形式。 最大的公开仓库是Docker Hub，存放了数量庞大的镜像供用户下载。国内的公开仓库包括Docker Pool等，可以提供大陆用户更稳定快读的访问。 当用户创建了自己的镜像之后就可以使用push命令将它上传到公有或者私有仓库，这样下载在另外一台机器上使用这个镜像时候，只需需要从仓库上pull下来就可以了。 注意：Docker仓库的概念跟Git类似，注册服务器可以理解为GitHub这样的托管服务。 docker安装 卸载旧版本
sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 设置存储库
sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 安装docker社区版
sudo yum install docker-ce 启动关闭docker
systemctl start docker docker镜像加速
vim /etc/docker/daemon.json写以下内容
{ "registry-mirrors": ["https://kuamavit.mirror.aliyuncs.com", "https://registry.docker-cn.com","https://docker.mirrors.ustc.edu.cn"], "max-concurrent-downloads": 10, "storage-driver": "overlay2", "graph": "/data/docker", "log-driver": "json-file", "log-level": "warn", "log-opts": { "max-size": "10m", "max-file": "3" } } docker基本命令 选择参数:
&ndash;config=~/.dockerLocation of client config files 客户端配置文件的位置 -D, &ndash;debug=falseEnable debug mode 启用Debug调试模式 -H, &ndash;host=[]Daemon socket(s) to connect to 守护进程的套接字（Socket）连接 -h, &ndash;help=falsePrint usage 打印使用 -l, &ndash;log-level=infoSet the logging level 设置日志级别 &ndash;tls=falseUse TLS; implied by&ndash;tlsverify 证书 &ndash;tlscacert=~/.docker/ca.pemTrust certs signed only by this CA 信任证书签名CA &ndash;tlscert=~/.docker/cert.pemPath to TLS certificate file TLS证书文件路径 &ndash;tlskey=~/.docker/key.pemPath to TLS key file TLS密钥文件路径 &ndash;tlsverify=falseUse TLS and verify the remote 使用TLS验证远程 -v, &ndash;version=falsePrint version information and quit 打印版本信息并退出 指令:
attach Attach to a running container 当前shell下attach连接指定运行镜像 build Build an image from a Dockerfile 通过Dockerfile定制镜像 commit Create a new image from a container&rsquo;s changes 提交当前容器为新的镜像 cp Copy files/folders from a container to a HOSTDIR or to STDOUT 从容器中拷贝指定文件或者目录到宿主机中 create Create a new container 创建一个新的容器，同run 但不启动容器 diff Inspect changes on a container&rsquo;s filesystem 查看docker容器变化 events Get real time events from the server 从docker服务获取容器实时事件 exec Run a command in a running container 在已存在的容器上运行命令 export Export a container&rsquo;s filesystem as a tar archive 导出容器的内容流作为一个tar归档文件(对应import) history Show the history of an image 展示一个镜像形成历史 images List images 列出系统当前镜像 import Import the contents from a tarball to create a filesystem image 从tar包中的内容创建一个新的文件系统映像(对应export) info Display system-wide information 显示系统相关信息 inspect Return low-level information on a container or image 查看容器详细信息 kill Kill a running container kill指定docker容器 load Load an image from a tar archive or STDIN 从一个tar包中加载一个镜像(对应save) login Register or log in to a Docker registry 注册或者登陆一个docker源服务器 logout Log out from a Docker registry 从当前Docker registry退出 logs Fetch the logs of a container 输出当前容器日志信息 pause Pause all processes within a container 暂停容器 port List port mappings or a specific mapping for the CONTAINER 查看映射端口对应的容器内部源端口 ps List containers 列出容器列表 pull Pull an image or a repository from a registry 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to a registry 推送指定镜像或者库镜像至docker源服务器 rename Rename a container 重命名容器 restart Restart a running container 重启运行的容器 rm Remove one or more containers 移除一个或者多个容器 rmi Remove one or more images 移除一个或多个镜像(无容器使用该镜像才可以删除，否则需要删除相关容器才可以继续或者-f强制删除) run Run a command in a new container 创建一个新的容器并运行一个命令 save Save an image(s) to a tar archive 保存一个镜像为一个tar包(对应load) search Search the Docker Hub for images 在docker 镜像:
start Start one or more stopped containers 启动容器 stats Display a live stream of container(s) resource usage statistics 统计容器使用资源 stop Stop a running container 停止容器 tag Tag an image into a repository 给源中镜像打标签 top Display the running processes of a container 查看容器中运行的进程信息 unpause Unpause all processes within a container 取消暂停容器 version Show the Docker version information 查看容器版本号 wait Block until a container stops, then print its exit code 截取容器停止时的退出状态值 运行hello-world镜像 命令:docker run hello-world
[root@VM-0-3-centos ~]## docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 0e03bdcc26d7: Pull complete Digest: sha256:7f0a9f93b4aa3022c3a4c147a449bf11e0941a1fd0bf4a8e6c9408b2600777c5 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1\. The Docker client contacted the Docker daemon. 2\. The Docker daemon pulled the "hello-world" image from the Docker Hub. (amd64) 3\. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4\. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 运行linux容器 下载imagedocker pull centos
[root@VM-0-3-centos ~]## docker pull centos Using default tag: latest latest: Pulling from library/centos Digest: sha256:76d24f3ba3317fa945743bb3746fbaf3a0b752f10b10376960de01da70685fbd Status: Image is up to date for centos:latest docker.io/library/centos:latest 运行centosdocker run -it &ndash;rm centos bash
-i 是交互式操作，-t是终端 容器退出后将其删除 centos为镜像 指定用交互式的shell，因此需要bash命令 [root@VM-0-3-centos ~]## docker run -it --rm centos bash [root@33be613ee1eb /]## username -a bash: username: command not found [root@33be613ee1eb /]## cat /proc/version Linux version 3.10.0-1062.18.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Tue Mar 17 23:49:17 UTC 2020 [root@33be613ee1eb /]## exit exit [root@VM-0-3-centos ~]# 后台模式启动docker-d后台运行容器，返回容器ID
进入容器 使用-d参数时，容器启动后会进入后台,想进入容器操作
docker exec -it 容器id docker attach 容器id 提交创建自定义的镜像(docker container commit) 我们进入交互式的centos容器中，发现没有vim命令docker run -it centos
在当前容器中，安装一个vimyum install -y vim
安装好vim之后，exit退出容器exit
查看刚才安装好vim的容器记录docker container ls -a
提交这个容器，创建新的imagedocker commit 059fdea031ba zhy
查看镜像文件
外部访问容器 容器中可以运行网络应用，但是要让外部也可以访问这些应用，可以通过-p或-P参数指定端口映射。-P参数会随机映射端口到容器开放的网络端口 检查映射的端口docker ps -l 查看容器日志信息docker logs -f cfd不间断显示log 外部访问服务器的端口 查看指定容器的端口映射 docker port 76d
查看容器内的进程 docker top 76d
docer数据卷 Docker volume使用 Docker中的数据可以存储在类似于虚拟机磁盘的介质中，在Docker中称为数据卷（Data Volume）。数据卷可以用来存储Docker应用的数据，也可以用来在Docker容器间进行数据共享。 数据卷呈现给Docker容器的形式就是一个目录，支持多个容器间共享，修改也不会影响镜像。使用Docker的数据卷，类似在系统中使用 mount 挂载一个文件系统。
一个数据卷是一个特别指定的目录，该目录利用容器的UFS文件系统可以为容器提供一些稳定的特性或者数据共享。数据卷可以在多个容器之间共享。 创建数据卷，只要在docker run命令后面跟上-v参数即可创建一个数据卷，当然也可以跟多个-v参数来创建多个数据卷，当创建好带有数据卷的容器后， 就可以在其他容器中通过&ndash;volumes-froms参数来挂载该数据卷了，而不管该容器是否运行。也可以在Dockerfile中通过VOLUME指令来增加一个或者多个数据卷。 如果有一些数据想在多个容器间共享，或者想在一些临时性的容器中使用该数据，那么最好的方案就是你创建一个数据卷容器，然后从该临时性的容器中挂载该数据卷容器的数据。这样，即使删除了刚开始的第一个数据卷容器或者中间层的数据卷容器，只要有其他容器使用数据卷，数据卷都不会被删除的。 不能使用docker export、save、cp等命令来备份数据卷的内容，因为数据卷是存在于镜像之外的。备份的方法可以是创建一个新容器，挂载数据卷容器，同时挂载一个本地目录，然后把远程数据卷容器的数据卷通过备份命令备份到映射的本地目录里面。如下：docker run -rm &ndash;volumes-from DATA -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data 也可以把一个本地主机的目录当做数据卷挂载在容器上，同样是在docker run后面跟-v参数，不过-v后面跟的不再是单独的目录了，它是[host-dir]:[container-dir]:[rw|ro]这样格式的，host-dir是一个绝对路径的地址，如果host-dir不存在，则docker会创建一个新的数据卷，如果host-dir存在，但是指向的是一个不存在的目录，则docker也会创建该目录，然后使用该目录做数据源。 Docker Volume数据卷可以实现：
绕过“拷贝写”系统，以达到本地磁盘IO的性能，（比如运行一个容器，在容器中对数据卷修改内容，会直接改变宿主机上的数据卷中的内容，所以是本地磁盘IO的性能，而不是先在容器中写一份，最后还要将容器中的修改的内容拷贝出来进行同步。） 绕过“拷贝写”系统，有些文件不需要在docker commit打包进镜像文件。 数据卷可以在容器间共享和重用数据 数据卷可以在宿主和容器间共享数据 数据卷数据改变是直接修改的 数据卷是持续性的，直到没有容器使用它们。即便是初始的数据卷容器或中间层的数据卷容器删除了，只要还有其他的容器使用数据卷，那么里面的数据都不会丢失。 Docker数据持久化：
容器在运行期间产生的数据是不会写在镜像里面的，重新用此镜像启动新的容器就会初始化镜像，会加一个全新的读写入层来保存数据。 如果想做到数据持久化，Docker提供数据卷（Data volume）或者数据容器卷来解决问题，另外还可以通过commit提交一个新的镜像来保存产生的数据。 创建一个数据卷 docker run -it &ndash;name=myubuntu -v /home/flynngod/bin/MainDataVolume:/ContainerDataVolume /bin/hash
&ndash;name是给创建的容器取名 -v后的MainDataVolume是在宿主机上创建的文件夹名，用 : 将宿主机和容器的路径隔开；ContainerDataVolume是容器上的 创建完成后，在容器中touch文件test.txt并写入一行字符串： 在宿主机中可以看到同样的文件:
同样的，如果在宿主机这端创建文件或者修改文件，容器中也会有相同的变化。如果说，容器中只能有读取文件权限，而无法修改的话，可以这么写&hellip;. -v /home/flynngod/bin/MainDataVolume:/ContainerDataVolume:ro，在-v后添加:ro就行了。如果需要创建多个容器数据卷，那么久在后面再添加一个 -v + 宿主机和容器的目录路径。 数据卷的备份和还原 数据卷备份使用的命令： docker run &ndash;volumes-from 存在的容器名 -v $(pwd):/backup &ndash;name 新建的容器名 镜像名 tar cvf /backup/backup.tar 数据卷
backup.tar压缩文件只是对容器中的ContainerDataVolume文件夹的压缩。同时会生成容器的备份容器，使用docker ps -a可以查看到。
数据卷还原的命令: docker run &ndash;volumes-from 存在的容器名 -v $(pwd):/backup &ndash;name 新建的容器名 镜像名 tar xvf /backup/backup.tar
删除数据卷 Volume 只有在下列情况下才能被删除：
docker rm -v删除容器时添加了-v选项 docker run &ndash;rm运行容器时添加了&ndash;rm选项 否则，会在/var/lib/docker/volumes目录中遗留很多不明目录。
dockerfile FROM FROM FROM指定构建镜像的基础源镜像，如果本地没有指定的镜像，则会自动从 Docker 的公共库 pull 镜像下来。
FROM必须是 Dockerfile 中非注释行的第一个指令，即一个 Dockerfile 从FROM语句开始。
如果FROM语句没有指定镜像标签，则默认使用latest标签。
FROM可以在一个 Dockerfile 中出现多次，如果有需求在一个 Dockerfile 中创建多个镜像。
MAINTAINER MAINTAINER 指定创建镜像的用户 RUN RUN "executable", "param1", "param2" 每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像，后续的RUN都在之前RUN提交后的镜像为基础，镜像是分层的，可以通过一个镜像的任何一个历史提交点来创建，类似源码的版本控制。 CMD CMD的目的是为了在启动容器时提供一个默认的命令执行选项。如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。 CMD指定在 Dockerfile 中只能使用一次，如果有多个，则只有最后一个会生效。 CMD ["executable","param1","param2"] CMD ["param1","param2"] CMD command param1 param2 (shell form) RUN 和CMD的区别： CMD会在启动容器的时候执行，build 时不执行。 RUN只是在构建镜像的时候执行
EXPOSE EXPOSE [...] 告诉 Docker 服务端容器对外映射的本地端口，需要在 docker run 的时候使用-p或者-P选项生效 ENV ENV ## 只能设置一个变量 ENV = ... ## 允许一次设置多个变量 指定一个环境变量，会被后续RUN指令使用，可以在容器内被脚本或者程序调用。 ADD ADD ... ADD复制本地主机文件、目录到目标容器的文件系统中。
如果源是一个URL，该URL的内容将被下载并复制到目标容器中。
COPY COPY ... COPY复制新文件或者目录到目标容器指定路径中 。
用法和功能同ADD，区别在于不能用URL，ADD功能更强大些。
ENTRYPOINT ENTRYPOINT ["executable", "param1", "param2"] ENTRYPOINT command param1 param2 (shell form) 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，而CMD是可以被覆盖的。如果需要覆盖，则可以使用docker run &ndash;entrypoint选项。 每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个生效。 疑问: ENTRYPOINT 和 CMD 可同时存在吗？ 测试结果：可以的。 两者使用场景： ENTRYPOINT 用于稳定-不被修改的执行命令。 CMD 用于 可变的命令。
VOLUME VOLUME ["/data"] 将本地主机目录挂载到目标容器中
将其他容器挂载的挂载点 挂载到目标容器中
USER USER mysql 指定运行容器时的用户名或 UID，
在这之后的命令如RUN、CMD、ENTRYPOINT也会使用指定用户
WORKDIR WORKDIR /path/to/workdir 切换目录，相当于cd ONBUILD ONBUILD [INSTRUCTION] 使用该dockerfile生成的镜像A，并不执行ONBUILD中命令 如再来个dockerfile 基础镜像为镜像A时，生成的镜像B时就会执行ONBUILD中的命令 docker-compose docker-compose是 docker 官方的开源项目，使用 python 编写，实现上调用了 Docker 服务的 API 进行容器管理。其官方定义为为 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）），其实就是上面所讲的功能。
安装 sudo curl -L &ldquo;https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)&rdquo; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose &ndash;version查看 简介 类似 docker 的Dockerfile文件，docker-compose使用 YAML 文件对容器进行管理。
对于 docker-compose 有两个基本的概念：
服务(service)：一个应用容器，即 docker 容器，比如之前所说的mysql 容器、nginx 容器 项目(project)：由一组关联的应用容器组成的一个完整业务单元，比如上面所讲的由 mysql、web app、nginx 容器组成的网站。docker-compose 面向项目进行管理。 YAML 文件格式。
1.大小写敏感，缩进表示表示层级关系
2.缩进空格数不重要，相同层级左侧对齐即可。（不允许使用 tab 缩进！）
3.由冒号分隔的键值对表示对象；一组连词线开头的行，构成一个数组；字符串默认不使用引号
docker-compose区域 services
服务，在它下面可以定义应用需要的一些服务，每个服务都有自己的名字、使用的镜像、挂载的数据卷、所属的网络、依赖哪些其他服务等等。 volumes
数据卷，在它下面可以定义的数据卷（名字等等），然后挂载到不同的服务下去使用。 networks
应用的网络，在它下面可以定义应用的名字、使用的网络类型等等。 version: '2.0' services: nginx: restart: always image: nginx:1.11.6-alpine ports: - 8080:80 - 80:80 - 443:443 volumes: - ./conf.d:/etc/nginx/conf.d - ./log:/var/log/nginx - ./www:/var/www - /etc/letsencrypt:/etc/letsencrypt docker-compose命令 启动:docker-compose up -d-d为守护进程 查看服务进程 :docker-compose ps 停止服务:docker-compose stop [name] 启动服务:docker-compose start [name] 删除服务:docker-compose rm [name] 查看具体服务的日志:docker-compose logs -f [name] 可以进入容器内部:docker-compose exec [name] shell 说明 命令 build 构建项目中的服务容器 help 获得一个命令的帮助 kill 通过发送SIGKILL信号来强制停止服务容器 config 验证和查看compose文件配置 create 为服务创建容器。只是单纯的create，还需要使用start启动compose down 停止并删除容器，网络，镜像和数据卷 exec 在运行的容器中执行一个命令 logs 查看服务容器的输出 pause 暂停一个服务容器 port 打印某个容器端口所映射的公共端口 ps 列出项目中目前的所有容器 pull 拉取服务依赖的镜像 push 推送服务镜像 restart 重启项目中的服务 rm 删除所有（停止状态的）服务容器 run 在指定服务上执行一个命令 scale 设置指定服务运行的容器个数 start 启动已经存在的服务容器 stop 停止已经处于运行状态的容器，但不删除它 top 显示运行的进程 unpause 恢复处于暂停状态中的服务 up 自动完成包括构建镜像、创建服务、启动服务并关闭关联服务相关容器的一些列操作 参考文章:
https://www.cnblogs.com/pyyu/p/9485268.html https://www.jianshu.com/p/b027c61346af https://zhuanlan.zhihu.com/p/51055141 https://www.jianshu.com/p/93a678d1bde6</content></entry><entry><title>grpc基础</title><url>https://www.zhaohaiyu.com/post/microservice/grpc/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>protobuf</tag><tag>grpc</tag></tags><content type="html"> RPC 框架原理 RPC 框架的目标就是让远程服务调用更加简单、透明，RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、序列化方式（XML/Json/ 二进制）和通信细节。服务调用者可以像调用本地接口一样调用远程的服务提供者，而不需要关心底层通信细节和调用过程。
业界主流的 RPC 框架整体上分为三类：
支持多语言的 RPC 框架，比较成熟的有 Google 的 gRPC、facebook的Apache、Thrift； 只支持特定语言的 RPC 框架，例如新浪微博的 Motan； 支持服务治理等服务化特性的分布式服务框架，其底层内核仍然是 RPC 框架, 例如阿里的 Dubbo。 gRPC是什么 gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C## 支持.
gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。
grc优点 多语言：语言中立，支持多种语言。 轻量级、高性能：序列化支持 PB(Protocol Buffer)和 JSON，PB 是一种语言无关的高性能序列化框架。 可插拔 IDL：基于文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。 移动端：基于标准的 HTTP2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性，这些特性使得 gRPC 在移动端设备上更加省电和节省网络流量。 安全 HTTP2 规范当使用 TLS 时强制使用 TLS 1.2 及以上的版本，并且在部署上对允许的密码施加一些额外的限制以避免已知的比如需要 SNI 支持的问题。并且期待 HTTP2 与专有的传输安全机制相结合，这些传输机制的规格说明不能提供有意义的建议。
gRPC使用 使用gRPC， 我们可以一次性的在一个.proto文件中定义服务并使用任何支持它的语言去实现客户端和服务端，反过来，它们可以应用在各种场景中，从Google的服务器到你自己的平板电脑—— gRPC帮你解决了不同语言及环境间通信的复杂性。使用protocol buffers还能获得其他好处，包括高效的序列号，简单的IDL以及容易进行接口更新。总之一句话，使用gRPC能让我们更容易编写跨语言的分布式代码。
通过一个 protocol buffers 模式，定义一个简单的带有 Hello World 方法的 RPC 服务。 用你最喜欢的语言(如果可用的话)来创建一个实现了这个接口的服务端。 用你最喜欢的(或者其他你愿意的)语言来访问你的服务端。 什么用grpc 服务而非对象、消息而非引用：促进微服务的系统间粗粒度消息交互设计理念。 负载无关的：不同的服务需要使用不同的消息类型和编码，例如 protocol buffers、JSON、XML 和 Thrift。 流：Streaming API。 阻塞式和非阻塞式：支持异步和同步处理在客户端和服务端间交互的消息序列。 元数据交换：常见的横切关注点，如认证或跟踪，依赖数据交换。 标准化状态码：客户端通常以有限的方式响应 API 调用返回的错误。 HealthCheck gRPC 有一个标准的健康检测协议，在 gRPC 的所有语言实现中基本都提供了生成代码和用于设置运行状态的功能。
主动健康检查 health check，可以在服务提供者服务不稳定时，被消费者所感知，临时从负载均衡中摘除，减少错误请求。当服务提供者重新稳定后，health check 成功，重新加入到消费者的负载均衡，恢复请求。health check，同样也被用于外挂方式的容器健康检测，或者流量检测(k8s liveness &amp; readiness)。
protubuf文件编写 syntax = "proto3"; package hello; // option go_package = "hello"; option go_package = "/hello"; // The greeting service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {} } // The request message containing the user's name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloReply { string message = 1; } golang创建grpc server 安装工具包:
下载protoc 链接 go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 执行:
protoc --go_out=./ --go-grpc_out=./ hello.proto &ndash;proto_path: 指定了要去哪个目录中搜索import中导入的和要编译为.go的proto文件 (在这没有使用,需要的话可以加上) &ndash;go_out:指定了生成的go文件的目录，我在这里把go文件放到本目录中 &ndash;go-grpc_out: 指定了生成的go grpc文件的目录，我在这里把go grpc文件放到本目录中 hello.proto， 定义了我要编译的文件是哪个文件。 go server代码 package main import ( "context" "errors" "fmt" "github.com/zhaohaiyu1996/akit/example/grpc/hello" "google.golang.org/grpc" "net" ) type Server struct { hello.UnimplementedGreeterServer } // SayHello implements helloworld.GreeterServer func (s *Server) SayHello(ctx context.Context, in *hello.HelloRequest) (*hello.HelloReply, error) { if in.Name == "error" { return nil, errors.New("123") } if in.Name == "panic" { panic("grpc panic") } return &amp;hello.HelloReply{Message: fmt.Sprintf("Hello %+v", in.Name)}, nil } type Ss struct { *grpc.Server } func main() { // 监听本地的8848端口 s := Ss{grpc.NewServer()} hello.RegisterGreeterServer(s, &amp;Server{}) // 在gRPC服务端注册服务 lis, err := net.Listen("tcp", "127.0.0.1:8808") if err != nil { fmt.Printf("listen failed: %v", err) return } //reflection.Register(s.Server) //在给定的gRPC服务器上注册服务器反射服务 // Serve方法在lis上接受传入连接，为每个连接创建一个ServerTransport和server的goroutine。 // 该goroutine读取gRPC请求，然后调用已注册的处理程序来响应它们。 err = s.Serve(lis) if err != nil { fmt.Printf("failed to serve: %v", err) return } } golang创建grpc client 执行:
protoc --go_out=./ --go-grpc_out=./ hello.proto go client代码 package main import ( "context" "fmt" "github.com/zhaohaiyu1996/akit/example/grpc/hello" "google.golang.org/grpc" ) func main() { // 连接服务器 conn, err := grpc.Dial("localhost:8808", grpc.WithInsecure()) if err != nil { fmt.Printf("connect faild: %v", err) } defer conn.Close() c := hello.NewGreeterClient(conn) // 调用SayHello r, err := c.SayHello(context.Background(), &amp;hello.HelloRequest{Name: "zhaohaiyu"}) if err != nil { fmt.Printf("sayHello failed: %v", err) } fmt.Println(r) } 结果:
SayHello: hello ---> zhaohaiyu python创建grpc client 使用python客户端调用golang服务端的方法
下载依赖:
pip install grpcio pip install protobuf pip install grpcio_tools 执行:
python -m grpc_tools.protoc -I ./ --python_out=./ --grpc_python_out=./ hello.proto python client代码 import grpc import hello_pb2 import hello_pb2_grpc def run(): with grpc.insecure_channel('localhost:8848') as channel: stub = hello_pb2_grpc.HelloStub(channel) res = stub.SayHello(hello_pb2.HelloRequest(name="赵海宇")) print(res.message) if __name__ == '__main__': run() 结果:
python ./main.go hello ---> 赵海宇 gprc的haeder grpc是基于http2.0的rpc框架 - grpc对于http头部传递数据进行了封装 metadata,单独抽象了一个包google.golang.org/grpc/metadata- type ***p[string][]string其实就是一个map 客户端发送方式一:
// 创建md 并加入ctx md := metadata.Pairs("key1","value1","key2","value2") ctx := metadata.NewOutgoingContext(context.Background(),md) // 从ctx中拿出md md,_ = metadata.FromOutgoingContext(ctx) newMd := metadata.Pairs("key3","value3") ctx = metadata.NewOutgoingContext(ctx,metadata.Join(md,newMd)) 客户端发送方式二:
ctx := context.Background() ctx = metadata.AppendToOutgoingContext(ctx,"key1","value1","key2","value2") ctx = metadata.AppendToOutgoingContext(ctx,"key3","value3") 服务端接收:
md,ok := metadata.FromIncomingContext(ctx) 实例:
server: package main import ( "fmt" "net" pb "test/demo13/server/hello" "github.com/grpc-ecosystem/grpc-gateway/examples/clients/responsebody" "github.com/uber/jaeger-client-go/crossdock/client" "golang.org/x/net/context" "google.golang.org/grpc" "google.golang.org/grpc/metadata" "google.golang.org/grpc/reflection" ) type server struct{} func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloResponse, error) { md,ok := metadata.FromIncomingContext(ctx) if ok { fmt.Println(md) } return &amp;pb.HelloResponse{Message: "hello ---> " + in.Name}, nil } func main() { // 监听本地的8848端口 lis, err := net.Listen("tcp", "localhost:8848") if err != nil { fmt.Printf("listen failed: %v", err) return } s := grpc.NewServer() // 创建gRPC服务器 pb.RegisterHelloServer(s, &amp;server{}) // 在gRPC服务端注册服务 reflection.Register(s) //在给定的gRPC服务器上注册服务器反射服务 // Serve方法在lis上接受传入连接，为每个连接创建一个ServerTransport和server的goroutine。 // 该goroutine读取gRPC请求，然后调用已注册的处理程序来响应它们。 err = s.Serve(lis) if err != nil { fmt.Printf("failed to serve: %v", err) return } } client package main import ( "context" "fmt" pb "test/demo13/client/hello" "google.golang.org/grpc" "google.golang.org/grpc/metadata" ) func main() { // 连接服务器 conn, err := grpc.Dial("localhost:8848", grpc.WithInsecure()) if err != nil { fmt.Printf("faild to connect: %v", err) } defer conn.Close() c := pb.NewHelloClient(conn) // 调用服务端的SayHello ctx := context.Background() ctx = metadata.AppendToOutgoingContext(ctx,"zhyyz","961119") r, err := c.SayHello(ctx, &amp;pb.HelloRequest{Name: "zhaohaiyu"}) if err != nil { fmt.Printf("sayHello failed: %v", err) } fmt.Printf("SayHello: %s \n", r.Message) }</content></entry><entry><title>proto bufer</title><url>https://www.zhaohaiyu.com/post/microservice/protobufer/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>protobuf</tag></tags><content type="html"> protobuf是一种高效的数据格式，平台无关、语言无关、可扩展，可用于 RPC 系统和持续数据存储系统。
protobuf介绍 Protobuf是Protocol Buffer的简称，它是Google公司于2008年开源的一种高效的平台无关、语言无关、可扩展的数据格式，目前Protobuf作为接口规范的描述语言，可以作为Go语言RPC接口的基础工具。
protobuf使用 protobuf是一个与语言无关的一个数据协议，所以我们需要先编写IDL文件然后借助专用工具生成指定语言的代码，从而实现数据的序列化与反序列化过程。
大致开发流程如下： 1. IDL编写 2. 生成指定语言的代码 3. 序列化和反序列化
protobuf语法 官网：https://developers.google.cn/protocol-buffers/docs/proto3 (英文)
三方：https://colobu.com/2017/03/16/Protobuf3-language-guide (中文)
编译器安装 ptotoc mac安装：
brew info protobuf cdn下载：(下载需要的版本)
cdn下载链接 linux/mac 编译安装
教程 protoc-gen-go 安装生成Go语言代码的工具
两个版本：
github版本 github.com/golang/protobuf/protoc-gen-go google版本 google.golang.org/protobuf/cmd/protoc-gen-go 区别在于前者是旧版本，后者是google接管后的新版本，他们之间的API是不同的，也就是说用于生成的命令，以及生成的文件都是不一样的。
因为目前的gRPC-go源码中的example用的是后者的生成方式，为了与时俱进，本文也采取最新的方式。
安装：
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 编写IDL代码 新建一个名为person.proto的文件具体内容如下：
// 指定使用protobuf版本 // 此处使用v3版本 syntax = "proto3"; // 包名，通过protoc生成go文件 package address; // go的包名 新版protoc-gen-go 必须带"/" option go_package = "../hello"; // 性别类型 // 枚举类型第一个字段必须为0 enum GenderType { SECRET = 0; FEMALE = 1; MALE = 2; } // 人 message Person { int64 id = 1; string name = 2; GenderType gender = 3; string number = 4; } // 联系簿 message ContactBook { repeated Person persons = 1; } 生成go语言代码 在protobuf_demo/address目录下执行以下命令。
protoc --proto_path=./ --go_out=./ ./person.proto &ndash;proto_path: 指定了要去哪个目录中搜索import中导入的和要编译为.go的proto文件 &ndash;go_out:指定了生成的go文件的目录，我在这里把go文件放到本目录中 person.proto， 定义了我要编译的文件是哪个文件。 此时在当前目录下会生成一个person.pb.go文件，我们的Go语言代码里就是使用这个文件。 在protobuf_demo/main.go文件中：
package main import ( "fmt" "io/ioutil" "z/test3/person" "github.com/golang/protobuf/proto" ) func main() { var cb person.ContactBook p1 := person.Person{ Name: "zhao", Gender: person.GenderType_MALE, Number: "12345678910", } fmt.Println(p1) cb.Persons = append(cb.Persons, &amp;p1) data, err := proto.Marshal(&amp;p1) if err != nil { fmt.Printf("marshal failed,err:%v\n", err) return } ioutil.WriteFile("./proto.dat", data, 0644) data2, err := ioutil.ReadFile("./proto.dat") if err != nil { fmt.Printf("read file failed, err:%v\n", err) return } var p2 person.Person proto.Unmarshal(data2, &amp;p2) fmt.Println(p2) } 参考文章:https://www.liwenzhou.com/posts/Go/protobuf/</content></entry><entry><title>微服务架构及raft协议</title><url>https://www.zhaohaiyu.com/post/microservice/microservice-raft/</url><categories><category>microservice</category></categories><tags><tag>微服务</tag><tag>raft</tag></tags><content type="html"> 微服务架构全景图 服务注册和发现 Client side implement
调用需要维护所有调用服务的地址 有一定的技术难度，需要rpc框架支持 Server side implement
架构简单 有单点故障 注册中心 etcd注册中心
分布式一致性系统 基于raft一致性协议 etcd使用场景
服务注册和发现 共享配置 分布式锁 Leader选举 Raft协议详解 应用场景
解决分布式系统一致性的问题 基于复制的 工作机制
leader选举 日志复制 安全性 基本概念 raft协议演示：http://www.kailing.pub/raft/index.html
角色
Follower角色 Leader角色 Candicate角色 Term（任期）概念
在raft协议中，将时间分成一个个term（任期） 复制状态机 在一个分布式系统数据库中,如果每个节点的状态一致,每个节点都执行相同的命令序列,那么最终他们会得到一个一致的状态。也就是和说,为了保证整个分布式系统的一致性,我们需要保证每个节点执行相同的命令序列,也就是说每个节点的日志要保持一样。所以说,保证日志复制一致就是Raf等一致性算法的工作了
这里就涉及 Replicated State Machine(复制状态机),如上图所示。在一个节点上,一致性模块( Consensus Module,也就是分布式共识算法)接收到了来自客户端的命令。然后把接收到的命令写入到日志中,该节点和其他节点通过一致性模块进行通信确保每个日志最终包含相同的命令序列。一旦这些日志的命令被正确复制,每个节点的状态机( State Machine)都会按照相同的序列去执行他们,从而最终得到一致的状态。然后将达成共识的结果返回给客户端,如下图所示。
心跳（heartbeats）和超时机制（timeout） 在Ra算法中,有两个 timeout机制来控制领导人选举一个是选举定时器( elation timeou):
即 Follower等待成为 Candidate状态的等待时间,这个时间被随机设定为150ms-300ms之间
另一个是 headrbeat timeout:在某个节点成为 Leader以后,它会发送 Append Entries消息给其他节点,这些消息就是通过 heartbeat timeout来传送, Follower接收到 Leader的心跳包的同时也重置选举定时器
Leader选举 Raft 的选举过程 Raft 协议在集群初始状态下是没有 Leader 的, 集群中所有成员均是 Follower，在选举开始期间所有 Follower 均可参与选举，这时所有 Follower 的角色均转变为 Condidate, Leader 由集群中所有的 Condidate 投票选出，最后获得投票最多的 Condidate 获胜，其角色转变为 Leader 并开始其任期，其余落败的 Condidate 角色转变为 Follower 开始服从 Leader 领导。这里有一种意外的情况会选不出 Leader 就是所有 Condidate 均投票给自己，这样无法决出票数多的一方，Raft 算法为了解决这个问题引入了北洋时期袁世凯获选大总统的谋略，即选不出 Leader 不罢休，直到选出为止，一轮选不出 Leader，便令所有 Condidate 随机 sleap（Raft 论文称为 timeout）一段时间，然后马上开始新一轮的选举，这里的随机 sleep 就起了很关键的因素，第一个从 sleap 状态恢复过来的 Condidate 会向所有 Condidate 发出投票给我的申请，这时还没有苏醒的 Condidate 就只能投票给已经苏醒的 Condidate ，因此可以有效解决 Condiadte 均投票给自己的故障，便可快速的决出 Leader。
选举出 Leader 后 Leader 会定期向所有 Follower 发送 heartbeat 来维护其 Leader 地位，如果 Follower 一段时间后未收到 Leader 的心跳则认为 Leader 已经挂掉，便转变自身角色为 Condidate，同时发起新一轮的选举，产生新的 Leader。
Raft 的数据一致性策略 Raft 协议强依赖 Leader 节点来确保集群数据一致性。即 client 发送过来的数据均先到达 Leader 节点，Leader 接收到数据后，先将数据标记为 uncommitted 状态，随后 Leader 开始向所有 Follower 复制数据并等待响应，在获得集群中大于 N/2 个 Follower 的已成功接收数据完毕的响应后，Leader 将数据的状态标记为 committed，随后向 client 发送数据已接收确认，在向 client 发送出已数据接收后，再向所有 Follower 节点发送通知表明该数据状态为committed。
Raft 如何处理 Leader 意外的？ client 发送数据到达 Leader 之前 Leader 就挂了，因为数据还没有到达集群内部，所以对集群内部数据的一致性没有影响，Leader 挂了之后，集群会进行新的选举产生新的 Leader，之前挂掉的 Leader 重启后作为 Follower 加入集群，并同步 Leader 上的数据。这里最好要求 client 有重试机制在一定时间没有收到 Leader 的数据已接收确认后进行一定次数的重试，并再次向新的 Leader 发送数据来确保业务的流畅性。 client 发送数据到 Leader，数据到达 Leader 后，Leader 还没有开始向 Folloers 复制数据，Leader就挂了，此时数据仍被标记为 uncommited 状态，这时集群会进行新的选举产生新的 Leader，之前挂掉的 Leader 重启后作为 Follower 加入集群，并同步 Leader 上的数据，来保证数据一致性，之前接收到 client 的数据由于是 uncommited 状态所以可能会被丢弃。这里同样最好要求 client 有重试机制通过在一定时间在没有收到 Leader 的数据已接收确认后进行一定次数的重试，再次向新的 Leader 发送数据来确保业务的流畅性。 client 发送数据到 Leader, Leader 接收数据完毕后标记为 uncommited，开始向 Follower复制数据，在复制完毕一小部分 Follower 后 Leader 挂了，此时数据在所有已接收到数据的 Follower 上仍被标记为 uncommitted，但国不可一日无君，此时集群将进行新的选举，而拥有最新数据的 Follower 变换角色为 Condidate，也就意味着 Leader 将在拥有最新数据的 Follower 中产生，新的 Leader 产生后所有节点开始从新 Leader 上同步数据确保数据的一致性，包括之前挂掉后恢复了状态的 老Leader，这时也以 Follower 的身份同步新 Leader 上的数据。 client 发送数据到 Leader，Leader 接收数据完毕后标记为 uncommitted，开始向 Follower 复制数据，在复制完毕所有 Follower 节点或者大部分节点（大于 N/2），并接收到大部分节点接收完毕的响应后，Leader 节点将数据标记为 committed，这时 Leader 挂了，此时已接收到数据的所有 Follower 节点上的数据状态由于还没有接收到 Leader 的 commited 通知，均处于 uncommited 状态。这时集群进行了新的选举，新的 Leader 将在拥有最新数据的节点中产生，新的 Leader 产生后，由于 client 端因老 Leader 挂掉前没有通知其数据已接收，所以会向新的 Leader 发送重试请求，而新的 Leader 上已经存在了这个之前从老 Leader 上同步过来的数据，因此 Raft 集群要求各节点自身实现去重的机制，保证数据的一致性。 集群脑裂的一致性处理，多发于双机房的跨机房模式的集群。假设一个 5 节点的 Raft 集群，其中三个节点在 A 机房，Leader 节点也在 A 机房，两个节点在 B 机房。突然 A、B 两个机房之间因其他故障无法通讯，那么此时 B 机房中的 2 个Follower 因为失去与 Leader 的联系，均转变自身角色为 Condidate。根据 Leader 选举机制，B 机房中产生了一个新的 Leader，这就发生了脑裂即存在 A 机房中的老 Leader 的集群与B机房新 Leader 的集群。Raft 针对这种情况的处理方式是老的 Leader 集群虽然剩下三个节点，但是 Leader 对数据的处理过程还是在按原来 5 个节点进行处理，所以老的 Leader 接收到的数据，在向其他 4 个节点复制数据，由于无法获取超过 N/2 个 Follower 节点的复制完毕数据响应（因为无法连接到 B 机房中的 2个节点），所以 client 在向老 Leader 发送的数据请求均无法成功写入，而 client 向B机房新 Leader 发送的数据，因为是新成立的集群，所以可以成功写入数据，在A、B两个机房恢复网络通讯后，A 机房中的所有节点包括老 Leader 再以 Follower 角色接入这个集群，并同步新 Leader 中的数据，完成数据一致性处理。 参考文章 https://www.jianshu.com/p/aa77c8f4cb5c</content></entry><entry><title>Go HTML标签提取器soup</title><url>https://www.zhaohaiyu.com/post/go/go-soup/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 什么是soup 类似python中beatifulsoup，用于提取html标签提取，多用于爬虫。它可以很好的处理不规范标记并生成剖析树(parse tree)。 它提供简单又常用的导航，搜索以及修改剖析树的操作。利用它我们不在需要编写正则表达式就可以方便的实现网页信息的提取。soup是一个小型的网页提取包，其接口与beauthoulsoup非常相似。
下载 go get github.com/anaskhan96/soup 接口 var Headers map[string]string 将头文件设置为键-值对的映射，这是单独调用Header()的替代方法 var Cookies map[string]string 将Cookie设置为键-值对的映射，这是单独调用Cookie()的另一种方法 func Get(string) (string,error) {} 将url作为参数，返回HTML字符串 func GetWithClient(string, *http.Client) {} 将url和自定义HTTP客户端作为参数，返回HTML字符串 func Post(string, string, interface{}) (string, error) {} 以url、bodyType和负载为参数，返回HTML字符串 func PostForm(string, url.Values) {} 接受url和正文。bodyType设置为“application/x-www-form-urlencoded func Header(string, string) {} 接受key，value对，将其设置为Get（）中的HTTP请求的头 func Cookie(string, string) {} 接受key，value对，将其设置为要与Get（）中的HTTP请求一起发送的Cookie func HTMLParse(string) Root {} 以HTML字符串为参数，返回一个指向构造的DOM的指针 func Find([]string) Root {} Element标记，（属性键值对）作为参数，返回指向第一个出现的指针 func FindAll([]string) []Root {} 与Find（）相同，但返回指向所有匹配项的指针 func FindStrict([]string) Root {} Element tag，（attribute key-value pair）作为参数，指向第一次出现的指针返回了完全匹配的值 func FindAllStrict([]string) []Root {} 与FindStrict（）相同，但指向返回的所有引用的指针 func FindNextSibling() Root {} find指向同一个functing}元素的下一个functing}指针 func FindNextElementSibling() Root {} 指向返回的DOM中元素的下一个同级元素的指针 func FindPrevSibling() Root {} 指向返回的DOM中元素的上一个同级的指针 func FindPrevElementSibling() Root {} 指向返回的DOM中元素的上一个同级元素的指针 func Children() []Root {} 查找此DOM元素的所有直接子级 func Attrs() map[string]string {} map返回元素的所有属性作为对其各自值的查找 func Text() string {} 返回非嵌套标记内的全文，在嵌套标记中返回前半部分e func FullText() string {} 返回嵌套/非嵌套标记内的全文 func SetDebug(bool) {} 将调试模式设置为true或false；默认为false func HTML() {} HTML返回特定元素的HTML代码 例子 package main import ( "fmt" "os" "github.com/anaskhan96/soup" ) func main() { resp, err := soup.Get("http://zhaohaiyu.com") if err != nil { os.Exit(1) } doc := soup.HTMLParse(resp) links := doc.Find("div", "class", "res-cons").FindAll("article","class","post") fmt.Println(links) for _, link := range links { l := link.Find("a") fmt.Println(l.Text(), "-------->", l.Attrs()["href"]) } } 结果
【置顶】golang目录 --------> https://zhaohaiyu.com/post/go/go_catalog/ go语言文件系统 --------> https://zhaohaiyu.com/post/go/go_file/ Flex --------> https://zhaohaiyu.com/post/javascript/flex/ makefile --------> https://zhaohaiyu.com/post/go/makefile/ air热加载 --------> https://zhaohaiyu.com/post/go/air/ thrift的介绍及其使用 --------> https://zhaohaiyu.com/post/go/thrift/ golang中间件的实现 --------> https://zhaohaiyu.com/post/go/middleware/ zap高性能日志 --------> https://zhaohaiyu.com/post/go/zap/ viper配置管理 --------> https://zhaohaiyu.com/post/go/viper/ proto Prometheus --------> https://zhaohaiyu.com/post/go/promethues/</content></entry><entry><title>Go单元测试</title><url>https://www.zhaohaiyu.com/post/go/go-test/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> go test go test命令是一个按照一定的约定和组织来测试代码的程序。在包目录内，所有以_test.go为后缀名的源文件在执行go build时不会被构建成包的一部分，它们是go test测试的一部分。
go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，生成一个临时的main包用于调用相应的测试函数，接着构建并运行、报告测试结果，最后清理测试中生成的临时文件。
在*_test.go文件中有三种类型的函数，单元测试函数、基准测试函数和示例函数。
类型 格式 作用 测试函数 函数名前缀为Test 测试程序的一些逻辑行为是否正确 基准函数 函数名前缀为Benchmark 测试函数的性能 示例函数 函数名前缀为Example 为文档提供示例文档 测试函数 每个测试函数必须导入testing包。测试函数有如下的签名：
func TestName(t *testing.T) { // ... } 测试函数的名字必须以Test开头，可选的后缀名必须以大写字母开头：
func TestSin(t *testing.T) { /* ... */ } func TestCos(t *testing.T) { /* ... */ } func TestLog(t *testing.T) { /* ... */ } 其中参数t用于报告测试失败和附加的日志信息。testing.T的拥有的方法如下：
func (c *T) Error(args ...interface{}) func (c *T) Errorf(format string, args ...interface{}) func (c *T) Fail() func (c *T) FailNow() func (c *T) Failed() bool func (c *T) Fatal(args ...interface{}) func (c *T) Fatalf(format string, args ...interface{}) func (c *T) Log(args ...interface{}) func (c *T) Logf(format string, args ...interface{}) func (c *T) Name() string func (t *T) Parallel() func (t *T) Run(name string, f func(t *T)) bool func (c *T) Skip(args ...interface{}) func (c *T) SkipNow() func (c *T) Skipf(format string, args ...interface{}) func (c *T) Skipped() bool 测试函数示例 就像细胞是构成我们身体的基本单位，一个软件程序也是由很多单元组件构成的。单元组件可以是函数、结构体、方法和最终用户可能依赖的任意东西。总之我们需要确保这些组件是能够正常运行的。单元测试是一些利用各种方法测试单元组件的程序，它会将结果与预期输出进行比较。
接下来，我们定义一个split的包，包中定义了一个Split函数，具体实现如下：
// split/split.go package split import "strings" // split package with a single split function. // Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i > -1 { result = append(result, s[:i]) s = s[i+1:] i = strings.Index(s, sep) } result = append(result, s) return } 在当前目录下，我们创建一个split_test.go的测试文件，并定义一个测试函数如下：
// split/split_test.go package split import ( "reflect" "testing" ) func TestSplit(t *testing.T) { // 测试函数名必须以Test开头，必须接收一个*testing.T类型参数 got := Split("a🅱️c", ":") // 程序输出的结果 want := []string{"a", "b", "c"} // 期望的结果 if !reflect.DeepEqual(want, got) { // 因为slice不能比较直接，借助反射包中的方法比较 t.Errorf("excepted:%v, got:%v", want, got) // 测试失败输出错误提示 } } 此时split这个包中的文件如下：
split $ ls -l total 16 -rw-r--r-- 1 zhaohaiyu test 408 4 29 15:50 split.go -rw-r--r-- 1 zhaohaiyu test 466 4 29 16:04 split_test.go 在split包路径下，执行go test命令，可以看到输出结果如下：
split $ go test PASS ok test/split 0.005s 一个测试用例有点单薄，我们再编写一个测试使用多个字符切割字符串的例子，在split_test.go中添加如下测试函数：
func TestMoreSplit(t *testing.T) { got := Split("abcd", "bc") want := []string{"a", "d"} if !reflect.DeepEqual(want, got) { t.Errorf("excepted:%v, got:%v", want, got) } } 再次运行go test命令，输出结果如下：
split $ go test --- FAIL: TestMultiSplit (0.00s) split_test.go:20: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL test/split 0.006s 这一次，我们的测试失败了。我们可以为go test命令添加-v参数，查看测试函数名称和运行时间：
split $ go test -v === RUN TestSplit --- PASS: TestSplit (0.00s) === RUN TestMoreSplit --- FAIL: TestMoreSplit (0.00s) split_test.go:21: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL test/split 0.005s 这一次我们能清楚的看到是TestMoreSplit这个测试没有成功。 还可以在go test命令后添加-run参数，它对应一个正则表达式，只有函数名匹配上的测试函数才会被go test命令执行。
split $ go test -v -run="More" === RUN TestMoreSplit --- FAIL: TestMoreSplit (0.00s) split_test.go:21: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL test/split 0.006s 现在我们回过头来解决我们程序中的问题。很显然我们最初的split函数并没有考虑到sep为多个字符的情况，我们来修复下这个Bug：
package split import "strings" // split package with a single split function. // Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i > -1 { result = append(result, s[:i]) s = s[i+len(sep):] // 这里使用len(sep)获取sep的长度 i = strings.Index(s, sep) } result = append(result, s) return } 这一次我们再来测试一下，我们的程序。注意，当我们修改了我们的代码之后不要仅仅执行那些失败的测试函数，我们应该完整的运行所有的测试，保证不会因为修改代码而引入了新的问题。
split $ go test -v === RUN TestSplit --- PASS: TestSplit (0.00s) === RUN TestMoreSplit --- PASS: TestMoreSplit (0.00s) PASS ok test/split 0.006s 这一次我们的测试都通过了。
测试组 我们现在还想要测试一下split函数对中文字符串的支持，这个时候我们可以再编写一个TestChineseSplit测试函数，但是我们也可以使用如下更友好的一种方式来添加更多的测试用例。
func TestSplit(t *testing.T) { // 定义一个测试用例类型 type test struct { input string sep string want []string } // 定义一个存储测试用例的切片 tests := []test{ {input: "a🅱️c", sep: ":", want: []string{"a", "b", "c"}}, {input: "a🅱️c", sep: ",", want: []string{"a🅱️c"}}, {input: "abcd", sep: "bc", want: []string{"a", "d"}}, {input: "沙河有沙又有河", sep: "沙", want: []string{"河有", "又有河"}}, } // 遍历切片，逐一执行测试用例 for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf("excepted:%v, got:%v", tc.want, got) } } } 我们通过上面的代码把多个测试用例合到一起，再次执行go test命令。
split $ go test -v === RUN TestSplit --- FAIL: TestSplit (0.00s) split_test.go:42: excepted:[河有 又有河], got:[ 河有 又有河] FAIL exit status 1 FAIL test/split 0.006s 我们的测试出现了问题，仔细看打印的测试失败提示信息：excepted:[河有 又有河], got:[ 河有 又有河]，你会发现[ 河有 又有河]中有个不明显的空串，这种情况下十分推荐使用%#v的格式化方式。
我们修改下测试用例的格式化输出错误提示部分：
func TestSplit(t *testing.T) { ... for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf("excepted:%#v, got:%#v", tc.want, got) } } } 此时运行go test命令后就能看到比较明显的提示信息了：
split $ go test -v === RUN TestSplit --- FAIL: TestSplit (0.00s) split_test.go:42: excepted:[]string{"河有", "又有河"}, got:[]string{"", "河有", "又有河"} FAIL exit status 1 FAIL test/split 0.006s 子测试 看起来都挺不错的，但是如果测试用例比较多的时候，我们是没办法一眼看出来具体是哪个测试用例失败了。我们可能会想到下面的解决办法：
func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 "simple": {input: "a🅱️c", sep: ":", want: []string{"a", "b", "c"}}, "wrong sep": {input: "a🅱️c", sep: ",", want: []string{"a🅱️c"}}, "more sep": {input: "abcd", sep: "bc", want: []string{"a", "d"}}, "leading sep": {input: "沙河有沙又有河", sep: "沙", want: []string{"河有", "又有河"}}, } for name, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf("name:%s excepted:%#v, got:%#v", name, tc.want, got) // 将测试用例的name格式化输出 } } } 上面的做法是能够解决问题的。同时Go1.7+中新增了子测试，我们可以按照如下方式使用t.Run执行子测试：
func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 "simple": {input: "a🅱️c", sep: ":", want: []string{"a", "b", "c"}}, "wrong sep": {input: "a🅱️c", sep: ",", want: []string{"a🅱️c"}}, "more sep": {input: "abcd", sep: "bc", want: []string{"a", "d"}}, "leading sep": {input: "沙河有沙又有河", sep: "沙", want: []string{"河有", "又有河"}}, } for name, tc := range tests { t.Run(name, func(t *testing.T) { // 使用t.Run()执行子测试 got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf("excepted:%#v, got:%#v", tc.want, got) } }) } } 此时我们再执行go test命令就能够看到更清晰的输出内容了：
split $ go test -v === RUN TestSplit === RUN TestSplit/leading_sep === RUN TestSplit/simple === RUN TestSplit/wrong_sep === RUN TestSplit/more_sep --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/leading_sep (0.00s) split_test.go:83: excepted:[]string{"河有", "又有河"}, got:[]string{"", "河有", "又有河"} --- PASS: TestSplit/simple (0.00s) --- PASS: TestSplit/wrong_sep (0.00s) --- PASS: TestSplit/more_sep (0.00s) FAIL exit status 1 FAIL test/split 0.006s 这个时候我们要把测试用例中的错误修改回来：
func TestSplit(t *testing.T) { ... tests := map[string]test{ // 测试用例使用map存储 "simple": {input: "a🅱️c", sep: ":", want: []string{"a", "b", "c"}}, "wrong sep": {input: "a🅱️c", sep: ",", want: []string{"a🅱️c"}}, "more sep": {input: "abcd", sep: "bc", want: []string{"a", "d"}}, "leading sep": {input: "沙河有沙又有河", sep: "沙", want: []string{"", "河有", "又有河"}}, } ... } 我们都知道可以通过-run=RegExp来指定运行的测试用例，还可以通过/来指定要运行的子测试用例，例如：go test -v -run=Split/simple只会运行simple对应的子测试用例。
测试覆盖率 测试覆盖率是你的代码被测试套件覆盖的百分比。通常我们使用的都是语句的覆盖率，也就是在测试中至少被运行一次的代码占总代码的比例。
Go提供内置功能来检查你的代码覆盖率。我们可以使用go test -cover来查看测试覆盖率。例如：
split $ go test -cover PASS coverage: 100.0% of statements ok test/split 0.005s 从上面的结果可以看到我们的测试用例覆盖了100%的代码。
Go还提供了一个额外的-coverprofile参数，用来将覆盖率相关的记录信息输出到一个文件。例如：
split $ go test -cover -coverprofile=c.out PASS coverage: 100.0% of statements ok test/split 0.005s 上面的命令会将覆盖率相关的信息输出到当前文件夹下面的c.out文件中，然后我们执行go tool cover -html=c.out，使用cover工具来处理生成的记录信息，该命令会打开本地的浏览器窗口生成一个HTML报告。 上图中每个用绿色标记的语句块表示被覆盖了，而红色的表示没有被覆盖。
基准测试 基准测试函数格式 基准测试就是在一定的工作负载之下检测程序性能的一种方法。基准测试的基本格式如下：
func BenchmarkName(b *testing.B){ // ... } 基准测试以Benchmark为前缀，需要一个*testing.B类型的参数b，基准测试必须要执行b.N次，这样的测试才有对照性，b.N的值是系统根据实际情况去调整的，从而保证测试的稳定性。testing.B拥有的方法如下：
func (c *B) Error(args ...interface{}) func (c *B) Errorf(format string, args ...interface{}) func (c *B) Fail() func (c *B) FailNow() func (c *B) Failed() bool func (c *B) Fatal(args ...interface{}) func (c *B) Fatalf(format string, args ...interface{}) func (c *B) Log(args ...interface{}) func (c *B) Logf(format string, args ...interface{}) func (c *B) Name() string func (b *B) ReportAllocs() func (b *B) ResetTimer() func (b *B) Run(name string, f func(b *B)) bool func (b *B) RunParallel(body func(*PB)) func (b *B) SetBytes(n int64) func (b *B) SetParallelism(p int) func (c *B) Skip(args ...interface{}) func (c *B) SkipNow() func (c *B) Skipf(format string, args ...interface{}) func (c *B) Skipped() bool func (b *B) StartTimer() func (b *B) StopTimer() 基准测试示例 我们为split包中的Split函数编写基准测试如下：
func BenchmarkSplit(b *testing.B) { for i := 0; i &lt; b.N; i++ { Split("沙河有沙又有河", "沙") } } 基准测试并不会默认执行，需要增加-bench参数，所以我们通过执行go test -bench=Split命令执行基准测试，输出结果如下：
split $ go test -bench=Split goos: darwin goarch: amd64 pkg: test/split BenchmarkSplit-8 10000000 203 ns/op PASS ok test/split 2.255s 其中BenchmarkSplit-8表示对Split函数进行基准测试，数字8表示GOMAXPROCS的值，这个对于并发基准测试很重要。10000000和203ns/op表示每次调用Split函数耗时203ns，这个结果是10000000次调用的平均值。
我们还可以为基准测试添加-benchmem参数，来获得内存分配的统计数据。
split $ go test -bench=Split -benchmem goos: darwin goarch: amd64 pkg: test/split BenchmarkSplit-8 10000000 215 ns/op 112 B/op 3 allocs/op PASS ok test/split 2.394s 其中，112 B/op表示每次操作内存分配了112字节，3 allocs/op则表示每次操作进行了3次内存分配。 我们将我们的Split函数优化如下：
func Split(s, sep string) (result []string) { result = make([]string, 0, strings.Count(s, sep)+1) i := strings.Index(s, sep) for i > -1 { result = append(result, s[:i]) s = s[i+len(sep):] // 这里使用len(sep)获取sep的长度 i = strings.Index(s, sep) } result = append(result, s) return } 这一次我们提前使用make函数将result初始化为一个容量足够大的切片，而不再像之前一样通过调用append函数来追加。我们来看一下这个改进会带来多大的性能提升：
split $ go test -bench=Split -benchmem goos: darwin goarch: amd64 pkg: test/split BenchmarkSplit-8 10000000 127 ns/op 48 B/op 1 allocs/op PASS ok test/split 1.423s 这个使用make函数提前分配内存的改动，减少了2/3的内存分配次数，并且减少了一半的内存分配。
性能比较函数 上面的基准测试只能得到给定操作的绝对耗时，但是在很多性能问题是发生在两个不同操作之间的相对耗时，比如同一个函数处理1000个元素的耗时与处理1万甚至100万个元素的耗时的差别是多少？再或者对于同一个任务究竟使用哪种算法性能最佳？我们通常需要对两个不同算法的实现使用相同的输入来进行基准比较测试。
性能比较函数通常是一个带有参数的函数，被多个不同的Benchmark函数传入不同的值来调用。举个例子如下：
func benchmark(b *testing.B, size int){/* ... */} func Benchmark10(b *testing.B){ benchmark(b, 10) } func Benchmark100(b *testing.B){ benchmark(b, 100) } func Benchmark1000(b *testing.B){ benchmark(b, 1000) } 例如我们编写了一个计算斐波那契数列的函数如下：
// fib.go // Fib 是一个计算第n个斐波那契数的函数 func Fib(n int) int { if n &lt; 2 { return n } return Fib(n-1) + Fib(n-2) } 我们编写的性能比较函数如下：
// fib_test.go func benchmarkFib(b *testing.B, n int) { for i := 0; i &lt; b.N; i++ { Fib(n) } } func BenchmarkFib1(b *testing.B) { benchmarkFib(b, 1) } func BenchmarkFib2(b *testing.B) { benchmarkFib(b, 2) } func BenchmarkFib3(b *testing.B) { benchmarkFib(b, 3) } func BenchmarkFib10(b *testing.B) { benchmarkFib(b, 10) } func BenchmarkFib20(b *testing.B) { benchmarkFib(b, 20) } func BenchmarkFib40(b *testing.B) { benchmarkFib(b, 40) } 运行基准测试：
split $ go test -bench=. goos: darwin goarch: amd64 pkg: test/fib BenchmarkFib1-8 1000000000 2.03 ns/op BenchmarkFib2-8 300000000 5.39 ns/op BenchmarkFib3-8 200000000 9.71 ns/op BenchmarkFib10-8 5000000 325 ns/op BenchmarkFib20-8 30000 42460 ns/op BenchmarkFib40-8 2 638524980 ns/op PASS ok test/fib 12.944s 这里需要注意的是，默认情况下，每个基准测试至少运行1秒。如果在Benchmark函数返回时没有到1秒，则b.N的值会按1,2,5,10,20,50，…增加，并且函数再次运行。
最终的BenchmarkFib40只运行了两次，每次运行的平均值只有不到一秒。像这种情况下我们应该可以使用-benchtime标志增加最小基准时间，以产生更准确的结果。例如：
split $ go test -bench=Fib40 -benchtime=20s goos: darwin goarch: amd64 pkg: test/fib BenchmarkFib40-8 50 663205114 ns/op PASS ok test/fib 33.849s 这一次BenchmarkFib40函数运行了50次，结果就会更准确一些了。
使用性能比较函数做测试的时候一个容易犯的错误就是把b.N作为输入的大小，例如以下两个例子都是错误的示范：
// 错误示范1 func BenchmarkFibWrong(b *testing.B) { for n := 0; n &lt; b.N; n++ { Fib(n) } } // 错误示范2 func BenchmarkFibWrong2(b *testing.B) { Fib(b.N) } 重置时间 b.ResetTimer之前的处理不会放到执行时间里，也不会输出到报告中，所以可以在之前做一些不计划作为测试报告的操作。例如：
func BenchmarkSplit(b *testing.B) { time.Sleep(5 * time.Second) // 假设需要做一些耗时的无关操作 b.ResetTimer() // 重置计时器 for i := 0; i &lt; b.N; i++ { Split("沙河有沙又有河", "沙") } } 并行测试 func (b *B) RunParallel(body func(*PB))会以并行的方式执行给定的基准测试。
RunParallel会创建出多个goroutine，并将b.N分配给这些goroutine执行， 其中goroutine数量的默认值为GOMAXPROCS。用户如果想要增加非CPU受限（non-CPU-bound）基准测试的并行性， 那么可以在RunParallel之前调用SetParallelism。RunParallel通常会与-cpu标志一同使用。
func BenchmarkSplitParallel(b *testing.B) { // b.SetParallelism(1) // 设置使用的CPU数 b.RunParallel(func(pb *testing.PB) { for pb.Next() { Split("沙河有沙又有河", "沙") } }) } 执行一下基准测试：
split $ go test -bench=. goos: darwin goarch: amd64 pkg: test/split BenchmarkSplit-8 10000000 131 ns/op BenchmarkSplitParallel-8 50000000 36.1 ns/op PASS ok test/split 3.308s 还可以通过在测试命令后添加-cpu参数如go test -bench=. -cpu 1来指定使用的CPU数量。
Setup与TearDown 测试程序有时需要在测试之前进行额外的设置（setup）或在测试之后进行拆卸（teardown）。
TestMain 通过在*_test.go文件中定义TestMain函数来可以在测试之前进行额外的设置（setup）或在测试之后进行拆卸（teardown）操作。
如果测试文件包含函数:func TestMain(m *testing.M)那么生成的测试会先调用 TestMain(m)，然后再运行具体测试。TestMain运行在主goroutine中, 可以在调用m.Run前后做任何设置（setup）和拆卸（teardown）。退出测试的时候应该使用m.Run的返回值作为参数调用os.Exit。
一个使用TestMain来设置Setup和TearDown的示例如下：
func TestMain(m *testing.M) { fmt.Println("write setup code here...") // 测试之前的做一些设置 // 如果 TestMain 使用了 flags，这里应该加上flag.Parse() retCode := m.Run() // 执行测试 fmt.Println("write teardown code here...") // 测试之后做一些拆卸工作 os.Exit(retCode) // 退出测试 } 需要注意的是：在调用TestMain时,flag.Parse并没有被调用。所以如果TestMain依赖于command-line标志 (包括 testing 包的标记), 则应该显示的调用flag.Parse。
子测试的Setup与Teardown 有时候我们可能需要为每个测试集设置Setup与Teardown，也有可能需要为每个子测试设置Setup与Teardown。下面我们定义两个函数工具函数如下：
// 测试集的Setup与Teardown func setupTestCase(t *testing.T) func(t *testing.T) { t.Log("如有需要在此执行:测试之前的setup") return func(t *testing.T) { t.Log("如有需要在此执行:测试之后的teardown") } } // 子测试的Setup与Teardown func setupSubTest(t *testing.T) func(t *testing.T) { t.Log("如有需要在此执行:子测试之前的setup") return func(t *testing.T) { t.Log("如有需要在此执行:子测试之后的teardown") } } 使用方式如下：
func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 "simple": {input: "a🅱️c", sep: ":", want: []string{"a", "b", "c"}}, "wrong sep": {input: "a🅱️c", sep: ",", want: []string{"a🅱️c"}}, "more sep": {input: "abcd", sep: "bc", want: []string{"a", "d"}}, "leading sep": {input: "沙河有沙又有河", sep: "沙", want: []string{"", "河有", "又有河"}}, } teardownTestCase := setupTestCase(t) // 测试之前执行setup操作 defer teardownTestCase(t) // 测试之后执行testdoen操作 for name, tc := range tests { t.Run(name, func(t *testing.T) { // 使用t.Run()执行子测试 teardownSubTest := setupSubTest(t) // 子测试之前执行setup操作 defer teardownSubTest(t) // 测试之后执行testdoen操作 got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf("excepted:%#v, got:%#v", tc.want, got) } }) } } 测试结果如下：
split $ go test -v === RUN TestSplit === RUN TestSplit/simple === RUN TestSplit/wrong_sep === RUN TestSplit/more_sep === RUN TestSplit/leading_sep --- PASS: TestSplit (0.00s) split_test.go:71: 如有需要在此执行:测试之前的setup --- PASS: TestSplit/simple (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/wrong_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/more_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/leading_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown split_test.go:73: 如有需要在此执行:测试之后的teardown === RUN ExampleSplit --- PASS: ExampleSplit (0.00s) PASS ok test/split 0.006s 示例函数 示例函数的格式 被go test特殊对待的第三种函数就是示例函数，它们的函数名以Example为前缀。它们既没有参数也没有返回值。标准格式如下：
func ExampleName() { // ... } 示例函数示例 下面的代码是我们为Split函数编写的一个示例函数：
func ExampleSplit() { fmt.Println(split.Split("a🅱️c", ":")) fmt.Println(split.Split("沙河有沙又有河", "沙")) // Output: // [a b c] // [ 河有 又有河] } 为你的代码编写示例代码有如下三个用处：
示例函数能够作为文档直接使用，例如基于web的godoc中能把示例函数与对应的函数或包相关联。
示例函数只要包含了// Output:也是可以通过go test运行的可执行测试。
split $ go test -run Example PASS ok test/split 0.006s 示例函数提供了可以直接运行的示例代码，可以直接在golang.org的godoc文档服务器上使用Go Playground运行示例代码。下图为strings.ToUpper函数在Playground的示例函数效果。![Go Playground]
参考文章:
《go语言圣经》 https://www.liwenzhou.com/posts/Go/16_test/</content></entry><entry><title>Go Channel</title><url>https://www.zhaohaiyu.com/post/go/go-channel/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 什么是channel channels 是一种类型安全的消息队列，充当两个 goroutine 之间的管道，将通过它同步的进行任意资源的交换。chan 控制 goroutines 交互的能力从而创建了 Go 同步机制。当创建的 chan 没有容量时，称为无缓冲通道。反过来，使用容量创建的 chan 称为缓冲通道。
要了解通过 chan 交互的 goroutine 的同步行为是什么，我们需要知道通道的类型和状态。根据我们使用的是无缓冲通道还是缓冲通道，场景会有所不同，所以让我们单独讨论每个场景。
无缓冲管道 make ： ch := make(chan struct{}) 无缓冲 chan 没有容量，因此进行任何交换前需要两个 goroutine 同时准备好。当 goroutine 试图将一个资源发送到一个无缓冲的通道并且没有goroutine 等待接收该资源时，该通道将锁住发送 goroutine 并使其等待。当 goroutine 尝试从无缓冲通道接收，并且没有 goroutine 等待发送资源时，该通道将锁住接收 goroutine 并使其等待。
无缓冲信道的本质是保证同步。
无缓冲channel在消息发送时需要接收者就绪。声明无缓冲channel的方式是不指定缓冲大小。以下是一个列子：
package main import ( "sync" "time" ) func main() { c := make(chan string) var wg sync.WaitGroup wg.Add(2) go func() { defer wg.Done() c &lt;- `foo` }() go func() { defer wg.Done() time.Sleep(time.Second * 1) println(`Message: `+ &lt;-c) }() wg.Wait() } 第一个协程会在发送消息foo时阻塞，原因是接收者还没有就绪：这个特性在标准文档 中描述如下：
如果缓冲大小设置为0或者不设置，channel为无缓冲类型，通信成功的前提是发送者和接收者都处于就绪状态。
effective Go 文档也有相应的描述：
无缓冲channel，发送者会阻塞直到接收者接收了发送的值。
为了更好的理解channel的特性，接下来我们分析channel的内部结构。
package main import ( "sync" "time" "fmt" ) func main() { c := make(chan string) var wg sync.WaitGroup wg.Add(2) go func() { defer wg.Done() c &lt;- "foo" }() go func() { defer wg.Done() time.Sleep(time.Second) fmt.Println("message:" + &lt;- c) }() wg.Wait() } /* foo */ 有缓冲管道 buffered channel 具有容量，因此其行为可能有点不同。当 goroutine 试图将资源发送到缓冲通道，而该通道已满时，该通道将锁住 goroutine并使其等待缓冲区可用。如果通道中有空间，发送可以立即进行，goroutine 可以继续。当goroutine 试图从缓冲通道接收数据，而缓冲通道为空时，该通道将锁住 goroutine 并使其等待资源被发送。
package main import ( "sync" "time" "fmt" ) func main() { c := make(chan string,2) var wg sync.WaitGroup wg.Add(2) go func(){ defer wg.Done() c &lt;- "foo" c &lt;- "bar" }() go func(){ defer wg.Done() time.Sleep(time.Second) fmt.Println("mesage:" + &lt;- c) fmt.Println("message:" + &lt;- c) }() wg.Wait() } /* mesage:foo message:bar */ 追踪耗时 通过Go工具trace中的synchronization blocking profile来查看测试程序被同步原语阻塞所消耗的时间。接收时的耗时对比：无缓冲channel为9毫秒，缓冲大小为50的channel为1.9毫秒。
发送时的耗时对比：有缓冲channel将耗时缩小了五倍。
Send 先于 Receive 发生。 好处: 延迟更小。 代价: 不保证数据到达，越大的 buffer，越小的保障到达。buffer = 1 时，给你延迟一个消息的保障。 参考文章 https://www.it1352.com/807929.html https://www.pengrl.com/p/21027/</content></entry><entry><title>Go context包</title><url>https://www.zhaohaiyu.com/post/go/go-context/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> go context标准库 context包在Go1.7版本时加入到标准库中。其设计目标是给Golang提供一个标准接口来给其他任务发送取消信号和传递数据。其具体作用为：
可以通过context发送取消信号。
可以指定截止时间（Deadline)，context在截止时间到期后自动发送取消信号。
可以通过context传输一些数据。
context在Golang中最主要的用途是控制协程任务的取消，但是context除了协程以外也可以用在线程控制等非协程的情况。
基本概念 context的核心是其定义的Context接口类型。围绕着Context接口类型存在两种角色：
父任务：创建Context，将Context对象传递给子任务，并且根据需要发送取消信号来结束子任务。
子任务：使用Context类型对象，当收到父任务发来的取消信号，结束当前任务并退出。
接下来我们从这两个角色的视角分别看一下Context对象。
context接口 type Context interface { Deadline() (deadline time.Time, ok bool) Done() chan struct{} Err() error Value(key interface{}) interface{} } Deadline方法需要返回当前Context被取消的时间，也就是完成工作的截止时间（deadline）；
Done方法需要返回一个Channel，这个Channel会在当前工作完成或者上下文被取消之后关闭，多次调用Done方***返回同一个Channel；
Err方***返回当前Context结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值；
如果当前Context被取消就会返回Canceled错误；
如果当前Context超时就会返回DeadlineExceeded错误；
Value方***从Context中返回键对应的值，对于同一个上下文来说，多次调用Value 并传入相同的Key会返回相同的结果，该方法仅用于传递跨API和进程间跟请求域的数据；
Background()和TODO() Go内置两个函数：Background()和TODO()，这两个函数分别返回一个实现了Context接口的background和todo。我们代码中最开始都是以这两个内置的上下文对象作为最顶层的partent context，衍生出更多的子上下文对象。
Background()主要用于main函数、初始化以及测试代码中，作为Context这个树结构的最顶层的Context，也就是根Context。
TODO()，它目前还不知道具体的使用场景，如果我们不知道该使用什么Context的时候，可以使用这个。
background和todo本质上都是emptyCtx结构体类型，是一个不可取消，没有设置截止时间，没有携带任何值的Context。
With函数 WithCancel函数，传递一个父Context作为参数，返回子Context，以及一个取消函数用来取消Context
WithDeadline函数，和WithCancel差不多，它会多传递一个截止时间参数，意味着到了这个时间点，会自动取消Context，当然我们也可以不等到这个时候，可以提前通过取消函数进行取消
WithTimeout和WithDeadline基本上一样，这个表示是超时自动取消，是多少时间后自动取消Context的意思
WithValue函数和取消Context无关，它是为了生成一个绑定了一个键值对数据的Context，这个绑定的数据可以通过Context.Value方法访问到
Context使用原则 不要把Context放在结构体中，要以参数的方式进行传递
以Context作为参数的函数方法，应该把Context作为第一个参数，放在第一位]
给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO
Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递
package main import ( "context" "fmt" "time" ) func main() { server1() time.Sleep(time.Second) } func server1() { ctx, cancel := context.WithTimeout(context.Background(),time.Millisecond * 30 )// 30毫秒后过期 defer cancel() ctx = context.WithValue(ctx, "name", "zhaohaiyu") for i:=0;i&lt;100;i++{ time.Sleep(time.Millisecond * 10) go server2(ctx) } } func server2(ctx context.Context) { select { case ctx.Done(): fmt.Println("打断执行") return default: name,ok := ctx.Value("name").(string) if !ok{ fmt.Println("没有取到") return } fmt.Println("name=",name) } } 请求作用域上下文 在 Go 服务中，每个传入的请求都在其自己的goroutine 中处理。请求处理程序通常启动额外的 goroutine 来访问其他后端，如数据库和 RPC服务。处理请求的 goroutine 通常需要访问特定于请求(request-specific context)的值，例如最终用户的身份、授权令牌和请求的截止日期(deadline)。当一个请求被取消或超时时，处理该请求的所有 goroutine 都应该快速退出(fail fast)，这样系统就可以回收它们正在使用的任何资源。 Go 1.7 引入一个 context 包，它使得跨 API 边界的请求范围元数据、取消信号和截止日期很容易传递给处理请求所涉及的所有 goroutine(显示传递)。
其他语言: Thread Local Storage(TLS)，XXXContext
type Context interface { // Deadline returns the time when work done on behalf of this context // should be canceled. Deadline returns ok==false when no deadline is // set. Successive calls to Deadline return the same results. Deadline() (deadline time.Time, ok bool) // Done returns a channel that's closed when work done on behalf of this // context should be canceled. Done may return nil if this context can // never be canceled. Successive calls to Done return the same value. // The close of the Done channel may happen asynchronously, // after the cancel function returns. // // WithCancel arranges for Done to be closed when cancel is called; // WithDeadline arranges for Done to be closed when the deadline // expires; WithTimeout arranges for Done to be closed when the timeout // elapses. // // Done is provided for use in select statements: // // // Stream generates values with DoSomething and sends them to out // // until DoSomething returns an error or ctx.Done is closed. // func Stream(ctx context.Context, out chan&lt;- Value) error { // for { // v, err := DoSomething(ctx) // if err != nil { // return err // } // select { // case &lt;-ctx.Done(): // return ctx.Err() // case out &lt;- v: // } // } // } // // See https://blog.golang.org/pipelines for more examples of how to use // a Done channel for cancellation. Done() &lt;-chan struct{} // If Done is not yet closed, Err returns nil. // If Done is closed, Err returns a non-nil error explaining why: // Canceled if the context was canceled // or DeadlineExceeded if the context's deadline passed. // After Err returns a non-nil error, successive calls to Err return the same error. Err() error // Value returns the value associated with this context for key, or nil // if no value is associated with key. Successive calls to Value with // the same key returns the same result. // // Use context values only for request-scoped data that transits // processes and API boundaries, not for passing optional parameters to // functions. // // A key identifies a specific value in a Context. Functions that wish // to store values in Context typically allocate a key in a global // variable then use that key as the argument to context.WithValue and // Context.Value. A key can be any type that supports equality; // packages should define keys as an unexported type to avoid // collisions. // // Packages that define a Context key should provide type-safe accessors // for the values stored using that key: // // // Package user defines a User type that's stored in Contexts. // package user // // import "context" // // // User is the type of value stored in the Contexts. // type User struct {...} // // // key is an unexported type for keys defined in this package. // // This prevents collisions with keys defined in other packages. // type key int // // // userKey is the key for user.User values in Contexts. It is // // unexported; clients use user.NewContext and user.FromContext // // instead of using this key directly. // var userKey key // // // NewContext returns a new Context that carries value u. // func NewContext(ctx context.Context, u *User) context.Context { // return context.WithValue(ctx, userKey, u) // } // // // FromContext returns the User value stored in ctx, if any. // func FromContext(ctx context.Context) (*User, bool) { // u, ok := ctx.Value(userKey).(*User) // return u, ok // } Value(key interface{}) interface{} } func IsAdminUser(ctx context.Context) { x := token.GetToken(ctx) userObject := auth.AuthenticateToken(x) return userObject.IsAdmin || userObject.IsRoot() } 如何将 context 集成到 API 中？ 在将 context 集成到 API 中时，要记住的最重要的一点是，它的作用域是请求级别 的。例如，沿单个数据库查询存在是有意义的，但沿数据库对象存在则没有意义。 目前有两种方法可以将 context 对象集成到 API 中：
The first parameter of a function call
首参数传递 context 对象，比如，参考 net 包 Dialer.DialContext。此函数执行正常的 Dial 操作，但可以通过 context 对象取消函数调用。
func (d *Dialer) DialContext(ctx context.Context,network,address string) (Conn,error)
Optional config on a request structure 在第一个 request 对象中携带一个可选的 context 对象。例如 net/http 库的 Request.WithContext，通过携带给定的 context 对象，返回一个新的 Request 对象。
func (r *Request) WithContext(ctx context.Context) *Request
不要在stuct类型中存储上下文 不要在结构题类型中存储上下文；相反，应该显式地将上下文传递给每个需要它的函数。上下文应该是第一个参数，通常命名为ctx:
func DoSomething(ctx context.Context,arg Arg) error { // .. use ctx } 对服务器的传入请求应创建上下文。 使用 context 的一个很好的心智模型是它应该在程序中流动，应该贯穿你的代码。这通常意味着您不希望将其存储在结构体之中。它从一个函数传递到另一个函数，并根据需要进行扩展。理想情况下，每个请求都会创建一个 context 对象，并在请求结束时过期。 不存储上下文的一个例外是，当您需要将它放入一个结构中时，该结构纯粹用作通过通道传递的消息。如下例所示。
type message struct { responseChan chan&lt;- int parameter string ctx context.Context } context.WithValue 比如我们新建了一个基于 context.Background() 的 ctx1，携带了一个 map 的数据，map 中包含了 “k1”: “v1” 的一个键值对，ctx1 被两个 goroutine 同时使用作为函数签名传入，如果我们修改了 这个map，会导致另外进行读 context.Value 的 goroutine 和修改 map 的 goroutine，在 map 对象上产生 data race。因此我们要使用 copy-on-write 的思路，解决跨多个 goroutine 使用数据、修改数据的场景。
context.WithValue 内部基于 valueCtx 实现:
type valueCtx struct { Context key,val interface{} } 为了实现不断的 WithValue，构建新的 context，内部在查找 key 时候，使用递归方式不断从当前，从父节点寻找匹配的 key，直到 root context(Backgrond 和 TODO Value 函数会返回 nil)。
func (c *valueCtx) Value(key interface{}( interface{} { if c.key == key { return c.val } return c.Context.Value(key) } 调试或跟踪数据在上下文中传递是安全的 context.WithValue 方法允许上下文携带请求范围的数据。这些数据必须是安全的，以便多个 goroutine 同时使用。这里的数据，更多是面向请求的元数据，不应该作为函数的可选参数来使用(比如 context 里面挂了一个sql.Tx 对象，传递到 Dao 层使用)，因为元数据相对函数参数更加是隐含的，面向请求的。而参数是更加显示的。
同一个 context 对象可以传递给在不同 goroutine 中运行的函数；上下文对于多个 goroutine 同时使用是安全的。对于值类型最容易犯错的地方，在于 context value 应该是 immutable 的，每次重新赋值应该是新的 context，即: context.WithValue(ctx, oldvalue) https://pkg.go.dev/google.golang.org/grpc/metadata Context.Value should inform, not control
func WithValue(parent Context,key val interface{}) Context { if parent == nil { panic("connot creat context from nil parent") } if key == nil { panic("nil key") } if !reflectlite.Typeof(key).Comparable() { panic("key is not comparable") } return &amp;valueCtx{parent,key,val} } type valueCtx struct { Context key,val interface{} } 用于传递作用域的参数的可选api和用于传递作用域的参数的可选api。比如 染色，API 重要性，Trace
比如我们新建了一个基于 context.Background() 的 ctx1，携带了一个 map 的数据，map 中包含了 “k1”: “v1” 的一个键值对，ctx1 被两个 goroutine 同时使用作为函数签名传入，如果我们修改了 这个map，会导致另外进行读 context.Value 的 goroutine 和修改 map 的 goroutine，在 map 对象上产生 data race。因此我们要使用 copy-on-write 的思路，解决跨多个 goroutine 使用数据、修改数据的场景。
COW: 从 ctx1 中获取 map1(可以理解为 v1 版本的 map 数据)。构建一个新的 map 对象 map2，复制所有 map1 数据，同时追加新的数据 “k2”: “v2” 键值对，使用 context.WithValue 创建新的 ctx2，ctx2 会传递到其他的 goroutine 中。这样各自读取的副本都是自己的数据，写行为追加的数据，在 ctx2 中也能完整读取到，同时也不会污染 ctx1 中的数据。
当上下文被取消时，从它派生的所有上下文也被取消
当一个 context 被取消时，从它派生的所有 context 也将被取消。WithCancel(ctx) 参数 ctx 认为是 parent ctx，在内部会进行一个传播关系链的关联。Done() 返回 一个 chan，当我们取消某个parent context, 实际上上会递归层层 cancel 掉自己的 child context 的 done chan 从而让整个调用链中所有监听 cancel 的 goroutine退出。
package main import ( "context" "fmt" ) func main() { gen := func(ctx context.Context) &lt;-chan int { dst := make(chan int) n := 1 go func(){ for { select { case &lt;- ctx.Done(): return case dst &lt;- n: n++ } } }() } return dst ctx,cancel := context.WithCancel(context.Backgroup()) for n := range gen(ctx) { fmt.Println(n) if n == 5 { break } } 所有阻塞/长操作都应可取消
如果要实现一个超时控制，通过上面的context 的parent/child 机制，其实我们只需要启动一个定时器，然后在超时的时候，直接将当前的 context 给 cancel 掉，就可以实现监听在当前和下层的额context.Done() 的 goroutine 的退出。
package main import ( "context" "fmt" "fmt" ) const shortDuration = time.Millisecond func main() { d := time.Now().Add(shortDuration) ctx,cancel := context.WithDeadline(context.Backgroup(),d) defer canel() select { case &lt;-time.After(time.Second): fmt.Println("overslept") case &lt;- ctx.Done(): fmt.Println(ctx.Err()) } }</content></entry><entry><title>Go Template</title><url>https://www.zhaohaiyu.com/post/go/go-template/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> html模板生成: html/template包实现了数据驱动的模板，用于生成可对抗代码注入的安全HTML输出。它提供了和text/template包相同的接口，Go语言中输出HTML的场景都应使用text/template包。 模板语法 {{.}} 模板语法都包含在{{和}}中间，其中{{.}}中的点表示当前对象。
当我们传入一个结构体对象时，我们可以根据.来访问结构体的对应字段。例如：
// main.go func sayHello(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 tmpl, err := template.ParseFiles("./hello.html") if err != nil { fmt.Println("create template failed, err:", err) return } var user = struct { name string age int }{ name:"zhaohaiyu", age:18, } // 利用给定数据渲染模板，并将结果写入w tmpl.Execute(w, user) } func main() { http.HandleFunc("/", sayHello) err := http.ListenAndServe(":9090", nil) if err != nil { fmt.Println("HTTP server failed,err:", err) return } } Hello 姓名 {{.Name}} 年龄：{{.Age}} 同理，当我们传入的变量是map时，也可以在模板文件中通过.根据key来取值。 注释 {{/* a comment */}}
pipeline pipeline是指产生数据的操作。比如{{.}}、{{.Name}}等。Go的模板语法中支持使用管道符号|链接多个命令，用法和unix下的管道类似：|前面的命令会将运算结果(或返回值)传递给后一个命令的最后一个位置。 **注意：**并不是只有使用了|才是pipeline。Go的模板语法中，pipeline的概念是传递数据，只要能产生数据的，都是pipeline。
变量 我们还可以在模板中声明变量，用来保存传入模板的数据或其他语句生成的结果。具体语法如下： $obj := {{.}} 其中$obj是变量的名字，在后续的代码中就可以使用该变量了。 移除空格 有时候我们在使用模板语法的时候会不可避免的引入一下空格或者换行符，这样模板最终渲染出来的内容可能就和我们想的不一样，这个时候可以使用{{-语法去除模板内容左侧的所有空白符号， 使用-}}去除模板内容右侧的所有空白符号。 例如：{{- .Name -}}
注意：-要紧挨{{和}}，同时与模板值之间需要使用空格分隔。
条件判断 Go模板语法中的条件判断有以下几种: {{if pipeline}} T1 {{end}} {{if pipeline}} T1 {{else}} T0 {{end}} {{if pipeline}} T1 {{else if pipeline}} T0 {{end}} range Go的模板语法中使用range关键字进行遍历，有以下两种写法，其中pipeline的值必须是数组、切片、字典或者通道。
{{range pipeline}} T1 {{end}} {{range pipeline}} T1 {{else}} T0 {{end}} with {{with pipeline}} T1 {{end}} {{with pipeline}} T1 {{else}} T0 {{end}} 预定义函数 执行模板时，函数从两个函数字典中查找：首先是模板函数字典，然后是全局函数字典。一般不在模板内定义函数，而是使用Funcs方法添加函数到模板里。
预定义的全局函数如下：
and 函数返回它的第一个empty参数或者最后一个参数； 就是说"and x y"等价于"if x then y else x"；所有参数都会执行； or 返回第一个非empty参数或者最后一个参数； 亦即"or x y"等价于"if x then x else y"；所有参数都会执行； not 返回它的单个参数的布尔值的否定 len 返回它的参数的整数类型长度 index 执行结果为第一个参数以剩下的参数为索引/键指向的值； 如"index x 1 2 3"返回x[1][2][3]的值；每个被索引的主体必须是数组、切片或者字典。 print 即fmt.Sprint printf 即fmt.Sprintf println 即fmt.Sprintln html 返回与其参数的文本表示形式等效的转义HTML。 这个函数在html/template中不可用。 urlquery 以适合嵌入到网址查询中的形式返回其参数的文本表示的转义值。 这个函数在html/template中不可用。 js 返回与其参数的文本表示形式等效的转义JavaScript。 call 执行结果是调用第一个参数的返回值，该参数必须是函数类型，其余参数作为调用该函数的参数；
如"call .X.Y 1 2"等价于go语言里的dot.X.Y(1, 2)； 其中Y是函数类型的字段或者字典的值，或者其他类似情况； call的第一个参数的执行结果必须是函数类型的值（和预定义函数如print明显不同）； 该函数类型值必须有1到2个返回值，如果有2个则后一个必须是error接口类型； 如果有2个返回值的方法返回的error非nil，模板执行会中断并返回给调用模板执行者该错误；
比较函数 布尔函数会将任何类型的零值视为假，其余视为真。 下面是定义为函数的二元比较运算的集合：
eq 如果arg1 == arg2则返回真 ne 如果arg1 != arg2则返回真 lt 如果arg1 &lt; arg2则返回真 le 如果arg1 &lt;= arg2则返回真 gt 如果arg1 > arg2则返回真 ge 如果arg1 >= arg2则返回真
为了简化多参数相等检测，eq（只有eq）可以接受2个或更多个参数，它会将第一个参数和其余参数依次比较，返回下式的结果：
{{eq arg1 arg2 arg3}}
比较函数只适用于基本类型（或重定义的基本类型，如”type Celsius float32”）。但是，整数和浮点数不能互相比较。
自定义函数 Go的模板支持自定义函数。
func sayHello(w http.ResponseWriter, r *http.Request) { htmlByte, err := ioutil.ReadFile("./hello.tmpl") if err != nil { fmt.Println("read html failed, err:", err) return } // 自定义一个夸人的模板函数 kua := func(arg string) (string, error) { return arg + "真帅", nil } // 采用链式操作在Parse之前调用Funcs添加自定义的kua函数 tmpl, err := template.New("hello").Funcs(template.FuncMap{"kua": kua}).Parse(string(htmlByte)) if err != nil { fmt.Println("create template failed, err:", err) return } user := UserInfo{ Name: "小王子", Gender: "男", Age: 18, } // 使用user渲染模板，并将结果写入w tmpl.Execute(w, user) } 我们可以在模板文件hello.tmpl中按照如下方式使用我们自定义的kua函数了。
{{kua .Name}}
嵌套template 我们可以在template中嵌套其他的template。这个template可以是单独的文件，也可以是通过define定义的template。
举个例子：t.tmpl文件内容如下：tmpl test
测试嵌套template语法 {{template &ldquo;ul.tmpl&rdquo;}}
{{template "ol.tmpl"}} {{ define "ol.tmpl"}} 吃饭 睡觉 打豆豆 {{end}} ul.tmpl文件内容如下： 注释 日志 测试 我们注册一个templDemo路由处理函数. http.HandleFunc("/tmpl", tmplDemo) tmplDemo函数的具体内容如下：
func tmplDemo(w http.ResponseWriter, r *http.Request) { tmpl, err := template.ParseFiles("./t.tmpl", "./ul.tmpl") if err != nil { fmt.Println("create template failed, err:", err) return } user := UserInfo{ Name: "小王子", Gender: "男", Age: 18, } tmpl.Execute(w, user) } 注意：在解析模板时，被嵌套的模板一定要在后面解析，例如上面的示例中t.tmpl模板中嵌套了ul.tmpl，所以ul.tmpl要在t.tmpl后进行解析。
block {{block &ldquo;name&rdquo; pipeline}} T1 {{end}}
block是定义模板{{define &ldquo;name&rdquo;}} T1 {{end}}和执行{{template &ldquo;name&rdquo; pipeline}}缩写，典型的用法是定义一组根模板，然后通过在其中重新定义块模板进行自定义。
定义一个根模板templates/base.tmpl，内容如下：Go Templates
{{block &ldquo;content&rdquo; . }}{{end}}
然后定义一个templates/index.tmpl，”继承”base.tmpl：
{{template "base.tmpl"}} {{define "content"}} Hello world! {{end}} 然后使用template.ParseGlob按照正则匹配规则解析模板文件，然后通过ExecuteTemplate渲染指定的模板：
func index(w http.ResponseWriter, r *http.Request){ tmpl, err := template.ParseGlob("templates/*.tmpl") if err != nil { fmt.Println("create template failed, err:", err) return } err = tmpl.ExecuteTemplate(w, "index.tmpl", nil) if err != nil { fmt.Println("render template failed, err:", err) return } } 如果我们的模板名称冲突了，例如不同业务线下都定义了一个index.tmpl模板，我们可以通过下面两种方法来解决。
在模板文件开头使用{{define 模板名}}语句显式的为模板命名。 可以把模板文件存放在templates文件夹下面的不同目录中，然后使用template.ParseGlob(&ldquo;templates/**/*.tmpl&rdquo;)解析模板。 修改默认的标识符 Go标准库的模板引擎使用的花括号{{和}}作为标识，而许多前端框架（如Vue和AngularJS）也使用{{和}}作为标识符，所以当我们同时使用Go语言模板引擎和以上前端框架时就会出现冲突，这个时候我们需要修改标识符，修改前端的或者修改Go语言的。这里演示如何修改Go语言模板引擎默认的标识符：
template.New(&ldquo;test&rdquo;).Delims("{[", &ldquo;]}&rdquo;).ParseFiles("./t.tmpl")
text/template与html/tempalte的区别 html/template针对的是需要返回HTML内容的场景，在模板渲染过程中会对一些有风险的内容进行转义，以此来防范跨站脚本攻击。
例如，我定义下面的模板文件：
Hello {{.}} 这个时候传入一段JS代码并使用html/template去渲染该文件，会在页面上显示出转义后的JS内容。alert(&lsquo;嘿嘿嘿&rsquo;)这就是html/template为我们做的事。
但是在某些场景下，我们如果相信用户输入的内容，不想转义的话，可以自行编写一个safe函数，手动返回一个template.HTML类型的内容。示例如下：
func xss(w http.ResponseWriter, r *http.Request){ tmpl,err := template.New("xss.tmpl").Funcs(template.FuncMap{ "safe": func(s string)template.HTML { return template.HTML(s) }, }).ParseFiles("./xss.tmpl") if err != nil { fmt.Println("create template failed, err:", err) return } jsStr := `alert('嘿嘿嘿')` err = tmpl.Execute(w, jsStr) if err != nil { fmt.Println(err) } } 这样我们只需要在模板文件不需要转义的内容后面使用我们定义好的safe函数就可以了。{{ . | safe }}
代码生成 生成代码用text/template包,模板语法和html/template一样
package main import ( "fmt" "html/template" "os" ) var data = ` package main import "fmt" func main() { str := "{{ . }}" for _, v := range str { fmt.Println(v) } } ` func main() { t := template.New("main") t, err := t.Parse(data) if err != nil { fmt.Println("解析失败") return } var str = "zhaohaiyu" file, err := os.OpenFile("./print/main.go", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0755) if err != nil { fmt.Printf("open file:%s failed, err:%v\n", "./print/main.go", err) return } err = t.Execute(file, str) if err != nil { fmt.Println("execute failed err:",err) return } return } 生成的代码:
package main import "fmt" func main() { str := "zhaohaiyu" for _, v := range str { fmt.Println(v) } } 参考文章:
https://www.liwenzhou.com/posts/Go/go_template/#autoid-1-3-0</content></entry><entry><title>Go Mod</title><url>https://www.zhaohaiyu.com/post/go/go-mod/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> go module是 Go1.11版本之后官方推出的版本管理工具，并且从Go1.13版本开始，go module将是Go语言默认的依赖管理工具。
GO111MODULE 要启用go module支持首先要设置环境变量GO111MODULE，通过它可以开启或关闭模块支持，它有三个可选值：off、on、auto，默认值是auto。
GO111MODULE=off禁用模块支持，编译时会从GOPATH和vendor文件夹中查找包。
GO111MODULE=on启用模块支持，编译时会忽略GOPATH和vendor文件夹，只根据 go.mod下载依赖。
GO111MODULE=auto，当项目在$GOPATH/src外且项目根目录有go.mod文件时，开启模块支持。
简单来说，设置GO111MODULE=on之后就可以使用go module了，以后就没有必要在GOPATH中创建项目了，并且还能够很好的管理项目依赖的第三方包信息。
使用 go module 管理依赖后会在项目根目录下生成两个文件go.mod和go.sum。
GOPROXY Go1.11之后设置GOPROXY命令为：
1 export GOPROXY=https://goproxy.cn Go1.13之后GOPROXY默认值为https://proxy.golang.org，在国内是无法访问的，所以十分建议大家设置GOPROXY，这里我推荐使用goproxy.cn 。
go env -w GOPROXY=https://goproxy.cn,direct go mod命令 常用的go mod命令如下：
go mod download 下载依赖的module到本地cache（默认为$GOPATH/pkg/mod目录） go mod edit 编辑go.mod文件 go mod graph 打印模块依赖图 go mod init 初始化当前文件夹, 创建go.mod文件 go mod tidy 增加缺少的module，删除无用的module go mod vendor 将依赖复制到vendor下 go mod verify 校验依赖 go mod why 解释为什么需要依赖 go.mod go.mod文件记录了项目所有的依赖信息，其结构大致如下：
module test go 1.15 require ( github.com/DeanThompson/ginpprof v0.0.0-20190408063150-3be636683586 github.com/gin-gonic/gin v1.4.0 github.com/go-sql-driver/mysql v1.4.1 github.com/jmoiron/sqlx v1.2.0 10 github.com/satori/go.uuid v1.2.0 google.golang.org/appengine v1.6.1 // indirect 12 ) 其中，
module用来定义包名
require用来定义依赖包及版本
indirect表示间接引用
依赖的版本 go mod支持语义化版本号，比如go get foo@v1.2.3 ，也可以跟git的分支或tag，比如go get foo@master，当然也可以跟git提交哈希，比如go get foo@e3702bed2。关于依赖的版本支持以下几种格式：
gopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 gopkg.in/vmihailenco/msgpack.v2 v2.9.1 gopkg.in/yaml.v2 v2.2.1 github.com/tatsushid/go-fastping v0.0.0-20160109021039-d7bb493dee3e latest replace 在国内访问golang.org/x的各个包都需要***，你可以在go.mod中使用replace替换成github上对应的库。
replace ( golang.org/x/crypto v0.0.0-20180820150726-614d502a4dac => github.com/golang/crypto v0.0.0-20180820150726-614d502a4dac golang.org/x/net v0.0.0-20180821023952-922f4815f713 => github.com/golang/net v0.0.0-20180826012351-8a410e7b638d golang.org/x/text v0.3.0 => github.com/golang/text v0.3.0 ) go get 在项目中执行go get命令可以下载依赖包，并且还可以指定下载的版本。
运行go get -u将会升级到最新的次要版本或者修订版本(x.y.z, z是修订版本号， y是次要版本号)
运行go get -u=patch将会升级到最新的修订版本
运行go get package@version将会升级到指定的版本号version
如果下载所有依赖可以使用go mod download命令。
整理依赖 我们在代码中删除依赖代码后，相关的依赖库并不会在go.mod文件中自动移除。这种情况下我们可以使用go mod tidy命令更新go.mod中的依赖关系。
go mod edit 格式化 因为我们可以手动修改go.mod文件，所以有些时候需要格式化该文件。Go提供了一下命令：
go mod edit -fmt 添加依赖项 go mod edit -require=golang.org/x/text 移除依赖项 如果只是想修改go.mod文件中的内容，那么可以运行go mod edit -droprequire=package path，比如要在go.mod中移除golang.org/x/text包，可以使用如下命令：
go mod edit -droprequire=golang.org/x/text 关于go mod edit的更多用法可以通过go help mod edit查看。
在项目中使用go module 既有项目 如果需要对一个已经存在的项目启用go module，可以按照以下步骤操作：
在项目目录下执行go mod init，生成一个go.mod文件。
执行go get，查找并记录当前项目的依赖，同时生成一个go.sum记录每个依赖库的版本和哈希值。
新项目 对于一个新创建的项目，我们可以在项目文件夹下按照以下步骤操作：
执行go mod init 项目名命令，在当前项目文件夹下创建一个go.mod文件。
手动编辑go.mod中的require依赖项或执行go get自动发现、维护依赖。
文章转自 https://www.liwenzhou.com/posts/Go/go_dependency/</content></entry><entry><title>reids基础</title><url>https://www.zhaohaiyu.com/post/database/redis/</url><categories><category>database</category></categories><tags><tag>redis</tag></tags><content type="html"> redis介绍 Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。
Redis 与其他 key - value 缓存产品有以下三个特点：
Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 redis的安装 brew install redis(mac) yum install redis(centos) apt-get install redis(ubuntu) redis的命令网站 Redis 命令参考 — Redis 命令参考 (redisfans.com) redis的基本操作 redis的五大数据类型 redis的五大数据类型是: String(字符串)、Hash(哈希)、List(列表)、Set(集合)、和zset(sorted set:有序集合)
redis键操作 keys *查看当前库所有key (匹配：keys *1) exists key判断某个key是否存在 type key 查看你的key是什么类型 del key 删除指定的key数据 unlink key 根据value选择非阻塞删除 仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。 expire key 10 10秒钟：为给定的key设置过期时间 ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期 select命令切换数据库 dbsize查看当前数据库的key的数量 flushdb清空当前库 flushall通杀全部库 字符串(String) 简介 String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。
String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。
String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M
常用命令 set &lt;key>&lt;value>添加键值对 get &lt;key>查询对应键值 append &lt;key>&lt;value>将给定的 追加到原值的末尾 strlen &lt;key>获得值的长度 setnx &lt;key>&lt;value>只有在 key 不存在时 设置 key 的值 incr &lt;key> 将 key 中储存的数字值增1 只能对数字值操作，如果为空，新增值为1 decr &lt;key> 将 key 中储存的数字值减1 只能对数字值操作，如果为空，新增值为-1 incrby / decrby &lt;key>&lt;步长>将 key 中储存的数字值增减。自定义步长。 数据结构 String的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配.
如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。
列表(List) 简介 单键多值
Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。
它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。
常用命令 lpush/rpush &lt;key>&lt;value1>&lt;value2>&lt;value3> .... 从左边/右边插入一个或多个值。 lpop/rpop &lt;key>从左边/右边吐出一个值。值在键在，值光键亡。 rpoplpush &lt;key1>&lt;key2>从列表右边吐出一个值，插到列表左边。 lrange &lt;key>&lt;start>&lt;stop> 按照索引下标获得元素(从左到右) lrange mylist 0 -1 0左边第一个，-1右边第一个，（0-1表示获取所有） lindex &lt;key>&lt;index>按照索引下标获得元素(从左到右) llen &lt;key>获得列表长度 linsert &lt;key> before &lt;value>&lt;newvalue>在的后面插入插入值 lrem &lt;key>&lt;n>&lt;value>从左边删除n个value(从左到右) lset&lt;key>&lt;index>&lt;value>将列表key下标为index的值替换成value 数据结构 List的数据结构为快速链表quickList。
首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。
Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。
集合(Set) 简介 Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以****自动排重****的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。
Redis的Set是string类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的****复杂度都是O(1)****。
一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变
常用命令 sadd &lt;key>&lt;value1>&lt;value2> ..... 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略 smembers &lt;key>取出该集合的所有值。 sismember &lt;key>&lt;value>判断集合是否为含有该值，有1，没有0 scard&lt;key>返回该集合的元素个数。 srem &lt;key>&lt;value1>&lt;value2> .... 删除集合中的某个元素。 spop &lt;key>*随机从该集合中吐出一个值。* srandmember &lt;key>&lt;n>随机从该集合中取出n个值。不会从集合中删除 。 smove &lt;source>&lt;destination>value把集合中一个值从一个集合移动到另一个集合 sinter &lt;key1>&lt;key2>返回两个集合的交集元素。 sunion &lt;key1>&lt;key2>返回两个集合的并集元素。 sdiff &lt;key1>&lt;key2>返回两个集合的****差集****元素(key1中的，不包含key2中的) 数据结构 Set数据结构是dict字典，字典是用哈希表实现的。 Java中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。
哈希(Hash) 简介 Redis hash 是一个键值对集合。
Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。
常用命令 hset &lt;key>&lt;field>&lt;value>给集合中的 键赋值 hget &lt;key1>&lt;field>从集合取出 value hmset &lt;key1>&lt;field1>&lt;value1>&lt;field2>&lt;value2>... 批量设置hash的值 hexists&lt;key1>&lt;field>查看哈希表 key 中，给定域 field 是否存在。 hkeys &lt;key>列出该hash集合的所有field hvals &lt;key>列出该hash集合的所有value hincrby &lt;key>&lt;field>&lt;increment>为哈希表 key 中的域 field 的值加上增量 1 -1 hsetnx &lt;key>&lt;field>&lt;value>将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 . 数据结构 Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。
有序集合Zset(sorted set) 简介 Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。
不同之处是有序集合的每个成员都关联了一个****评分（score）****,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。
因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。
访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。
常用命令 zadd &lt;key>&lt;score1>&lt;value1>&lt;score2>&lt;value2>… 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 zrange &lt;key>&lt;start>&lt;stop> [WITHSCORES] 返回有序集 key 中，下标在之间的元素带WITHSCORES，可以让分数一起和值返回到结果集。 zrangebyscore key minmax [withscores] [limit offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 zrevrangebyscore key maxmin [withscores] [limit offset count] 同上，改为从大到小排列。 zincrby &lt;key>&lt;increment>&lt;value> 为元素的score加上增量 zrem &lt;key>&lt;value>删除该集合下，指定值的元素 zcount &lt;key>&lt;min>&lt;max>统计该集合，分数区间内的元素个数 zrank &lt;key>&lt;value>返回该值在集合中的排名，从0开始。 数据结构 SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double>，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。
zset底层使用了两个数据结构
hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。 Redis新数据类型 Bitmaps 简介 现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011，如下图
合理地使用操作位能够有效地提高内存使用率和开发效率。
Redis提供了Bitmaps这个“数据类型”可以实现对位的操作：
Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。 Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。 命令 setbit （1）格式
setbit&lt;key>&lt;offset>&lt;value>设置Bitmaps中某个偏移量的值（0或1）
*offset:偏移量从0开始
（2）实例
每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。
设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图
unique:users:20201106代表2020-11-06这天的独立访问用户的Bitmaps
注：
很多应用的用户id以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。
在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞。
getbit （1）格式 getbit获取Bitmaps中某个偏移量的值
获取键的第offset位的值（从0开始算）
（2）实例 获取id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过
注：因为100根本不存在，所以也是返回0
bitcount 统计字符串被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。 （1）格式 bitcount[start end] 统计字符串从start字节到end字节比特值为1的数量
（2）实例 计算2022-11-06这天的独立访问用户数量
start和end代表起始和结束字节数， 下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。
举例： K1 【01000001 01000000 00000000 00100001】，对应【0，1，2，3】 bitcount K1 1 2 ： 统计下标1、2字节组中bit=1的个数，即01000000 00000000 --》bitcount K1 1 2 --》1 bitcount K1 1 3 ： 统计下标1、2字节组中bit=1的个数，即01000000 00000000 00100001 --》bitcount K1 1 3　--》3 bitcount K1 0 -2 ： 统计下标0到下标倒数第2，字节组中bit=1的个数，即01000001 01000000 00000000 --》bitcount K1 0 -2　--》3 注意：redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。
bitop (1)格式 bitop and(or/not/xor) [key…]
bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。
(2)实例
2020-11-04 日访问网站的userid=1,2,5,9。
setbit unique:users:20201104 1 1
setbit unique:users:20201104 2 1
setbit unique:users:20201104 5 1
setbit unique:users:20201104 9 1
2020-11-03 日访问网站的userid=0,1,4,9。
setbit unique:users:20201103 0 1
setbit unique:users:20201103 1 1
setbit unique:users:20201103 4 1
setbit unique:users:20201103 9 1
计算出两天都访问过网站的用户数量
bitop and unique:users:and:20201104_03
unique:users:20201103unique:users:20201104
计算出任意一天都访问过网站的用户数量（例如月活跃就是类似这种） ， 可以使用or求并集
Bitmaps与set对比 假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用集合类型和Bitmaps分别存储活跃用户可以得到表
set和Bitmaps存储一天活跃用户对比 数据类型 每个用户id占用空间 需要存储的用户量 全部内存量 集合类型 64位 50000000 64位*50000000 = 400MB Bitmaps 1位 100000000 1位*100000000 = 12.5MB 很明显， 这种情况下使用Bitmaps能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的
set和Bitmaps存储独立用户空间对比 数据类型 一天 一个月 一年 集合类型 400MB 12GB 144GB Bitmaps 12.5MB 375MB 4.5GB 但Bitmaps并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有10万（大量的僵尸用户） ， 那么两者的对比如下表所示， 很显然， 这时候使用Bitmaps就不太合适了， 因为基本上大部分位都是0。
set和Bitmaps存储一天活跃用户对比（独立用户比较少） 数据类型 每个userid占用空间 需要存储的用户量 全部内存量 集合类型 64位 100000 64位*100000 = 800KB Bitmaps 1位 100000000 1位*100000000 = 12.5MB HyperLogLog 简介 在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。 但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题。 解决基数问题有很多种方案： （1）数据存储在MySQL表中，使用distinct count计算不重复个数
（2）使用Redis提供的hash、set、bitmaps等数据结构来处理
以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。
能否能够降低一定的精度来平衡存储空间？Redis推出了HyperLogLog
Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。
在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。
但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。
什么是基数?
比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。
命令 1、pfadd
（1）格式
pfadd &lt; element> [element &hellip;] 添加指定元素到 HyperLogLog 中
（2）实例
将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。 2、pfcount
（1）格式
pfcount [key &hellip;] 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可
（2）实例
3、pfmerge
（1）格式
pfmerge [sourcekey &hellip;] 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得
（2）实例
Geospatial 简介 Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。
命令 1、geoadd
（1）格式
geoadd&lt; longitude> [longitude latitude member&hellip;] 添加地理位置（经度，纬度，名称）
2）实例
geoadd china:city 121.47 31.23 shanghai
geoadd china:city 106.50 29.53 chongqing 114.05 22.52 shenzhen 116.38 39.90 beijing
两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。
有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。
当坐标位置超出指定范围时，该命令将会返回一个错误。
已经添加的数据，是无法再次往里面添加的。
2、geopos
（1）格式
geopos [member&hellip;] 获得指定地区的坐标值
（2）实例
3、geodist
（1）格式
geodist [m|km|ft|mi ] 获取两个位置之间的直线距离
（2）实例
获取两个位置之间的直线距离
单位：
m 表示单位为米[默认值]。
km 表示单位为千米。
mi 表示单位为英里。
ft 表示单位为英尺。
如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位
4、georadius
（1）格式
georadius&lt; longitude>radius m|km|ft|mi 以给定的经纬度为中心，找出某一半径内的元素
经度 纬度 距离 单位
（2）实例</content></entry><entry><title>mysql索引</title><url>https://www.zhaohaiyu.com/post/database/mysql-index/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> 什么是索引 一般的应用系统，都是读多写少。而且插入操作和一般的更新操作很少出现性能问题（因为有redo log锁cache缓存）。在生产环境中，我们遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，因此对查询语句的优化显然是重中之重。说起加速查询，就不得不提到索引了。索引的核心思想就是加速查询。
索引的原理 索引原理 索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？
本质都是：通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是说，有了这种索引机制，我们可以总是用同一种查找方式来锁定数据。
数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(>、&lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。
磁盘IO与预读 考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。
索引的数据结构 前面讲了生活中索引的例子，索引的基本原理，数据库的复杂性，又讲了操作系统的相关知识，目的就是让大家了解，任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？就这样，b+树应运而生。
详解b+树 如上图，是一颗b+树，关于b+树的定义可以参见B+树 ，这里只说一些重点，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。
b+树的查找过程 如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。
b+树性质 索引字段要尽量的小：通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 索引的最左匹配特性：当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 聚集索引与辅助索引 在数据库中，B+树的高度一般都在24层，这也就是说查找某一个键值的行记录时最多只需要24次IO，这倒不错。因为当前一般的机械硬盘每秒至少可以做100次IO，24次的IO意味着查询时间只需要0.02~0.04秒。
数据库中的B+树索引可以分为聚集索引（clustered index）和辅助索引（secondary index），
聚集索引与辅助索引相同的是：不管是聚集索引还是辅助索引，其内部都是B+树的形式，即高度是平衡的，叶子结点存放着所有的数据。
聚集索引与辅助索引不同的是：叶子结点存放的是否是一整行的信息
聚集索引 InnoDB存储引擎表示索引组织表，即表中数据按照主键顺序存放。而聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子结点存放的即为整张表的行记录数据，也将聚集索引的叶子结点称为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接。 如果未定义主键，MySQL取第一个唯一索引（unique）而且只含非空列（NOT NULL）作为主键，InnoDB使用它作为聚簇索引。 如果没有这样的列，InnoDB就自己产生一个这样的ID值，它有六个字节，而且是隐藏的，使其作为聚簇索引。 由于实际的数据页只能按照一棵B+树进行排序，因此每张表只能拥有一个聚集索引。在多少情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在B+树索引的叶子节点上直接找到数据。此外由于定义了数据的逻辑顺序，聚集索引能够特别快地访问针对范围值得查询。 聚集索引的好处 它对主键的排序查找和范围查找速度非常快，叶子节点的数据就是用户所要查询的数据。如用户需要查找一张表，查询最后的10位用户信息，由于B+树索引是双向链表，所以用户可以快速找到最后一个数据页，并取出10条记录 范围查询（range query），即如果要查找主键某一范围内的数据，通过叶子节点的上层中间节点就可以得到页的范围，之后直接读取数据页即可 辅助索引 表中除了聚集索引外其他索引都是辅助索引（Secondary Index，也称为非聚集索引），与聚集索引的区别是：辅助索引的叶子节点不包含行记录的全部数据。 叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含一个书签（bookmark）。该书签用来告诉InnoDB存储引擎去哪里可以找到与索引相对应的行数据。 由于InnoDB存储引擎是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。如下图 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引，但只能有一个聚集索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得只想主键索引的主键，然后再通过主键索引来找到一个完整的行记录。
举例来说，如果在一棵高度为3的辅助索引树种查找数据，那需要对这个辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问才能得到最终的一个数据页。
MySQL索引管理 功能 索引的功能就是加速查找 mysql中的primary key，unique，联合唯一也都是索引，这些索引除了加速查找以外，还有约束的功能 MySQL常用的索引 聚簇索引（主键索引）：
加速查询 存储所有数据 普通索引INDEX：
加速查找 唯一索引：
主键索引PRIMARY KEY：加速查找+约束（不为空、不能重复） 唯一索引UNIQUE:加速查找+约束（不能重复） 联合索引：
加速查找 - PRIMARY KEY(id,name):联合主键索引 - UNIQUE(id,name):联合唯一索引 - INDEX(id,name):联合普通索引 索引建议使用bTree 不建议使用hash索引
创建/删除索引的语法 创建表时 /* CREATE TABLE 表名 ( 字段名1 数据类型 [完整性约束条件…], 字段名2 数据类型 [完整性约束条件…], [UNIQUE | FULLTEXT | SPATIAL ] INDEX | KEY [索引名] (字段名[(长度)] [ASC |DESC]) ); */ create table t1( id int, name char, age int, sex enum('male','female'), unique key uni_id(id), index ix_name(name) # index没有key ); CREATE在已存在的表上创建索引 /* CREATE [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 ON 表名 (字段名[(长度)] [ASC |DESC]) ; */ create index ix_age on t1(age); ALTER TABLE在已存在的表上创建索引 /* ALTER TABLE 表名 ADD [UNIQUE | FULLTEXT | SPATIAL ] INDEX 索引名 (字段名[(长度)] [ASC |DESC]) ; */ alter table t1 add index ix_sex(sex); 查看索引 show create table t1; /* | t1 | CREATE TABLE `t1` ( `id` int(11) DEFAULT NULL, `name` char(1) DEFAULT NULL, `age` int(11) DEFAULT NULL, `sex` enum('male','female') DEFAULT NULL, UNIQUE KEY `uni_id` (`id`), KEY `ix_name` (`name`), KEY `ix_age` (`age`), KEY `ix_sex` (`sex`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1 */ 删除索引 DROP INDEX 索引名 ON 表名字; 查询优化神器 - explain命令 关于explain命令相信大家并不陌生，具体用法和字段含义可以参考官网explain-output ，这里需要强调rows是核心指标，绝大部分rows小的语句执行一定很快（有例外，下面会讲到）。所以优化语句基本上都是在优化rows。
慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE
where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
order by limit 形式的sql语句让排序的表优先查
了解业务方使用场景
加索引时参照建索引的几大原则
观察结果，不符合预期继续从0分析
explain参数 select_typec 表示 SELECT 的类型。 常见的取值有
SIMPLE（简单表，即不使用表连接或者子查询） PRIMARY（主查询，即外层的查询） UNION（UNION 中的第二个或者后面的查询语句） SUBQUERY（子查询中的第一个 SELECT）等。 table 输出结果集的表。
type 表示表的连接类型，性能由好到差的连接类型如下
system（表中仅有一行，即常量表） const（单表中最多有一个匹配行，例如 primary key 或者 unique index） eq_ref（对于前面的每一行，在此表中只查询一条记录，简单来说，就是多表连接中使用primary key或者unique index） ref（与eq_ref类似，区别在于不是使用primary key 或者 unique index，而是使用普通的索引） ref_or_null（与 ref 类似，区别在于条件中包含对 NULL 的查询） index_merge (索引合并优化) unique_subquery（in的后面是一个查询主键字段的子查询） index_subquery（与 unique_subquery 类似，区别在于 in 的后面是查询非唯一索引字段的子查询） range（单表中的范围查询） index（对于前面的每一行，都通过查询索引来得到数据） all（对于前面的每一行，都通过全表扫描来得到数据）。 possible_keys 表示查询时，可能使用的索引。
key 表示实际使用的索引。
key_len 索引字段的长度。
rows 扫描行的数量。
Extra 执行情况的说明和描述。</content></entry><entry><title>Nginx基础</title><url>https://www.zhaohaiyu.com/post/operations/nginx/</url><categories><category>operations</category></categories><tags><tag>运维</tag><tag>nginx</tag></tags><content type="html"> nginx是什么 nginx是一个开源的，支持高性能，高并发的www服务和代理服务软件。
支持高并发，能支持几万并发连接
资源消耗少，在3万并发连接下开启10个nginx线程消耗的内存不到200M
可以做http反向代理和负载均衡
支持异步网络i/o事件模型epoll
Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。T目标是打造一个高效、稳定、安全、易用的Web平台。
安装环境依赖包 yum install gcc-c++ pcre pcre-devel zlib zlib-devel gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl openssl-devel -y 安装并启动nginx 下载源码包 http://tengine.taobao.org/download/tengine-2.3.3.tar.gz
解压缩源码 tar -zxvf tengine-2.3.3.tar.gz配置
编译安装 开启nginx状态监测功能
./configure make &amp;&amp; make install nginx操作，进入nginx下的sbin目录（默认在/usr/local下）
启动./nginx -c指定配置文件 关闭./nginx -s stop 重新加载./nginx -s reload 检查配置文件 ./nginx -t 部署一个web站点 nginx默认站点是Nginx目录下的html文件夹，这里可以从nginx.conf中查到
location / { root html; # 这里是默认的站点html文件夹，也就是 /usr/local/nginx/html 文件夹下的内容 index index.html index.htm; # 站点首页文件名是index.html } 如果要部署网站业务数据，只需要把开发好的程序全放到html目录下即可
[root@VM-0-3-centos html]# ls /usr/local/nginx/html/ 50x.html index.html 因此只需要通过域名/资源，即可访问
http://a.zhaohaoyu.com Nginx的目录结构 client_body_temp conf fastcgi_temp html logs proxy_temp sbin scgi_temp static uwsgi_temp conf 存放nginx所有配置文件的目录,主要nginx.conf
html 存放nginx默认站点的目录，如index.html、error.html等
logs 存放nginx默认日志的目录，如error.log access.log
sbin 存放nginx主命令的目录,./nginx
Nginx主配置文件解析 Nginx主配置文件/etc/nginx/nginx.conf是一个纯文本类型的文件，整个配置文件是以区块的形式组织的。一般，每个区块以一对大括号{}来表示开始与结束。
CoreModule核心模块 user www Nginx进程所使用的用户
worker_processes 1; Nginx运行的work进程数量(建议与CPU数量一致或auto)
error_log logs/error.log Nginx错误日志存放路径
pid logs/nginx.pid Nginx服务运行后产生的pid进程号
events事件模块 events { worker_connections 1024; # 每个worker进程支持的最大连接数 use epool; # 事件驱动模型, epoll默认 } http内核模块 # 公共的配置定义在http http { # http层开始 ... include mime.types; default_type application/octet-stream; access_log logs/access.log main; # 访问日志 # 使用Server配置网站, 每个Server{}代表一个网站(简称虚拟主机) server { listen 80; # 监听端口, 默认80 server_name localhost; # 提供服务的域名或主机名 location / { root html; # 存放网站代码路径 index index.html index.htm; # 服务器返回的默认页面文件 } # 指定错误代码, 统一定义错误页面, 错误代码重定向到新的Locaiton error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } include 当存在多个域名时，如果所有配置都写在 nginx.conf 主配置文件中，难免会显得杂乱与臃肿。为了方便配置文件的维护，所以需要进行拆分配置。
# 在nginx.conf中 加入 include a.zhaohaiyu.com/nginx.conf; # 在a.zhaohaiyu.com/nginx.conf中加入 server { listen 8000; server_name test2.com; location / { proxy_set_header Host $host:$server_port; proxy_set_header X-Real-Ip $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; ## proxy_pass http://xxx.xxx.xxx; echo "test2.com"; ## 输出测试 } } # 等于把zhaohaiyu.com/nginx.conf直接吸入nginx.conf中 Nginx虚拟主机 如果每台linux服务器只运行了一个小网站，那么人气低，流量小的草根站长需要承担高额的服务器租赁费，也造成了硬件资源浪费。
虚拟主机就是将一台服务器分割成多个“虚拟服务器”，每个站点使用各自的硬盘空间，由于省资源，省钱，众多网站都使用虚拟主机来部署网站。
虚拟主机的概念就是在web服务里的一个独立的网站站点，这个站点对应独立的域名（IP），具有独立的程序和资源目录，可以独立的对外提供服务。 这个独立的站点配置是在nginx.conf中使用server{}代码块标签来表示一个虚拟主机。 Nginx支持多个server{}标签，即支持多个虚拟主机站点。
nginx status 启用nginx status配置 在默认主机里面加上location或者你希望能访问到的主机里面。
server { stub_status on; } 重启nginx 请依照你的环境重启你的nginx
./ngnix -s reload
打开status页面 nginx status active connections – 活跃的连接数量
server accepts handled requests — 总共处理了11989个连接 , 成功创建11989次握手, 总共处理了11991个请求
reading — 读取客户端的连接数.
writing — 响应数据到客户端的数量
waiting — 开启 keep-alive 的情况下,这个值等于 active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接.
Nginx代理 正向代理 正向代理，也就是传说中的代理,他的工作原理就像一个跳板（VPN），简单的说：
我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代理服务器呢，他能访问那个我不能访问的网站，于是我先连上代理服务器，告诉他我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给我。
反向代理 对于客户端而言，代理服务器就像是原始服务器。
nginx实现负载均衡的组件
ngx_http_proxy_module # proxy代理模块，用于把请求抛给服务器节点或者upstream服务器池 实现一个简单的反向代理 机器准备，两台服务器
master 192.168.11.63　主负载 slave 192.168.11.64　web1 主负载均衡节点的配置文件
worker_processes 1; error_log logs/error.log; pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; sendfile on; keepalive_timeout 65; upstream slave_pools { server 192.168.11.64:80 weight=1; } server { listen 80; server_name localhost; location / { proxy_pass http://slave_pools; root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 检查语法并启动nginx
[root@master 192.168.11.63 /opt/nginx1-12]$./nginx -t nginx: the configuration file /opt/nginx1-12/conf/nginx.conf syntax is ok nginx: configuration file /opt/nginx1-12/conf/nginx.conf test is successful #启动nginx [root@master 192.168.11.63 /opt/nginx1-12]$/./nginx #检查端口 [root@master 192.168.11.63 /opt/nginx1-12]$netstat -tunlp|grep nginx tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 8921/nginx: master 此时访问master的服务器192.168.11.63:80地址，已经会将请求转发给slave的80端口
除了页面效果的展示以外，还可以通过log(access.log)查看代理效果
master端日志
slave端日志
LOCALTION Location语法优先级排列 匹配符 匹配规则 优先级
= 精确匹配 1
^~ 以某个字符串开头 2
~ 区分大小写的正则匹配 3
~* 不区分大小写的正则匹配 4
!~ 区分大小写不匹配的正则 5
!~* 不区分大小写不匹配的正则 6
/ 通用匹配，任何请求都会匹配到 7
nginx.conf配置文件实例 server { listen 80; server_name pythonav.cn; #优先级1,精确匹配，根路径 location =/ { return 400; } #优先级2,以某个字符串开头,以av开头的，优先匹配这里，区分大小写 location ^~ /av { root /data/av/; } #优先级3，区分大小写的正则匹配，匹配/media*****路径 location ~ /media { alias /data/static/; } #优先级4 ，不区分大小写的正则匹配，所有的****.jpg|gif|png 都走这里 location ~* .*\.(jpg|gif|png|js|css)$ { root /data/av/; } #优先7，通用匹配 location / { return 403; } } nginx语法之root和alias区别实战 nginx指定文件路径有root和alias两种方法 区别在方法和作用域：
方法：
root 语法 root 路径; 默认值 root html; 配置块 http{} server {} location{}
alias 语法： alias 路径 配置块 location{}
root和alias区别在nginx如何解释location后面的url，这会使得两者分别以不同的方式讲请求映射到服务器文件上
root参数是root路径+location位置
root实例：
location ^~ /av { root /data/av; 注意这里可有可无结尾的 / } 请求url是zhaohaiyu.com/av/index.html时 web服务器会返回服务器上的/data/av/av/index.html
root实例2：
location ~* .*\.(jpg|gif|png|js|css)$ { root /data/av/; } 请求url是zhaohaiyu.com/girl.gif时 web服务器会返回服务器上的/data/static/girl.gif
alias实例：
alias参数是使用alias路径替换location路径 alias是一个目录的别名 注意alias必须有 &ldquo;/&rdquo; 结束！ alias只能位于location块中 location ^~ /av { alias /data/static/; } 请求url是zhaohaiyu.com/av/index.html时 web服务器会返回服务器上的/data/static/index.html
Keepalived高可用软件 什么是keepalived
Keepalived是一个用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础架构提供简单而强大的负载均衡和高可用性设施。 还可以作为其他服务（nginx，mysql）的高可用软件 keepalived主要通过vrrp协议实现高可用功能。vrrp叫（virtual router redundancy protocol）虚拟路由器冗余协议，目的为了解决单点故障问题，他可以保证个别节点宕机时。整个网络可以不间断的运行。 高可用故障切换原理
在keepalived工作时，主master节点会不断的向备节点发送心跳消息，告诉备节点自己还活着， 当master节点故障时，就无法发送心跳消息，备节点就无法检测到来自master的心跳了，于是调用自身的接管程序，接管master节点的ip资源以及服务， 当master主节点恢复时，备backup节点又会释放接管的ip资源和服务，回复到原本的备节点角色。 硬件环境准备 实验环境应该最好是4台虚拟机，环境有限因此用2台机器
master
slave
global_defs { notification_email { eric.k.zhang@ericsson.com } notification_email_from keepalived@node-10-210-149-21 smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_script check_webproxy { script "killall -0 nginx" interval 1 weight 21 } vrrp_script check_mantaince_down { script "[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0" interval 1 weight 2 } vrrp_instance vip_10_210_149_23 { state MASTER interface ens192 virtual_router_id 23 garp_master_delay 1 mcast_src_ip 10.210.149.21 lvs_sync_daemon_interface ens192 priority 110 advert_int 2 authentication { auth_type PASS auth_pass 1111 } track_interface { ens192 } virtual_ipaddress { 10.210.149.23/24 dev ens192 label ens192:0 } track_script { check_webproxy check_mantaince_down } } vrrp_instance nginx_vip_10_210.149_24 { state BACKUP interface ens192 virtual_router_id 24 garp_master_delay 1 mcast_src_ip 10.210.149.21 lvs_sync_daemon_interface ens192 priority 100 advert_int 2 authentication { auth_type PASS auth_pass 1111 } track_interface { ens192 } virtual_ipaddress { 10.210.149.24/24 dev ens192 label ens192:1 } track_script { check_webproxy check_mantaince_down } } global_defs { notification_email { eric.k.zhang@ericsson.com } notification_email_from keepalived@node-10-210-149-21 smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_script check_webproxy { script "killall -0 nginx" interval 1 weight 21 } vrrp_script check_mantaince_down { script "[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0" interval 1 weight 2 } vrrp_instance vip_10_210_149_23 { state BACKUP interface ens192 virtual_router_id 23 garp_master_delay 1 mcast_src_ip 10.210.149.22 lvs_sync_daemon_interface ens192 priority 100 advert_int 2 authentication { auth_type PASS auth_pass 1111 } track_interface { ens192 } virtual_ipaddress { 10.210.149.23/24 dev ens192 label ens192:0 } track_script { check_webproxy check_mantaince_down } } vrrp_instance nginx_vip_10_210.149_24 { state MASTER interface ens192 virtual_router_id 24 garp_master_delay 1 mcast_src_ip 10.210.149.22 lvs_sync_daemon_interface ens192 priority 110 advert_int 2 authentication { auth_type PASS auth_pass 1111 } track_interface { ens192 } virtual_ipaddress { 10.210.149.24/24 dev ens192 label ens192:1 } track_script { check_webproxy check_mantaince_down } }</content></entry><entry><title>Makefile</title><url>https://www.zhaohaiyu.com/post/operations/makefile/</url><categories><category>operations</category></categories><tags><tag>运维</tag><tag>makefile</tag></tags><content type="html"> make make是一个构建自动化工具，会在当前目录下寻找Makefile或makefile文件。如果存在相应的文件，它就会依据其中定义好的规则完成构建任务。
makefile 什么是makefile？或许很多Winodws的程序员都不知道这个东西，因为那些Windows的IDE都为你做了这个工作，但我觉得要作一个好的和professional的程序员，makefile还是要懂。这就好像现在有这么多的HTML的编辑器，但如果你想成为一个专业人士，你还是要了解HTML的标识的含义。特别在Unix下的软件编译，你就不能不自己写makefile了，会不会写makefile，从一个侧面说明了一个人是否具备完成大型工程的能力。因为，makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。
规则概述 Makefile由多条规则组成，每条规则主要由两个部分组成，分别是依赖的关系和执行的命令。
其结构如下所示：
[target] ... : [prerequisites] ... [command] ... ... 其中：
targets：规则的目标 prerequisites：可选的要生成 targets 需要的文件或者是目标。 command：make 需要执行的命令（任意的 shell 命令）。可以有多条命令，每一条命令占一行。 举个例子：
build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o xx 示例 .PHONY: all build run gotool clean help BINARY="coursemanager" all: build build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ${BINARY} run: @go run ./ gotool: go fmt ./ go vet ./ clean: @if [ -f ${BINARY} ] ; then rm ${BINARY} ; fi help: @echo "make - 格式化 Go 代码, 并编译生成二进制文件" @echo "make build - 编译 Go 代码, 生成二进制文件" @echo "make run - 直接运行 Go 代码" @echo "make clean - 移除二进制文件和 vim swap files" @echo "make gotool - 运行 Go 工具 'fmt' and 'vet'" 参考文章:
https://www.liwenzhou.com/posts/Go/makefile/ https://blog.csdn.net/weixin_38391755/article/details/80380786</content></entry><entry><title>Go Channel源码分析</title><url>https://www.zhaohaiyu.com/post/go/go-deep-channel/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> channel介绍 channel一个类型管道，通过它可以在goroutine之间发送和接收消息。它是Golang在语言层面提供的goroutine间的通信方式。
众所周知，Go依赖于称为CSP（Communicating Sequential Processes）的并发模型，通过Channel实现这种同步模式。Go并发的核心哲学是不要通过共享内存进行通信; 相反，通过沟通分享记忆。
下面以简单的示例来演示Go如何通过channel来实现通信。
package main import ( "fmt" "time" ) func goRoutineA(a &lt;-chan int) { val := &lt;-a fmt.Println("goRoutineA received the data", val) } func goRoutineB(b chan int) { val := &lt;-b fmt.Println("goRoutineB received the data", val) } func main() { ch := make(chan int, 3) go goRoutineA(ch) go goRoutineB(ch) ch &lt;- 3 time.Sleep(time.Second * 1) } 结果为：goRoutineA received the data 3
上面只是个简单的例子，只输出goRoutineA ，没有执行goRoutineB，说明channel仅允许被一个goroutine读写。
go并发知识：go并发 说道channel这里不得不提通道的结构hchan。
hchan 源代码在src/runtime/chan.go
type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } type waitq struct { first *sudog last *sudog } 说明：
qcount uint // 当前队列中剩余元素个数 dataqsiz uint // 环形队列长度，即缓冲区的大小，即make（chan T，N），N. buf unsafe.Pointer // 环形队列指针 elemsize uint16 // 每个元素的大小 closed uint32 // 表示当前通道是否处于关闭状态。创建通道后，该字段设置为0，即通道打开; 通过调用close将其设置为1，通道关闭。 elemtype *_type // 元素类型，用于数据传递过程中的赋值； sendx uint和recvx uint是环形缓冲区的状态字段，它指示缓冲区的当前索引 - 支持数组，它可以从中发送数据和接收数据。 recvq waitq // 等待读消息的goroutine队列 sendq waitq // 等待写消息的goroutine队列 lock mutex // 互斥锁，为每个读写操作锁定通道，因为发送和接收必须是互斥操作。 这里sudog代表goroutine。
make chan make函数在创建channel的时候会在该进程的heap区申请一块内存，创建一个hchan结构体，返回执行该内存的指针，所以获取的的ch变量本身就是一个指针，在函数之间传递的时候是同一个channel。
hchan结构体使用一个环形队列来保存groutine之间传递的数据(如果是缓存channel的话)，使用两个list保存像该chan发送和从该chan接收数据的goroutine，还有一个mutex来保证操作这些结构的安全。
创建channel 有两种，一种是带缓冲的channel，一种是不带缓冲的channel
// 带缓冲 ch := make(chan Task, 3) // 不带缓冲 ch := make(chan int) 这里我们先讨论带缓冲
ch := make(chan int, 3) 创建通道后的缓冲通道结构
hchan struct { qcount uint : 0 dataqsiz uint : 3 buf unsafe.Pointer : 0xc00007e0e0 elemsize uint16 : 8 closed uint32 : 0 elemtype *runtime._type : &amp;{ size:8 ptrdata:0 hash:4149441018 tflag:7 align:8 fieldalign:8 kind:130 alg:0x55cdf0 gcdata:0x4d61b4 str:1055 ptrToThis:45152 } sendx uint : 0 recvx uint : 0 recvq runtime.waitq : {first:&lt;nil> last:&lt;nil>} sendq runtime.waitq : {first:&lt;nil> last:&lt;nil>} lock runtime.mutex : {key:0} } 源代码
func makechan(t *chantype, size int) *hchan { elem := t.elem ... } 如果我们创建一个带buffer的channel，底层的数据模型如下图：
发送和接受数据 向channel发送和从channel接收数据主要涉及hchan里的四个成员变量，借用Kavya ppt里的图示，来分析发送和接收的过程。
向channel写入数据 ch &lt;- 3 底层hchan数据流程如图
发送操作概要
1、锁定整个通道结构。
2、确定写入。尝试recvq从等待队列中等待goroutine，然后将元素直接写入goroutine。
3、如果recvq为Empty，则确定缓冲区是否可用。如果可用，从当前goroutine复制数据到缓冲区。
4、如果缓冲区已满，则要写入的元素将保存在当前正在执行的goroutine的结构中，并且当前goroutine将在sendq中排队并从运行时挂起。
5、写入完成释放锁。
这里我们要注意几个属性buf、sendx、lock的变化。
流程图
从channel读取操作 几乎和写入操作相同
代码
func goRoutineA(a &lt;-chan int) { val := &lt;-a fmt.Println("goRoutineA received the data", val) } 底层hchan数据流程如图
这里我们要注意几个属性buf、sendx、recvx、lock的变化。
读取操作概要
先获取channel全局锁 尝试sendq从等待队列中获取等待的goroutine， 如有等待的goroutine，没有缓冲区，取出goroutine并读取数据，然后唤醒这个goroutine，结束读取释放锁。 如有等待的goroutine，且有缓冲区（此时缓冲区已满），从缓冲区队首取出数据，再从sendq取出一个goroutine，将goroutine中的数据存入buf队尾，结束读取释放锁。 如没有等待的goroutine，且缓冲区有数据，直接读取缓冲区数据，结束读取释放锁。 如没有等待的goroutine，且没有缓冲区或缓冲区为空，将当前的goroutine加入recvq排队，进入睡眠，等待被写goroutine唤醒。结束读取释放锁。 流程图
recvq和sendq 结构 recvq和sendq基本上是链表，看起来基本如下
Goroutine Pause/Resume goroutine是Golang实现的用户空间的轻量级的线程，有runtime调度器调度，与操作系统的thread有多对一的关系，相关的数据结构如下图:
其中M是操作系统的线程，G是用户启动的goroutine，P是与调度相关的context，每个M都拥有一个P，P维护了一个能够运行的goutine队列，用于该线程执行。
当G1向buf已经满了的ch发送数据的时候，当runtine检测到对应的hchan的buf已经满了，会通知调度器，调度器会将G1的状态设置为waiting, 移除与线程M的联系，然后从P的runqueue中选择一个goroutine在线程M中执行，此时G1就是阻塞状态，但是不是操作系统的线程阻塞，所以这个时候只用消耗少量的资源。
那么G1设置为waiting状态后去哪了？怎们去resume呢？我们再回到hchan结构体，注意到hchan有个sendq的成员，其类型是waitq，查看源码如下：
type hchan struct { ... recvq waitq // list of recv waiters sendq waitq // list of send waiters ... } // type waitq struct { first *sudog last *sudog } 实际上，当G1变为waiting状态后，会创建一个代表自己的sudog的结构，然后放到sendq这个list中，sudog结构中保存了channel相关的变量的指针(如果该Goroutine是sender，那么保存的是待发送数据的变量的地址，如果是receiver则为接收数据的变量的地址，之所以是地址，前面我们提到在传输数据的时候使用的是copy的方式)
当G2从ch中接收一个数据时，会通知调度器，设置G1的状态为runnable，然后将加入P的runqueue里，等待线程执行.
wait empty channel 前面我们是假设G1先运行，如果G2先运行会怎么样呢？如果G2先运行，那么G2会从一个empty的channel里取数据，这个时候G2就会阻塞，和前面介绍的G1阻塞一样，G2也会创建一个sudog结构体，保存接收数据的变量的地址，但是该sudog结构体是放到了recvq列表里，当G1向ch发送数据的时候，runtime并没有对hchan结构体题的buf进行加锁，而是直接将G1里的发送到ch的数据copy到了G2 sudog里对应的elem指向的内存地址！
select select就是用来监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作。
一个简单的示例如下
package main import ( "fmt" "time" ) func goRoutineD(ch chan int, i int) { time.Sleep(time.Second * 3) ch &lt;- i } func goRoutineE(chs chan string, i string) { time.Sleep(time.Second * 3) chs &lt;- i } func main() { ch := make(chan int, 5) chs := make(chan string, 5) go goRoutineD(ch, 5) go goRoutineE(chs, "ok") select { case msg := &lt;-ch: fmt.Println(" received the data ", msg) case msgs := &lt;-chs: fmt.Println(" received the data ", msgs) default: fmt.Println("no data received ") time.Sleep(time.Second * 1) } } 运行程序，因为当前时间没有到3s，所以select 选择defult
no data received
修改程序，我们注释掉default，并多执行几次结果为
received the data 5 received the data ok received the data ok received the data ok select语句会阻塞，直到监测到一个可以执行的IO操作为止，而这里goRoutineD和goRoutineE睡眠时间是相同的，都是3s，从输出可看出，从channel中读出数据的顺序是随机的。
再修改代码，goRoutineD睡眠时间改成4s
func goRoutineD(ch chan int, i int) { time.Sleep(time.Second * 4) ch &lt;- i } 此时会先执行goRoutineE，select 选择case msgs := &lt;-chs。
range 可以持续从channel读取数据，一直到channel被关闭，当channel中没有数据时会阻塞当前goroutine，与读channel时阻塞处理机制一样。
package main import ( "fmt" "time" ) func goRoutineD(ch chan int, i int) { for i := 1; i &lt;= 5; i++{ ch &lt;- i } } func chanRange(chanName chan int) { for e := range chanName { fmt.Printf("Get element from chan: %d\n", e) if len(chanName) &lt;= 0 { // 如果现有数据量为0，跳出循环 break } } } func main() { ch := make(chan int, 5) go goRoutineD(ch, 5) chanRange(ch) } 结果：
Get element from chan: 1 Get element from chan: 2 Get element from chan: 3 Get element from chan: 4 Get element from chan: 5 死锁（deadlock） 指两个或两个以上的协程的执行过程中，由于竞争资源或由于彼此通信而造成的一种阻塞的现象。
在非缓冲信道若发生只流入不流出，或只流出不流入，就会发生死锁。
下面是一些死锁的例子
1、
package main func main() { ch := make(chan int) ch &lt;- 3 } 上面情况，向非缓冲通道写数据会发生阻塞，导致死锁。解决办法创建缓冲区 ch := make(chan int，3)
2、
package main import ( "fmt" ) func main() { ch := make(chan int) fmt.Println(&lt;-ch) } 向非缓冲通道读取数据会发生阻塞，导致死锁。 解决办法开启缓冲区，先向channel写入数据。
3、
package main func main() { ch := make(chan int, 3) ch &lt;- 3 ch &lt;- 4 ch &lt;- 5 ch &lt;- 6 } 写入数据超过缓冲区数量也会发生死锁。解决办法将写入数据取走。
死锁的情况有很多这里不再赘述。 还有一种情况，向关闭的channel写入数据，不会产生死锁，产生panic。
package main func main() { ch := make(chan int, 3) ch &lt;- 1 close(ch) ch &lt;- 2 } 解决办法别向关闭的channel写入数据。
参考文章 Go channel 实现原理分析 深入理解Golang Channel</content></entry><entry><title>Go fmt包</title><url>https://www.zhaohaiyu.com/post/go/go-fmt/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> fmt fmt包实现了类似C语言printf和scanf的格式化I/O。主要分为向外输出内容和获取输入内容两大部分。
向外输出 标准库fmt提供了以下几种输出相关函数。
Print Print系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。
func Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error) Fprint Fprint系列函数会将内容输出到一个io.Writer接口类型的变量w中，我们通常用这个函数往文件中写入内容。
func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) Sprint Sprint系列函数会把传入的数据生成并返回一个字符串。
func Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string Errorf Errorf函数根据format参数生成格式化字符串并返回一个包含该字符串的错误。
func Errorf(format string, a ...interface{}) error 格式化占位符 *printf系列函数都支持format格式化参数，在这里我们按照占位符将被替换的变量类型划分，方便查询和记忆。
通用占位符 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go语法表示 %T 打印值的类型 %% 百分号 布尔型 占位符 说明 %t true或false 整型 占位符 说明 %b 表示为二进制 %c 该值对应的unicode码值 %d 表示为十进制 %o 表示为八进制 %x 表示为十六进制，使用a-f %X 表示为十六进制，使用A-F %U 表示为Unicode格式：U+1234，等价于”U+%04X” %q 该值对应的单引号括起来的go语法字符字面值，必要时会采用安全的转义表示 浮点数与复数 占位符 说明 %b 无小数部分、二进制指数的科学计数法，如-123456p-78 %e 科学计数法，如-1234.456e+78 %E 科学计数法，如-1234.456E+78 %f 有小数部分但无指数部分，如123.456 %F 等价于%f %g 根据实际情况采用%e或%f格式（以获得更简洁、准确的输出） %G 根据实际情况采用%E或%F格式（以获得更简洁、准确的输出） 字符串和[]byte 占位符 说明 %s 直接输出字符串或者[]byte %q 该值对应的双引号括起来的go语法字符串字面值，必要时会采用安全的转义表示 %x 每个字节用两字符十六进制数表示（使用a-f） %X 每个字节用两字符十六进制数表示（使用A-F） 指针 占位符 说明 %p 表示为十六进制，并加上前导的0x 宽度标识符 宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可选的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下：
占位符 说明 %f 默认宽度，默认精度 %9f 宽度9，默认精度 %.2f 默认宽度，精度2 %9.2f 宽度9，精度2 %9.f 宽度9，精度0 其他falg 占位符 说明 ’+’ 总是输出数值的正负号；对%q（%+q）会生成全部是ASCII字符的输出（通过转义）； ’ ‘ 对数值，正数前加空格而负数前加负号；对字符串采用%x或%X时（% x或% X）会给各打印的字节之间加空格 ’-’ 在输出右边填充空白而不是默认的左边（即从默认的右对齐切换为左对齐）； ’#’ 八进制数前加0（%#o），十六进制数前加0x（%#x）或0X（%#X），指针去掉前面的0x（%#p）对%q（%#q），对%U（%#U）会输出空格和单引号括起来的go字面值； ‘0’ 使用0而不是空格填充，对于数值类型会把填充的0放在正负号后面； 获取输入 Go语言fmt包下有fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，可以在程序运行过程中从标准输入获取用户的输入。
fmt.Scan 函数定签名如下：
func Scan(a ...interface{}) (n int, err error) Scan从标准输入扫描文本，读取由空白符分隔的值保存到传递给本函数的参数中，换行符视为空白符。 本函数返回成功扫描的数据个数和遇到的任何错误。如果读取的数据个数比提供的参数少，会返回一个错误报告原因。 具体代码示例如下：
func main() { var ( name string age int married bool ) fmt.Scan(&amp;name, &amp;age, &amp;married) fmt.Printf("扫描结果 name:%s age:%d married:%t \n", name, age, married) } 将上面的代码编译后在终端执行，在终端依次输入小王子、28和false使用空格分隔。
$ ./scan_demo 小王子 28 false 扫描结果 name:小王子 age:28 married:false fmt.Scan从标准输入中扫描用户输入的数据，将以空白符分隔的数据分别存入指定的参数。
fmt.Scanf 函数签名如下：
func Scanf(format string, a ...interface{}) (n int, err error) Scanf从标准输入扫描文本，根据format参数指定的格式去读取由空白符分隔的值保存到传递给本函数的参数中。 本函数返回成功扫描的数据个数和遇到的任何错误。 代码示例如下：
func main() { var ( name string age int married bool ) fmt.Scanf("1:%s 2:%d 3:%t", &amp;name, &amp;age, &amp;married) fmt.Printf("扫描结果 name:%s age:%d married:%t \n", name, age, married) } 将上面的代码编译后在终端执行，在终端按照指定的格式依次输入小王子、28和false。
$ ./scan_demo 1:zhy 2:18 3:false 扫描结果 name:zhy age:18 married:false fmt.Scanf不同于fmt.Scan简单的以空格作为输入数据的分隔符，fmt.Scanf为输入数据指定了具体的输入内容格式，只有按照格式输入数据才会被扫描并存入对应变量。
例如，我们还是按照上个示例中以空格分隔的方式输入，fmt.Scanf就不能正确扫描到输入的数据。
$ ./scan_demo zhy 18 false 扫描结果 zhy: age:0 married:false fmt.Scanln 函数签名如下：
func Scanln(a ...interface{}) (n int, err error) Scanln类似Scan，它在遇到换行时才停止扫描。最后一个数据后面必须有换行或者到达结束位置。 本函数返回成功扫描的数据个数和遇到的任何错误。 具体代码示例如下：
func main() { var ( name string age int married bool ) fmt.Scanln(&amp;name, &amp;age, &amp;married) fmt.Printf("扫描结果 name:%s age:%d married:%t \n", name, age, married) } $ ./scan_demo zhy 18 false 扫描结果 name:zhy age:28 married:false fmt.Scanln遇到回车就结束扫描了，这个比较常用。
bufio.NewReader 有时候我们想完整获取输入的内容，而输入的内容可能包含空格，这种情况下可以使用bufio包来实现。示例代码如下：
func bufioDemo() { reader := bufio.NewReader(os.Stdin) // 从标准输入生成读对象 fmt.Print("请输入内容：") text, _ := reader.ReadString('\n') // 读到换行 text = strings.TrimSpace(text) fmt.Printf("%#v\n", text) } Fscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从io.Reader中读取数据。
func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) Sscan系列 这几个函数功能分别类似于fmt.Scan、fmt.Scanf、fmt.Scanln三个函数，只不过它们不是从标准输入中读取数据而是从指定字符串中读取数据。
func Sscan(str string, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) 参考文章:https://www.liwenzhou.com/posts/Go/go_fmt/</content></entry><entry><title>Go time包</title><url>https://www.zhaohaiyu.com/post/go/go-time/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 时间类型 time.Time类型表示时间。
func demo() { now := time.Now() //获取当前时间 fmt.Printf("Now:%v\n", now) // Now:2020-08-19 21:53:31.1633023 +0800 CST m=+0.003989401 year := now.Year() //年 month := now.Month() //月 day := now.Day() //日 hour := now.Hour() //小时 minute := now.Minute() //分钟 second := now.Second() //秒 fmt.Printf("%d-%02d-%02d %02d:%02d:%02d\n", year, month, day, hour, minute, second) // 2020-08-19 21:53:31 } 时间戳 func stamp() { now := time.Now() //获取当前时间 timestamp1 := now.Unix() //时间戳 timestamp2 := now.UnixNano() //纳秒时间戳 fmt.Printf("秒时间戳:%v\n", timestamp1) // 秒时间戳:1597845356 fmt.Printf("纳秒时间戳:%v\n", timestamp2) // 纳秒时间戳:1597845356562315400 } 使用time.Unix()函数可以将时间戳转为时间格式。
func demo2(timestamp int64) { timeObj := time.Unix(1462032000, 0) //将时间戳转为时间格式 fmt.Println(timeObj) // 2016-05-01 00:00:00 +0800 CST } 时间格式化 时间类型有一个自带的方法Format进行格式化，需要注意的是Go语言中格式化时间模板不是常见的Y-m-d H:M:S而是使用Go的诞生时间2006年1月2号15点04分
func demo4() { now := time.Now() fmt.Println(now.Format("2006-01-02 15:04:05.000 Mon Jan")) // 2020-08-19 22:02:46.296 Wed Aug fmt.Println(now.Format("2006-01-02 03:04:05.000 PM Mon Jan")) // 2020-08-19 10:02:46.296 PM Wed Aug fmt.Println(now.Format("2006*01*02")) // 2020*08*19 } 解析字符串格式的时间
// 加载时区 loc, err := time.LoadLocation("Asia/Shanghai") if err != nil { fmt.Println(err) return } // 解析字符串时间 timeObj, err := time.ParseInLocation("2006/01/02 15:04:05", "2016/04/30 22:00:00", loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) // 2016-04-30 22:00:00 +0800 CST fmt.Println(timeObj.Unix()) // 1462024800 时间操作 func (t Time) Add(d Duration) Time加时间 func (t Time) Sub(u Time) Duration减时间 func (t Time) Before(u Time) bool在u之前 func (t Time) After(u Time) bool在u之后 package main import ( "fmt" "time" ) func formatDemo() { now := time.Now() fmt.Println(now.Format("2006-01-02 15:04:05.000 Mon Jan")) // 2020-08-19 22:02:46.296 Wed Aug fmt.Println(now.Format("2006-01-02 03:04:05.000 PM Mon Jan")) // 2020-08-19 10:02:46.296 PM Wed Aug fmt.Println(now.Format("2006*01*02")) // 2020*08*19 } func main() { // 加载时区 loc, err := time.LoadLocation("Asia/Shanghai") if err != nil { fmt.Println(err) return } // 解析字符串时间 timeObj, err := time.ParseInLocation("2006/01/02 15:04:05", "2016/04/30 22:00:00", loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) // 2016-04-30 22:00:00 +0800 CST now := time.Now() a := now.Add(time.Hour) fmt.Println(a) // 2020-08-19 23:15:30.0153059 +0800 CST m=+3600.002023801 s := now.Sub(timeObj) fmt.Println(s) // 37728h15m30.0153059s fmt.Println(now.Before(timeObj)) // false fmt.Println(now.After(timeObj)) // true } 定时器 使用time.Tick(时间间隔)来设置定时器，定时器的本质上是一个channel
func tickDemo() { ticker := time.Tick(time.Second) //定义一个1秒间隔的定时器 for i := range ticker { fmt.Println(i) //每秒都会打印时间 } }</content></entry><entry><title>MySQL数据完整性约束</title><url>https://www.zhaohaiyu.com/post/database/mysql-constraint/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> 主键约束 主键可以是表中的某一列，也可以是表中的多个列所构成的一个组合；其中，由多个列组合而成的主键也称为复合主键。在MySQL中，主键列必须遵守以下规则。
（1）每一个表只能定义一个主键。
（2）唯一性原则。主键的值，也称键值，必须能够唯一表示表中的每一条记录，且不能为NULL。
（3）最小化规则。复合主键不能包含不必要的多余列。也就是说，当从一个复合主键中删除一列后，如果剩下的列构成的主键仍能满足唯一性原则，那么这个复合主键是不正确的。
（4）一个列名在复合主键的列表中只能出现一次。
示例：创建学生信息表tb_student时，将学号（stu_id）字段设置为主键。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(30) ); 示例：创建用户信息表tb_student时，将学号（stu_id）和所在班级号（class_id）字段设置为复合主键。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT, name VARCHAR(30), class_id INT NOT NULL, PRIMARY KEY (stu_id,class_id) ); 示例：通过修改数据表结构，添加主键约束。
ALTER TABLE tb_student ADD CONSTRAINT PRIMARY KEY(stu_id); 唯一约束 唯一约束使用UNIQUE关键字来定义。唯一约束的值必须是唯一的，且不能为空（NULL）。
在MySQL中，唯一约束与主键之间存在以下两点区别。
（1）一个表只能创建一个主键，但可以定义多个唯一约束。
（2）定义主键约束时，系统会自动创建PRIMARY KEY索引，而定义候选键约束时，系统会自动创建UNIQUE索引。
示例：创建用户信息表tb_student时，将学号（stu_id）和姓名（name）设置为唯一约束。
CREATE TABLE tb_student ( stu_id INT UNIQUE, name VARCHAR(30) UNIQUE ); 示例：创建用户信息表tb_student时，将学号（stu_id）和姓名（name）字段设置为复合唯一约束。
CREATE TABLE tb_student ( stu_id INT, name VARCHAR(30), UNIQUE uniq_id_name (stu_id,name) ); 示例：通过修改数据表结构，添加唯一约束。
ALTER TABLE tb_student ADD CONSTRAINT uniq_id_name UNIQUE(stu_id,name); 外键约束 MySQL有两种常用的引擎类型（MyISAM和InnoDB），目前，只用InnoDB引擎类型支持外键约束。
示例：创建班级信息表（tb_class）和学生信息表（tb_student），并设置学生信息表中班级编号（class_id）字段的外键约束。
&ndash; 创建班级信息表
CREATE TABLE tb_class ( class_id INT AUTO_INCREMENT PRIMARY KEY, class_name VARCHAR(30) NOT NULL ); &ndash; 创建学生信息表，并设置班级ID的外键约束
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(30), class_id INT NOT NULL, FOREIGN KEY fk_class_id (class_id) REFERENCES tb_class(class_id) ); 示例：通过修改数据表结构，添加外键约束。
ALTER TABLE tb_student ADD CONSTRAINT FOREIGN KEY fk_class_id (class_id) REFERENCES tb_class(class_id); 非空约束 非空约约束就是限制必须为某个列提供值。空值（NULL）是不存在值，它既不是数字0，也不是空字符串，而是不存在、未知的情况。
示例：创建学生信息表tb_student时，将姓名（name）字段添加为非空约束。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(30) NOT NULL ); 示例：通过修改数据表结构，将姓名（name）字段修改为非空。
ALTER TABLE tb_student MODIFY COLUMN name VARCHAR(30) NOT NULL; 检查约束 检查约束用来指定某列的可取值的范围，它通过限制输入到列中的值来强制域的完整性。
示例：创建学生信息表tb_student时，将年龄（age）的值设置在7至18之间（不包括18）的数值。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(30), age INT NOT NULL CHECK(age>=7 AND age&lt;18) ); 注意：目前的MySQL版本只是对CHECK约束进行了分析处理，但会被直接忽略，并不会报错。
约束的删除 删除约束语法：
ALTER TABLE 表名 DROP [FOREIGN KEY| INDEX 约束名称]|[PRIMARY KEY] 示例：删除约束。
CREATE TABLE tb_student ( stu_id INT, name VARCHAR(30) , class_id INT NOT NULL, -- 主键约束 PRIMARY KEY(stu_id), -- 外键约束 FOREIGN KEY fk_class_id (class_id) REFERENCES tb_class(class_id), -- 唯一性约束 UNIQUE uniq_name (name) ); -- 删除主键约束 ALTER TABLE tb_student DROP PRIMARY KEY; -- 删除外键约束 ALTER TABLE tb_student DROP FOREIGN KEY fk_class_id; -- 删除唯一性约束 ALTER TABLE tb_student DROP INDEX uniq_name; 文章转自： https://blog.csdn.net/pan_junbiao/article/details/86158117</content></entry><entry><title>MySQL基础数据类型</title><url>https://www.zhaohaiyu.com/post/database/mysql-data-type/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html"> 数值类型 MySQL支持所有标准SQL数值数据类型。
这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION)。
关键字INT是INTEGER的同义词，关键字DEC是DECIMAL的同义词。
BIT数据类型保存位字段值，并且支持MyISAM、MEMORY、InnoDB和BDB表。
作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。下面的表显示了需要的每个整数类型的存储和范围。
类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) ，如果M>D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 日期和时间类型 表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。
每个时间类型有一个有效值范围和一个"零"值，当指定不合法的MySQL不能表示的值时使用"零"值。
TIMESTAMP类型有专有的自动更新特性，将在后面描述。
类型 大小 (字节) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 &lsquo;-838:59:59&rsquo;/&lsquo;838:59:59&rsquo; HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 字符串类型 字符串类型指CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM和SET。该节描述了这些类型如何工作以及如何在查询中使用这些类型。
类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-65535 字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215字节 中等长度文本数据 LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295字节 极大文本数据 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。
BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。
BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们区别在于可容纳存储范围不同。
有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。对应的这 4 种 BLOB 类型，可存储的最大长度不同，可根据实际情况选择。
文章转自 http://www.runoob.com/mysql/mysql-data-types.html</content></entry><entry><title>Go Map实现原理</title><url>https://www.zhaohaiyu.com/post/go/go-deep-map/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 这篇文章主要讲 map 的赋值、删除、查询、扩容的具体执行过程，仍然是从底层的角度展开。结合源码，看完本文一定会彻底明白 map 底层原理。
我要说明的是，这里对 map 的基本用法涉及比较少，我相信可以通过阅读其他入门书籍了解。本文的内容比较深入，但是由于我画了各种图，我相信很容易看懂。
什么是 map 维基百科里这样定义 map：
In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.
简单说明一下：在计算机科学里，被称为相关数组、map、符号表或者字典，是由一组 &lt;key, value> 对组成的抽象数据结构，并且同一个 key 只会出现一次。
有两个关键点：map 是由 key-value 对组成的；key 只会出现一次。
和 map 相关的操作主要是：
增加一个 k-v 对 —— Add or insert； 删除一个 k-v 对 —— Remove or delete； 修改某个 k 对应的 v —— Reassign； 查询某个 k 对应的 v —— Lookup； 简单说就是最基本的 增删查改。
map 的设计也被称为 “The dictionary problem”，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：哈希查找表（Hash table）、搜索树（Search tree）。
哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。
哈希查找表一般会存在“碰撞”的问题，就是说不同的 key 被哈希到了同一个 bucket。一般有两种应对方法：链表法和开放地址法。链表法将一个 bucket 实现成一个链表，落在同一个 bucket 中的 key 都会插入这个链表。开放地址法则是碰撞发生后，通过一定的规律，在数组的后面挑选“空位”，用来放置新的 key。
搜索树法一般采用自平衡搜索树，包括：AVL 树，红黑树。面试时经常会被问到，甚至被要求手写红黑树代码，很多时候，面试官自己都写不上来，非常过分。
自平衡搜索树法的最差搜索效率是 O(logN)，而哈希查找表最差是 O(N)。当然，哈希查找表的平均查找效率是 O(1)，如果哈希函数设计的很好，最坏的情况基本不会出现。还有一点，遍历自平衡搜索树，返回的 key 序列，一般会按照从小到大的顺序；而哈希查找表则是乱序的。
为什么要用 map 从 Go 语言官方博客摘录一段话：
One of the most useful data structures in computer science is the hash table. Many hash table implementations exist with varying properties, but in general they offer fast lookups, adds, and deletes. Go provides a built-in map type that implements a hash table.
hash table 是计算机数据结构中一个最重要的设计。大部分 hash table 都实现了快速查找、添加、删除的功能。Go 语言内置的 map 实现了上述所有功能。
很难想象写一个程序不使用 map，以至于在回答为什么要用 map 这个问题上犯了难。
所以，到底为什么要用 map 呢？因为它太强大了，各种增删查改的操作效率非常高。
map 的底层如何实现 首先声明我用的 Go 版本：
go version go1.9.2 darwin/amd64 前面说了 map 实现的几种方案，Go 语言采用的是哈希查找表，并且使用链表解决哈希冲突。
接下来我们要探索 map 的核心原理，一窥它的内部结构。
map 内存模型 在源码中，表示 map 的结构体是 hmap，它是 hashmap 的“缩写”：
// A header for a Go map. type hmap struct { // 元素个数，调用 len(map) 时，直接返回此值 count int flags uint8 // buckets 的对数 log_2 B uint8 // overflow 的 bucket 近似数 noverflow uint16 // 计算 key 的哈希的时候会传入哈希函数 hash0 uint32 // 指向 buckets 数组，大小为 2^B // 如果元素个数为0，就为 nil buckets unsafe.Pointer // 扩容的时候，buckets 长度会是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 指示扩容进度，小于此地址的 buckets 迁移完成 nevacuate uintptr extra *mapextra // optional fields } 说明一下，B 是 buckets 数组的长度的对数，也就是说 buckets 数组的长度就是 2^B。bucket 里面存储了 key 和 value，后面会再讲。
buckets 是一个指针，最终它指向的是一个结构体：
type bmap struct { tophash [bucketCnt]uint8 } 但这只是表面(src/runtime/hashmap.go)的结构，编译期间会给它加料，动态地创建一个新的结构：
type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } bmap 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置）。
来一个整体的图：
当 map 的 key 和 value 都不是指针，并且 size 都小于 128 字节的情况下，会把 bmap 标记为不含指针，这样可以避免 gc 时扫描整个 hmap。但是，我们看 bmap 其实有一个 overflow 的字段，是指针类型的，破坏了 bmap 不含指针的设想，这时会把 overflow 移动到 extra 字段来。
type mapextra struct { // overflow[0] contains overflow buckets for hmap.buckets. // overflow[1] contains overflow buckets for hmap.oldbuckets. overflow [2]*[]*bmap // nextOverflow 包含空闲的 overflow bucket，这是预分配的 bucket nextOverflow *bmap } bmap 是存放 k-v 的地方，我们把视角拉近，仔细看 bmap 的内部组成。
上图就是 bucket 的内存模型，HOB Hash 指的就是 top hash。 注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式。源码里说明这样的好处是在某些情况下可以省略掉 padding 字段，节省内存空间。
例如，有这样一个类型的 map：
map[int64]int8 如果按照 key/value/key/value/... 这样的模式存储，那在每一个 key/value 对之后都要额外 padding 7 个字节；而将所有的 key，value 分别绑定到一起，这种形式 key/key/.../value/value/...，则只需要在最后添加 padding。
每个 bucket 设计成最多只能放 8 个 key-value 对，如果有第 9 个 key-value 落入当前的 bucket，那就需要再构建一个 bucket ，通过 overflow 指针连接起来。
创建 map 从语法层面上来说，创建 map 很简单：
ageMp := make(map[string]int) // 指定 map 长度 ageMp := make(map[string]int, 8) // ageMp 为 nil，不能向其添加元素，会直接panic var ageMp map[string]int 通过汇编语言可以看到，实际上底层调用的是 makemap 函数，主要做的工作就是初始化 hmap 结构体的各种字段，例如计算 B 的大小，设置哈希种子 hash0 等等。
func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap { // 省略各种条件检查... // 找到一个 B，使得 map 的装载因子在正常范围内 B := uint8(0) for ; overLoadFactor(hint, B); B++ { } // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果长度比较大，分配内存会花费长一点 buckets := bucket var extra *mapextra if B != 0 { var nextOverflow *bmap buckets, nextOverflow = makeBucketArray(t, B) if nextOverflow != nil { extra = new(mapextra) extra.nextOverflow = nextOverflow } } // 初始化 hamp if h == nil { h = (*hmap)(newobject(t.hmap)) } h.count = 0 h.B = B h.extra = extra h.flags = 0 h.hash0 = fastrand() h.buckets = buckets h.oldbuckets = nil h.nevacuate = 0 h.noverflow = 0 return h } 注意，这个函数返回的结果：*hmap，它是一个指针，而我们之前讲过的 makeslice 函数返回的是 Slice 结构体：
func makeslice(et *_type, len, cap int) slice 回顾一下 slice 的结构体定义：
// runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 len int // 长度 cap int // 容量 } 结构体内部包含底层的数据指针。
makemap 和 makeslice 的区别，带来一个不同点：当 map 和 slice 作为函数参数时，在函数参数内部对 map 的操作会影响 map 自身；而对 slice 却不会（之前讲 slice 的文章里有讲过）。
主要原因：一个是指针（*hmap），一个是结构体（slice）。Go 语言中的函数传参都是值传递，在函数内部，参数会被 copy 到本地。*hmap指针 copy 完之后，仍然指向同一个 map，因此函数内部对 map 的操作会影响实参。而 slice 被 copy 后，会成为一个新的 slice，对它进行的操作不会影响到实参。
哈希函数 map 的一个关键点在于，哈希函数的选择。在程序启动时，会检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。这是在函数 alginit() 中完成，位于路径：src/runtime/alg.go 下。
hash 函数，有加密型和非加密型。 加密型的一般用于加密数据、数字摘要等，典型代表就是 md5、sha1、sha256、aes256 这种； 非加密型的一般就是查找。在 map 的应用场景中，用的是查找。 选择 hash 函数主要考察的是两点：性能、碰撞概率。
之前我们讲过，表示类型的结构体：
type _type struct { size uintptr ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg gcdata *byte str nameOff ptrToThis typeOff } 其中 alg 字段就和哈希相关，它是指向如下结构体的指针：
// src/runtime/alg.go type typeAlg struct { // (ptr to object, seed) -> hash hash func(unsafe.Pointer, uintptr) uintptr // (ptr to object A, ptr to object B) -> ==? equal func(unsafe.Pointer, unsafe.Pointer) bool } typeAlg 包含两个函数，hash 函数计算类型的哈希值，而 equal 函数则计算两个类型是否“哈希相等”。
对于 string 类型，它的 hash、equal 函数如下：
func strhash(a unsafe.Pointer, h uintptr) uintptr { x := (*stringStruct)(a) return memhash(x.str, h, uintptr(x.len)) } func strequal(p, q unsafe.Pointer) bool { return *(*string)(p) == *(*string)(q) } 根据 key 的类型，_type 结构体的 alg 字段会被设置对应类型的 hash 和 equal 函数。
key 定位过程 key 经过哈希计算后得到哈希值，共 64 个 bit 位（64位机，32位机就不讨论了，现在主流都是64位机），计算它到底要落在哪个桶时，只会用到最后 B 个 bit 位。还记得前面提到过的 B 吗？如果 B = 5，那么桶的数量，也就是 buckets 数组的长度是 2^5 = 32。
例如，现在有一个 key 经过哈希函数计算后，得到的哈希结果是：
10010111 | 000011110110110010001111001010100010010110010101010 │ 01010 用最后的 5 个 bit 位，也就是 01010，值为 10，也就是 10 号桶。这个操作实际上就是取余操作，但是取余开销太大，所以代码实现上用的位操作代替。
再用哈希值的高 8 位，找到此 key 在 bucket 中的位置，这是在寻找已有的 key。最开始桶内还没有 key，新加入的 key 会找到第一个空位，放入。
buckets 编号就是桶编号，当两个不同的 key 落在同一个桶中，也就是发生了哈希冲突。冲突的解决手段是用链表法：在 bucket 中，从前往后找到第一个空位。这样，在查找某个 key 时，先找到对应的桶，再去遍历 bucket 中的 key。
这里参考曹大 github 博客里的一张图，原图是 ascii 图，geek 味十足，可以从参考资料找到曹大的博客，推荐大家去看看。
上图中，假定 B = 5，所以 bucket 总数就是 2^5 = 32。首先计算出待查找 key 的哈希，使用低 5 位 00110，找到对应的 6 号 bucket，使用高 8 位 10010111，对应十进制 151，在 6 号 bucket 中寻找 tophash 值（HOB hash）为 151 的 key，找到了 2 号槽位，这样整个查找过程就结束了。
如果在 bucket 中没找到，并且 overflow 不为空，还要继续去 overflow bucket 中寻找，直到找到或是所有的 key 槽位都找遍了，包括所有的 overflow bucket。
我们来看下源码吧，哈哈！通过汇编语言可以看到，查找某个 key 的底层函数是 mapacess 系列函数，函数的作用类似，区别在下一节会讲到。这里我们直接看 mapacess1 函数：
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // …… // 如果 h 什么都没有，返回零值 if h == nil || h.count == 0 { return unsafe.Pointer(&amp;zeroVal[0]) } // 写和读冲突 if h.flags&amp;hashWriting != 0 { throw("concurrent map read and map write") } // 不同类型 key 使用的 hash 算法在编译期确定 alg := t.key.alg // 计算哈希值，并且加入 hash0 引入随机性 hash := alg.hash(key, uintptr(h.hash0)) // 比如 B=5，那 m 就是31，二进制是全 1 // 求 bucket num 时，将 hash 与 m 相与， // 达到 bucket num 由 hash 的低 8 位决定的效果 m := uintptr(1)&lt;&lt;h.B - 1 // b 就是 bucket 的地址 b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize))) // oldbuckets 不为 nil，说明发生了扩容 if c := h.oldbuckets; c != nil { // 如果不是同 size 扩容（看后面扩容的内容） // 对应条件 1 的解决方案 if !h.sameSizeGrow() { // 新 bucket 数量是老的 2 倍 m >>= 1 } // 求出 key 在老的 map 中的 bucket 位置 oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize))) // 如果 oldb 没有搬迁到新的 bucket // 那就在老的 bucket 中寻找 if !evacuated(oldb) { b = oldb } } // 计算出高 8 位的 hash // 相当于右移 56 位，只取高8位 top := uint8(hash >> (sys.PtrSize*8 - 8)) // 增加一个 minTopHash if top &lt; minTopHash { top += minTopHash } for { // 遍历 8 个 bucket for i := uintptr(0); i &lt; bucketCnt; i++ { // tophash 不匹配，继续 if b.tophash[i] != top { continue } // tophash 匹配，定位到 key 的位置 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // key 是指针 if t.indirectkey { // 解引用 k = *((*unsafe.Pointer)(k)) } // 如果 key 相等 if alg.equal(key, k) { // 定位到 value 的位置 v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) // value 解引用 if t.indirectvalue { v = *((*unsafe.Pointer)(v)) } return v } } // bucket 找完（还没找到），继续到 overflow bucket 里找 b = b.overflow(t) // overflow bucket 也找完了，说明没有目标 key // 返回零值 if b == nil { return unsafe.Pointer(&amp;zeroVal[0]) } } } 函数返回 h[key] 的指针，如果 h 中没有此 key，那就会返回一个 key 相应类型的零值，不会返回 nil。
代码整体比较直接，没什么难懂的地方。跟着上面的注释一步步理解就好了。
这里，说一下定位 key 和 value 的方法以及整个循环的写法。
// key 定位公式 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // value 定位公式 v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) b 是 bmap 的地址，这里 bmap 还是源码里定义的结构体，只包含一个 tophash 数组，经编译器扩充之后的结构体才包含 key，value，overflow 这些字段。dataOffset 是 key 相对于 bmap 起始地址的偏移：
dataOffset = unsafe.Offsetof(struct { b bmap v int64 }{}.v) 因此 bucket 里 key 的起始地址就是 unsafe.Pointer(b)+dataOffset。第 i 个 key 的地址就要在此基础上跨过 i 个 key 的大小；而我们又知道，value 的地址是在所有 key 之后，因此第 i 个 value 的地址还需要加上所有 key 的偏移。理解了这些，上面 key 和 value 的定位公式就很好理解了。
再说整个大循环的写法，最外层是一个无限循环，通过
b = b.overflow(t) 遍历所有的 bucket，这相当于是一个 bucket 链表。
当定位到一个具体的 bucket 时，里层循环就是遍历这个 bucket 里所有的 cell，或者说所有的槽位，也就是 bucketCnt=8 个槽位。整个循环过程：
再说一下 minTopHash，当一个 cell 的 tophash 值小于 minTopHash 时，标志这个 cell 的迁移状态。因为这个状态值是放在 tophash 数组里，为了和正常的哈希值区分开，会给 key 计算出来的哈希值一个增量：minTopHash。这样就能区分正常的 top hash 值和表示状态的哈希值。
下面的这几种状态就表征了 bucket 的情况：
// 空的 cell，也是初始时 bucket 的状态 empty = 0 // 空的 cell，表示 cell 已经被迁移到新的 bucket evacuatedEmpty = 1 // key,value 已经搬迁完毕，但是 key 都在新 bucket 前半部分， // 后面扩容部分会再讲到。 evacuatedX = 2 // 同上，key 在后半部分 evacuatedY = 3 // tophash 的最小正常值 minTopHash = 4 源码里判断这个 bucket 是否已经搬迁完毕，用到的函数：
func evacuated(b *bmap) bool { h := b.tophash[0] return h > empty &amp;&amp; h &lt; minTopHash } 只取了 tophash 数组的第一个值，判断它是否在 0-4 之间。对比上面的常量，当 top hash 是 evacuatedEmpty、evacuatedX、evacuatedY 这三个值之一，说明此 bucket 中的 key 全部被搬迁到了新 bucket。
map 的两种 get 操作 Go 语言中读取 map 有两种语法：带 comma 和 不带 comma。当要查询的 key 不在 map 里，带 comma 的用法会返回一个 bool 型变量提示 key 是否在 map 中；而不带 comma 的语句则会返回一个 value 类型的零值。如果 value 是 int 型就会返回 0，如果 value 是 string 类型，就会返回空字符串。
package main import "fmt" func main() { ageMap := make(map[string]int) ageMap["qcrao"] = 18 // 不带 comma 用法 age1 := ageMap["stefno"] fmt.Println(age1) // 带 comma 用法 age2, ok := ageMap["stefno"] fmt.Println(age2, ok) } 运行结果：
00 false 以前一直觉得好神奇，怎么实现的？这其实是编译器在背后做的工作：分析代码后，将两种语法对应到底层两个不同的函数。
package main import "fmt" func main() { ageMap := make(map[string]int) ageMap["qcrao"] = 18 // 不带 comma 用法 age1 := ageMap["stefno"] fmt.Println(age1) // 带 comma 用法 age2, ok := ageMap["stefno"] fmt.Println(age2, ok) } 源码里，函数命名不拘小节，直接带上后缀 1，2，完全不理会《代码大全》里的那一套命名的做法。从上面两个函数的声明也可以看出差别了，mapaccess2 函数返回值多了一个 bool 型变量，两者的代码也是完全一样的，只是在返回值后面多加了一个 false 或者 true。
另外，根据 key 的不同类型，编译器还会将查找、插入、删除的函数用更具体的函数替换，以优化效率：
key 类型 查找 uint32 mapaccess1_fast32(t *maptype, h *hmap, key uint32) unsafe.Pointer uint32 mapaccess2_fast32(t *maptype, h *hmap, key uint32) (unsafe.Pointer, bool) uint64 mapaccess1_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer uint64 mapaccess2_fast64(t *maptype, h *hmap, key uint64) (unsafe.Pointer, bool) string mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer string mapaccess2_faststr(t *maptype, h *hmap, ky string) (unsafe.Pointer, bool) 这些函数的参数类型直接是具体的 uint32、unt64、string，在函数内部由于提前知晓了 key 的类型，所以内存布局是很清楚的，因此能节省很多操作，提高效率。
上面这些函数都是在文件 src/runtime/hashmap_fast.go 里。
如何进行扩容 使用哈希表的目的就是要快速查找到目标 key，然而，随着向 map 中添加的 key 越来越多，key 发生碰撞的概率也越来越大。bucket 中的 8 个 cell 会被逐渐塞满，查找、插入、删除 key 的效率也会越来越低。最理想的情况是一个 bucket 只装一个 key，这样，就能达到 O(1) 的效率，但这样空间消耗太大，用空间换时间的代价太高。
Go 语言采用一个 bucket 里装载 8 个 key，定位到某个 bucket 后，还需要再定位到具体的 key，这实际上又用了时间换空间。
当然，这样做，要有一个度，不然所有的 key 都落在了同一个 bucket 里，直接退化成了链表，各种操作的效率直接降为 O(n)，是不行的。
因此，需要有一个指标来衡量前面描述的情况，这就是装载因子。Go 源码里这样定义 装载因子：
loadFactor := count / (2^B) count 就是 map 的元素个数，2^B 表示 bucket 数量。
再来说触发 map 扩容的时机：在向 map 插入新 key 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容：
装载因子超过阈值，源码里定义的阈值是 6.5。 overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B >= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。 通过汇编语言可以找到赋值操作对应源码中的函数是 mapassign，对应扩容条件的源码如下：
// src/runtime/hashmap.go/mapassign // 触发扩容时机 if !h.growing() &amp;&amp; (overLoadFactor(int64(h.count), h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) } // 装载因子超过 6.5 func overLoadFactor(count int64, B uint8) bool { return count >= bucketCnt &amp;&amp; float32(count) >= loadFactor*float32((uint64(1)&lt;&lt;B)) } // overflow buckets 太多 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { if B &lt; 16 { return noverflow >= uint16(1)&lt;&lt;B } return noverflow >= 1&lt;&lt;15 } 解释一下：
第 1 点：我们知道，每个 bucket 有 8 个空位，在没有溢出，且所有的桶都装满了的情况下，装载因子算出来的结果是 8。因此当装载因子超过 6.5 时，表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。
第 2 点：是对第 1 点的补充。就是说在装载因子比较小的情况下，这时候 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是 bucket 数量多（真实分配的 bucket 数量多，包括大量的 overflow bucket）。
不难想像造成这种情况的原因：不停地插入、删除元素。先插入很多元素，导致创建了很多 bucket，但是装载因子达不到第 1 点的临界值，未触发扩容来缓解这种情况。之后，删除元素降低元素总数量，再插入很多元素，导致创建很多的 overflow bucket，但就是不会触犯第 1 点的规定，你能拿我怎么办？overflow bucket 数量太多，导致 key 会很分散，查找插入效率低得吓人，因此出台第 2 点规定。这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。
对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。
对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。
对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。
对于条件 2 的解决方案，曹大的博客里还提出了一个极端的情况：如果插入 map 的 key 哈希都一样，就会落到同一个 bucket 里，超过 8 个就会产生 overflow bucket，结果也会造成 overflow bucket 数过多。移动元素其实解决不了问题，因为这时整个哈希表已经退化成了一个链表，操作效率变成了 O(n)。
再来看一下扩容具体是怎么做的。由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。
上面说的 hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。
我们先看 hashGrow() 函数所做的工作，再来看具体的搬迁 buckets 是如何进行的。
func hashGrow(t *maptype, h *hmap) { // B+1 相当于是原来 2 倍的空间 bigger := uint8(1) // 对应条件 2 if !overLoadFactor(int64(h.count), h.B) { // 进行等量的内存扩容，所以 B 不变 bigger = 0 h.flags |= sameSizeGrow } // 将老 buckets 挂到 buckets 上 oldbuckets := h.buckets // 申请新的 buckets 空间 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger) flags := h.flags &amp;^ (iterator | oldIterator) if h.flags&amp;iterator != 0 { flags |= oldIterator } // 提交 grow 的动作 h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets // 搬迁进度为 0 h.nevacuate = 0 // overflow buckets 数为 0 h.noverflow = 0 // …… } 主要是申请到了新的 buckets 空间，把相关的标志位都进行了处理：例如标志 nevacuate 被置为 0， 表示当前搬迁进度为 0。
值得一说的是对 h.flags 的处理：
flags := h.flags &amp;^ (iterator | oldIterator) if h.flags&amp;iterator != 0 { flags |= oldIterator } 这里得先说下运算符：&amp;^。这叫按位置 0运算符。例如：
x = 01010011 y = 01010100 z = x &amp;^ y = 00000011 如果 y bit 位为 1，那么结果 z 对应 bit 位就为 0，否则 z 对应 bit 位就和 x 对应 bit 位的值相同。
所以上面那段对 flags 一顿操作的代码的意思是：先把 h.flags 中 iterator 和 oldIterator 对应位清 0，然后如果发现 iterator 位为 1，那就把它转接到 oldIterator 位，使得 oldIterator 标志位变成 1。潜台词就是：buckets 现在挂到了 oldBuckets 名下了，对应的标志位也转接过去吧。
几个标志位如下：
// 可能有迭代器使用 buckets iterator = 1 // 可能有迭代器使用 oldbuckets oldIterator = 2 // 有协程正在向 map 中写入 key hashWriting = 4 // 等量扩容（对应条件 2） sameSizeGrow = 8 再来看看真正执行搬迁工作的 growWork() 函数。
func growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket&amp;h.oldbucketmask()) // 再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) } } h.growing() 函数非常简单：
func (h *hmap) growing() bool { return h.oldbuckets != nil } 如果 oldbuckets 不为空，说明还没有搬迁完毕，还得继续搬。
bucket&amp;h.oldbucketmask() 这行代码，如源码注释里说的，是为了确认搬迁的 bucket 是我们正在使用的 bucket。oldbucketmask() 函数返回扩容前的 map 的 bucketmask。
所谓的 bucketmask，作用就是将 key 计算出来的哈希值与 bucketmask 相与，得到的结果就是 key 应该落入的桶。比如 B = 5，那么 bucketmask 的低 5 位是 11111，其余位是 0，hash 值与其相与的意思是，只有 hash 值的低 5 位决策 key 到底落入哪个 bucket。
接下来，我们集中所有的精力在搬迁的关键函数 evacuate。源码贴在下面，不要紧张，我会加上大面积的注释，通过注释绝对是能看懂的。之后，我会再对搬迁过程作详细说明。
源码如下：
func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位老的 bucket 地址 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // 结果是 2^B，如 B = 5，结果为32 newbit := h.noldbuckets() // key 的哈希函数 alg := t.key.alg // 如果 b 没有被搬迁过 if !evacuated(b) { var ( // 表示bucket 移动的目标地址 x, y *bmap // 指向 x,y 中的 key/val xi, yi int // 指向 x，y 中的 key xk, yk unsafe.Pointer // 指向 x，y 中的 value xv, yv unsafe.Pointer ) // 默认是等 size 扩容，前后 bucket 序号不变 // 使用 x 来进行搬迁 x = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) xi = 0 xk = add(unsafe.Pointer(x), dataOffset) xv = add(xk, bucketCnt*uintptr(t.keysize))、 // 如果不是等 size 扩容，前后 bucket 序号有变 // 使用 y 来进行搬迁 if !h.sameSizeGrow() { // y 代表的 bucket 序号增加了 2^B y = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) yi = 0 yk = add(unsafe.Pointer(y), dataOffset) yv = add(yk, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets // b 是老的 bucket 地址 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) v := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell for i := 0; i &lt; bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) { // 当前 cell 的 top hash 值 top := b.tophash[i] // 如果 cell 为空，即没有 key if top == empty { // 那就标志它被"搬迁"过 b.tophash[i] = evacuatedEmpty // 继续下个 cell continue } // 正常不会出现这种情况 // 未被搬迁的 cell 只可能是 empty 或是 // 正常的 top hash（大于 minTopHash） if top &lt; minTopHash { throw("bad map state") } k2 := k // 如果 key 是指针，则解引用 if t.indirectkey { k2 = *((*unsafe.Pointer)(k2)) } // 默认使用 X，等量扩容 useX := true // 如果不是等量扩容 if !h.sameSizeGrow() { // 计算 hash 值，和 key 第一次写入时一样 hash := alg.hash(k2, uintptr(h.hash0)) // 如果有协程正在遍历 map if h.flags&amp;iterator != 0 { // 如果出现 相同的 key 值，算出来的 hash 值不同 if !t.reflexivekey &amp;&amp; !alg.equal(k2, k2) { // 只有在 float 变量的 NaN() 情况下会出现 if top&amp;1 != 0 { // 第 B 位置 1 hash |= newbit } else { // 第 B 位置 0 hash &amp;^= newbit } // 取高 8 位作为 top hash 值 top = uint8(hash >> (sys.PtrSize*8 - 8)) if top &lt; minTopHash { top += minTopHash } } } // 取决于新哈希值的 oldB+1 位是 0 还是 1 // 详细看后面的文章 useX = hash&amp;newbit == 0 } // 如果 key 搬到 X 部分 if useX { // 标志老的 cell 的 top hash 值，表示搬移到 X 部分 b.tophash[i] = evacuatedX // 如果 xi 等于 8，说明要溢出了 if xi == bucketCnt { // 新建一个 bucket newx := h.newoverflow(t, x) x = newx // xi 从 0 开始计数 xi = 0 // xk 表示 key 要移动到的位置 xk = add(unsafe.Pointer(x), dataOffset) // xv 表示 value 要移动到的位置 xv = add(xk, bucketCnt*uintptr(t.keysize)) } // 设置 top hash 值 x.tophash[xi] = top // key 是指针 if t.indirectkey { // 将原 key（是指针）复制到新位置 *(*unsafe.Pointer)(xk) = k2 // copy pointer } else { // 将原 key（是值）复制到新位置 typedmemmove(t.key, xk, k) // copy value } // value 是指针，操作同 key if t.indirectvalue { *(*unsafe.Pointer)(xv) = *(*unsafe.Pointer)(v) } else { typedmemmove(t.elem, xv, v) } // 定位到下一个 cell xi++ xk = add(xk, uintptr(t.keysize)) xv = add(xv, uintptr(t.valuesize)) } else { // key 搬到 Y 部分，操作同 X 部分 // …… // 省略了这部分，操作和 X 部分相同 } } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc if h.flags&amp;oldIterator == 0 { b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 if t.bucket.kind&amp;kindNoPointers == 0 { memclrHasPointers(add(unsafe.Pointer(b), dataOffset), uintptr(t.bucketsize)-dataOffset) } else { memclrNoHeapPointers(add(unsafe.Pointer(b), dataOffset), uintptr(t.bucketsize)-dataOffset) } } } // 更新搬迁进度 // 如果此次搬迁的 bucket 等于当前进度 if oldbucket == h.nevacuate { // 进度加 1 h.nevacuate = oldbucket + 1 // Experiments suggest that 1024 is overkill by at least an order of magnitude. // Put it in there as a safeguard anyway, to ensure O(1) behavior. // 尝试往后看 1024 个 bucket stop := h.nevacuate + 1024 if stop > newbit { stop = newbit } // 寻找没有搬迁的 bucket for h.nevacuate != stop &amp;&amp; bucketEvacuated(t, h, h.nevacuate) { h.nevacuate++ } // 现在 h.nevacuate 之前的 bucket 都被搬迁完毕 // 所有的 buckets 搬迁完毕 if h.nevacuate == newbit { // 清除老的 buckets h.oldbuckets = nil // 清除老的 overflow bucket // 回忆一下：[0] 表示当前 overflow bucket // [1] 表示 old overflow bucket if h.extra != nil { h.extra.overflow[1] = nil } // 清除正在扩容的标志位 h.flags &amp;^= sameSizeGrow } } } evacuate 函数的代码注释非常清晰，对着代码和注释是很容易看懂整个的搬迁过程的，耐心点。
搬迁的目的就是将老的 buckets 搬迁到新的 buckets。而通过前面的说明我们知道，应对条件 1，新的 buckets 数量是之前的一倍，应对条件 2，新的 buckets 数量和之前相等。
对于条件 1，从老的 buckets 搬迁到新的 buckets，由于 bucktes 数量不变，因此可以按序号来搬，比如原来在 0 号 bucktes，到新的地方后，仍然放在 0 号 buckets。
对于条件 2，就没这么简单了。要重新计算 key 的哈希，才能决定它到底落在哪个 bucket。例如，原来 B = 5，计算出 key 的哈希后，只用看它的低 5 位，就能决定它落在哪个 bucket。扩容后，B 变成了 6，因此需要多看一位，它的低 6 位决定 key 落在哪个 bucket。这称为 rehash。
因此，某个 key 在搬迁前后 bucket 序号可能和原来相等，也可能是相比原来加上 2^B（原来的 B 值），取决于 hash 值 第 6 bit 位是 0 还是 1。
理解了上面 bucket 序号的变化，我们就可以回答另一个问题了：为什么遍历 map 是无序的？
map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。
当然，如果我就一个 hard code 的 map，我也不会向 map 进行插入删除的操作，按理说每次遍历这样的 map 都会返回一个固定顺序的 key/value 序列吧。的确是这样，但是 Go 杜绝了这种做法，因为这样会给新手程序员带来误解，以为这是一定会发生的事情，在某些情况下，可能会酿成大错。
当然，Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key/value 对了。
多说一句，“迭代 map 的结果是无序的”这个特性是从 go 1.0 开始加入的。
再明确一个问题：如果扩容后，B 增加了 1，意味着 buckets 总数是原来的 2 倍，原来 1 号的桶“裂变”到两个桶。
例如，原始 B = 2，1号 bucket 中有 2 个 key 的哈希值低 3 位分别为：010，110。由于原来 B = 2，所以低 2 位 10 决定它们落在 2 号桶，现在 B 变成 3，所以 010、110 分别落入 2、6 号桶。
理解了这个，后面讲 map 迭代的时候会用到。
再来讲搬迁函数中的几个关键点：
evacuate 函数每次只完成一个 bucket 的搬迁工作，因此要遍历完此 bucket 的所有的 cell，将有值的 cell copy 到新的地方。bucket 还会链接 overflow bucket，它们同样需要搬迁。因此会有 2 层循环，外层遍历 bucket 和 overflow bucket，内层遍历 bucket 的所有 cell。这样的循环在 map 的源码里到处都是，要理解透了。
源码里提到 X, Y part，其实就是我们说的如果是扩容到原来的 2 倍，桶的数量是原来的 2 倍，前一半桶被称为 X part，后一半桶被称为 Y part。一个 bucket 中的 key 可能会分裂落到 2 个桶，一个位于 X part，一个位于 Y part。所以在搬迁一个 cell 之前，需要知道这个 cell 中的 key 是落到哪个 Part。很简单，重新计算 cell 中 key 的 hash，并向前“多看”一位，决定落入哪个 Part，这个前面也说得很详细了。
有一个特殊情况是：有一种 key，每次对它计算 hash，得到的结果都不一样。这个 key 就是 math.NaN() 的结果，它的含义是 not a number，类型是 float64。当它作为 map 的 key，在搬迁的时候，会遇到一个问题：再次计算它的哈希值和它当初插入 map 时的计算出来的哈希值不一样！
你可能想到了，这样带来的一个后果是，这个 key 是永远不会被 Get 操作获取的！当我使用 m[math.NaN()] 语句的时候，是查不出来结果的。这个 key 只有在遍历整个 map 的时候，才有机会现身。所以，可以向一个 map 插入任意数量的 math.NaN() 作为 key。
当搬迁碰到 math.NaN() 的 key 时，只通过 tophash 的最低位决定分配到 X part 还是 Y part（如果扩容后是原来 buckets 数量的 2 倍）。如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。
这是通过 tophash 值与新算出来的哈希值进行运算得到的：
if top&amp;1 != 0 { // top hash 最低位为 1 // 新算出来的 hash 值的 B 位置 1 hash |= newbit } else { // 新算出来的 hash 值的 B 位置 0 hash &amp;^= newbit } // hash 值的 B 位为 0，则搬迁到 x part // 当 B = 5时，newbit = 32，二进制低 6 位为 10 0000 useX = hash&amp;newbit == 0 其实这样的 key 我随便搬迁到哪个 bucket 都行，当然，还是要搬迁到上面裂变那张图中的两个 bucket 中去。但这样做是有好处的，在后面讲 map 迭代的时候会再详细解释，暂时知道是这样分配的就行。
确定了要搬迁到的目标 bucket 后，搬迁操作就比较好进行了。将源 key/value 值 copy 到目的地相应的位置。
设置 key 在原始 buckets 的 tophash 为 evacuatedX 或是 evacuatedY，表示已经搬迁到了新 map 的 x part 或是 y part。新 map 的 tophash 则正常取 key 哈希值的高 8 位。
下面通过图来宏观地看一下扩容前后的变化。
扩容前，B = 2，共有 4 个 buckets，lowbits 表示 hash 值的低位。假设我们不关注其他 buckets 情况，专注在 2 号 bucket。并且假设 overflow 太多，触发了等量扩容（对应于前面的条件 2）。
扩容完成后，overflow bucket 消失了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。
假设触发了 2 倍的扩容，那么扩容完成后，老 buckets 中的 key 分裂到了 2 个 新的 bucket。一个在 x part，一个在 y 的 part。依据是 hash 的 lowbits。新 map 中 0-3 称为 x part，4-7 称为 y part。
注意，上面的两张图忽略了其他 buckets 的搬迁情况，表示所有的 bucket 都搬迁完毕后的情形。实际上，我们知道，搬迁是一个“渐进”的过程，并不会一下子就全部搬迁完毕。所以在搬迁过程中，oldbuckets 指针还会指向原来老的 []bmap，并且已经搬迁完毕的 key 的 tophash 值会是一个状态值，表示 key 的搬迁去向。
map 的遍历 本来 map 的遍历过程比较简单：遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。
但是，现实并没有这么简单。还记得前面讲过的扩容过程吗？扩容过程不是一个原子的操作，它每次最多只搬运 2 个 bucket，所以如果触发了扩容操作，那么在很长时间里，map 的状态都是处于一个中间态：有些 bucket 已经搬迁到新家，而有些 bucket 还待在老地方。
因此，遍历如果发生在扩容的过程中，就会涉及到遍历新老 bucket 的过程，这是难点所在。
我先写一个简单的代码样例，假装不知道遍历过程具体调用的是什么函数：
package main import "fmt" func main() { ageMp := make(map[string]int) ageMp["qcrao"] = 18 for name, age := range ageMp { fmt.Println(name, age) } } 执行命令：
go tool compile -S main.go 得到汇编命令。这里就不逐行讲解了，可以去看之前的几篇文章，说得很详细。
关键的几行汇编代码如下：
// ...... 0x0124 00292 (test16.go:9) CALL runtime.mapiterinit(SB) // ...... 0x01fb 00507 (test16.go:9) CALL runtime.mapiternext(SB) 0x0200 00512 (test16.go:9) MOVQ ""..autotmp_4+160(SP), AX 0x0208 00520 (test16.go:9) TESTQ AX, AX 0x020b 00523 (test16.go:9) JNE 302 // ...... 这样，关于 map 迭代，底层的函数调用关系一目了然。先是调用 mapiterinit 函数初始化迭代器，然后循环调用 mapiternext 函数进行 map 迭代。
迭代器的结构体定义：
type hiter struct { // key 指针 key unsafe.Pointer // value 指针 value unsafe.Pointer // map 类型，包含如 key size 大小等 t *maptype // map header h *hmap // 初始化时指向的 bucket buckets unsafe.Pointer // 当前遍历到的 bmap bptr *bmap overflow [2]*[]*bmap // 起始遍历的 bucet 编号 startBucket uintptr // 遍历开始时 cell 的编号（每个 bucket 中有 8 个 cell） offset uint8 // 是否从头遍历了 wrapped bool // B 的大小 B uint8 // 指示当前 cell 序号 i uint8 // 指向当前的 bucket bucket uintptr // 因为扩容，需要检查的 bucket checkBucket uintptr } mapiterinit 就是对 hiter 结构体里的字段进行初始化赋值操作。
前面已经提到过，即使是对一个写死的 map 进行遍历，每次出来的结果也是无序的。下面我们就可以近距离地观察他们的实现了。
// 生成随机数 r r := uintptr(fastrand()) if h.B > 31-bucketCntBits { r += uintptr(fastrand()) &lt;&lt; 31 } // 从哪个 bucket 开始遍历 it.startBucket = r &amp; (uintptr(1)&lt;&lt;h.B - 1) // 从 bucket 的哪个 cell 开始遍历 it.offset = uint8(r >> h.B &amp; (bucketCnt - 1)) 例如，B = 2，那 uintptr(1)&lt;&lt;h.B - 1 结果就是 3，低 8 位为 0000 0011，将 r 与之相与，就可以得到一个 0~3 的 bucket 序号；bucketCnt - 1 等于 7，低 8 位为 0000 0111，将 r 右移 2 位后，与 7 相与，就可以得到一个 0~7 号的 cell。
于是，在 mapiternext 函数中就会从 it.startBucket 的 it.offset 号的 cell 开始遍历，取出其中的 key 和 value，直到又回到起点 bucket，完成遍历过程。
源码部分比较好看懂，尤其是理解了前面注释的几段代码后，再看这部分代码就没什么压力了。所以，接下来，我将通过图形化的方式讲解整个遍历过程，希望能够清晰易懂。
假设我们有下图所示的一个 map，起始时 B = 1，有两个 bucket，后来触发了扩容（这里不要深究扩容条件，只是一个设定），B 变成 2。并且， 1 号 bucket 中的内容搬迁到了新的 bucket，1 号裂变成 1 号和 3 号；0 号 bucket 暂未搬迁。老的 bucket 挂在在 *oldbuckets 指针上面，新的 bucket 则挂在 *buckets 指针上面。
这时，我们对此 map 进行遍历。假设经过初始化后，startBucket = 3，offset = 2。于是，遍历的起点将是 3 号 bucket 的 2 号 cell，下面这张图就是开始遍历时的状态：
标红的表示起始位置，bucket 遍历顺序为：3 -> 0 -> 1 -> 2。
因为 3 号 bucket 对应老的 1 号 bucket，因此先检查老 1 号 bucket 是否已经被搬迁过。判断方法就是：
func evacuated(b *bmap) bool { h := b.tophash[0] return h > empty &amp;&amp; h &lt; minTopHash } 如果 b.tophash[0] 的值在标志值范围内，即在 (0,4) 区间里，说明已经被搬迁过了。
empty = 0 evacuatedEmpty = 1 evacuatedX = 2 evacuatedY = 3 minTopHash = 4 在本例中，老 1 号 bucket 已经被搬迁过了。所以它的 tophash[0] 值在 (0,4) 范围内，因此只用遍历新的 3 号 bucket。
依次遍历 3 号 bucket 的 cell，这时候会找到第一个非空的 key：元素 e。到这里，mapiternext 函数返回，这时我们的遍历结果仅有一个元素：
由于返回的 key 不为空，所以会继续调用 mapiternext 函数。
继续从上次遍历到的地方往后遍历，从新 3 号 overflow bucket 中找到了元素 f 和 元素 g。
遍历结果集也因此壮大：
新 3 号 bucket 遍历完之后，回到了新 0 号 bucket。0 号 bucket 对应老的 0 号 bucket，经检查，老 0 号 bucket 并未搬迁，因此对新 0 号 bucket 的遍历就改为遍历老 0 号 bucket。那是不是把老 0 号 bucket 中的所有 key 都取出来呢？
并没有这么简单，回忆一下，老 0 号 bucket 在搬迁后将裂变成 2 个 bucket：新 0 号、新 2 号。而我们此时正在遍历的只是新 0 号 bucket（注意，遍历都是遍历的 *bucket 指针，也就是所谓的新 buckets）。所以，我们只会取出老 0 号 bucket 中那些在裂变之后，分配到新 0 号 bucket 中的那些 key。
因此，lowbits == 00 的将进入遍历结果集：
和之前的流程一样，继续遍历新 1 号 bucket，发现老 1 号 bucket 已经搬迁，只用遍历新 1 号 bucket 中现有的元素就可以了。结果集变成：
继续遍历新 2 号 bucket，它来自老 0 号 bucket，因此需要在老 0 号 bucket 中那些会裂变到新 2 号 bucket 中的 key，也就是 lowbit == 10 的那些 key。
这样，遍历结果集变成：
最后，继续遍历到新 3 号 bucket 时，发现所有的 bucket 都已经遍历完毕，整个迭代过程执行完毕。
顺便说一下，如果碰到 key 是 math.NaN() 这种的，处理方式类似。核心还是要看它被分裂后具体落入哪个 bucket。只不过只用看它 top hash 的最低位。如果 top hash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。据此决定是否取出 key，放到遍历结果集里。
map 遍历的核心在于理解 2 倍扩容时，老 bucket 会分裂到 2 个新 bucket 中去。而遍历操作，会按照新 bucket 的序号顺序进行，碰到老 bucket 未搬迁的情况时，要在老 bucket 中找到将来要搬迁到新 bucket 来的 key。
map 的赋值 通过汇编语言可以看到，向 map 中插入或者修改 key，最终调用的是 mapassign 函数。
实际上插入或修改 key 的语法是一样的，只不过前者操作的 key 在 map 中不存在，而后者操作的 key 存在 map 中。
mapassign 有一个系列的函数，根据 key 类型的不同，编译器会将其优化为相应的“快速函数”。
key 类型 插入 uint32 mapassign_fast32(t *maptype, h *hmap, key uint32) unsafe.Pointer uint64 mapassign_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer string mapassign_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer 我们只用研究最一般的赋值函数 mapassign。
整体来看，流程非常得简单：对 key 计算 hash 值，根据 hash 值按照之前的流程，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。
源码大体和之前讲的类似，核心还是一个双层循环，外层遍历 bucket 和它的 overflow bucket，内层遍历整个 bucket 的各个 cell。限于篇幅，这部分代码的注释我也不展示了，有兴趣的可以去看，保证理解了这篇文章内容后，能够看懂。
我这里会针对这个过程提几点重要的。
函数首先会检查 map 的标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行“写”操作，进而导致程序 panic。这也说明了 map 对协程是不安全的。
通过前文我们知道扩容是渐进式的，如果 map 处在扩容的过程中，那么当 key 定位到了某个 bucket 后，需要确保这个 bucket 对应的老 bucket 完成了迁移过程。即老 bucket 里的 key 都要迁移到新的 bucket 中来（分裂到 2 个新 bucket），才能在新的 bucket 中进行插入或者更新的操作。
上面说的操作是在函数靠前的位置进行的，只有进行完了这个搬迁操作后，我们才能放心地在新 bucket 里定位 key 要安置的地址，再进行之后的操作。
现在到了定位 key 应该放置的位置了，所谓找准自己的位置很重要。准备两个指针，一个（inserti）指向 key 的 hash 值在 tophash 数组所处的位置，另一个(insertk)指向 cell 的位置（也就是 key 最终放置的地址），当然，对应 value 的位置就很容易定位出来了。这三者实际上都是关联的，在 tophash 数组中的索引位置决定了 key 在整个 bucket 中的位置（共 8 个 key），而 value 的位置需要“跨过” 8 个 key 的长度。
在循环的过程中，inserti 和 insertk 分别指向第一个找到的空闲的 cell。如果之后在 map 没有找到 key 的存在，也就是说原来 map 中没有此 key，这意味着插入新 key。那最终 key 的安置地址就是第一次发现的“空位”（tophash 是 empty）。
如果这个 bucket 的 8 个 key 都已经放置满了，那在跳出循环后，发现 inserti 和 insertk 都是空，这时候需要在 bucket 后面挂上 overflow bucket。当然，也有可能是在 overflow bucket 后面再挂上一个 overflow bucket。这就说明，太多 key hash 到了此 bucket。
在正式安置 key 之前，还要检查 map 的状态，看它是否需要进行扩容。如果满足扩容的条件，就主动触发一次扩容操作。
这之后，整个之前的查找定位 key 的过程，还得再重新走一次。因为扩容之后，key 的分布都发生了变化。
最后，会更新 map 相关的值，如果是插入新 key，map 的元素数量字段 count 值会加 1；在函数之初设置的 hashWriting 写标志出会清零。
另外，有一个重要的点要说一下。前面说的找到 key 的位置，进行赋值操作，实际上并不准确。我们看 mapassign 函数的原型就知道，函数并没有传入 value 值，所以赋值操作是什么时候执行的呢？
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer 答案还得从汇编语言中寻找。我直接揭晓答案，有兴趣可以私下去研究一下。mapassign 函数返回的指针就是指向的 key 所对应的 value 值位置，有了地址，就很好操作赋值了。
map 的删除 写操作底层的执行函数是 mapdelete：
func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) 根据 key 类型的不同，删除操作会被优化成更具体的函数：
key 类型 删除 uint32 mapdelete_fast32(t *maptype, h *hmap, key uint32) uint64 mapdelete_fast64(t *maptype, h *hmap, key uint64) string mapdelete_faststr(t *maptype, h *hmap, ky string) 当然，我们只关心 mapdelete 函数。它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。
计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。
删除操作同样是两层循环，核心还是找到 key 的具体位置。寻找过程都是类似的，在 bucket 中挨个 cell 寻找。
找到对应位置后，对 key 或者 value 进行“清零”操作：
// 对 key 清零 if t.indirectkey { *(*unsafe.Pointer)(k) = nil } else { typedmemclr(t.key, k) } // 对 value 清零 if t.indirectvalue { *(*unsafe.Pointer)(v) = nil } else { typedmemclr(t.elem, v) } 最后，将 count 值减 1，将对应位置的 tophash 值置成 Empty。
这块源码同样比较简单，感兴起直接去看代码。
map 进阶 可以边遍历边删除吗 map 并不是一个线程安全的数据结构。同时读写一个 map 是未定义的行为，如果被检测到，会直接 panic。
一般而言，这可以通过读写锁来解决：sync.RWMutex。
读之前调用 RLock() 函数，读完之后调用 RUnlock() 函数解锁；写之前调用 Lock() 函数，写完之后，调用 Unlock() 解锁。
另外，sync.Map 是线程安全的 map，也可以使用。它的实现原理，这次先不说了。
key 可以是 float 型吗？ 从语法上看，是可以的。Go 语言中只要是可比较的类型都可以作为 key。除开 slice，map，functions 这几种类型，其他类型都是 OK 的。具体包括：布尔值、数字、字符串、指针、通道、接口类型、结构体、只包含上述类型的数组。这些类型的共同特征是支持 == 和 != 操作符，k1 == k2 时，可认为 k1 和 k2 是同一个 key。如果是结构体，则需要它们的字段值都相等，才被认为是相同的 key。
顺便说一句，任何类型都可以作为 value，包括 map 类型。
来看个例子：
func main() { m := make(map[float64]int) m[1.4] = 1 m[2.4] = 2 m[math.NaN()] = 3 m[math.NaN()] = 3 for k, v := range m { fmt.Printf("[%v, %d] ", k, v) } fmt.Printf("\nk: %v, v: %d\n", math.NaN(), m[math.NaN()]) fmt.Printf("k: %v, v: %d\n", 2.400000000001, m[2.400000000001]) fmt.Printf("k: %v, v: %d\n", 2.4000000000000000000000001, m[2.4000000000000000000000001]) fmt.Println(math.NaN() == math.NaN()) } 程序的输出：
[2.4, 2] [NaN, 3] [NaN, 3] [1.4, 1] k: NaN, v: 0 k: 2.400000000001, v: 0 k: 2.4, v: 2 false 例子中定义了一个 key 类型是 float 型的 map，并向其中插入了 4 个 key：1.4， 2.4， NAN，NAN。
打印的时候也打印出了 4 个 key，如果你知道 NAN != NAN，也就不奇怪了。因为他们比较的结果不相等，自然，在 map 看来就是两个不同的 key 了。
接着，我们查询了几个 key，发现 NAN 不存在，2.400000000001 也不存在，而 2.4000000000000000000000001 却存在。
有点诡异，不是吗？
接着，我通过汇编发现了如下的事实：
当用 float64 作为 key 的时候，先要将其转成 unit64 类型，再插入 key 中。
具体是通过 Float64frombits 函数完成：
// Float64frombits returns the floating point number corresponding // the IEEE 754 binary representation b. func Float64frombits(b uint64) float64 { return *(*float64)(unsafe.Pointer(&amp;b)) } 也就是将浮点数表示成 IEEE 754 规定的格式。如赋值语句：
0x00bd 00189 (test18.go:9) LEAQ "".statictmp_0(SB), DX 0x00c4 00196 (test18.go:9) MOVQ DX, 16(SP) 0x00c9 00201 (test18.go:9) PCDATA $0, $2 0x00c9 00201 (test18.go:9) CALL runtime.mapassign(SB) "".statictmp_0(SB) 变量是这样的：
"".statictmp_0 SRODATA size=8 0x0000 33 33 33 33 33 33 03 40 "".statictmp_1 SRODATA size=8 0x0000 ff 3b 33 33 33 33 03 40 "".statictmp_2 SRODATA size=8 0x0000 33 33 33 33 33 33 03 40 我们再来输出点东西：
package main import ( "fmt" "math" ) func main() { m := make(map[float64]int) m[2.4] = 2 fmt.Println(math.Float64bits(2.4)) fmt.Println(math.Float64bits(2.400000000001)) fmt.Println(math.Float64bits(2.4000000000000000000000001)) } 转成十六进制为：
0x40033333333333330x4003333333333BFF0x4003333333333333 和前面的 "".statictmp_0 比较一下，很清晰了吧。2.4 和 2.4000000000000000000000001 经过 math.Float64bits() 函数转换后的结果是一样的。自然，二者在 map 看来，就是同一个 key 了。
再来看一下 NAN（not a number）：
// NaN returns an IEEE 754 ``not-a-number'' value. func NaN() float64 { return Float64frombits(uvnan) } uvan 的定义为：
uvnan = 0x7FF8000000000001 NAN() 直接调用 Float64frombits，传入写死的 const 型变量 0x7FF8000000000001，得到 NAN 型值。既然，NAN 是从一个常量解析得来的，为什么插入 map 时，会被认为是不同的 key？
这是由类型的哈希函数决定的，例如，对于 64 位的浮点数，它的哈希函数如下：
func f64hash(p unsafe.Pointer, h uintptr) uintptr { f := *(*float64)(p) switch { case f == 0: return c1 * (c0 ^ h) // +0, -0 case f != f: return c1 * (c0 ^ h ^ uintptr(fastrand())) // any kind of NaN default: return memhash(p, h, 8) } } 第二个 case，f != f 就是针对 NAN，这里会再加一个随机数。
这样，所有的谜题都解开了。
由于 NAN 的特性：
NAN != NANhash(NAN) != hash(NAN) 因此向 map 中查找的 key 为 NAN 时，什么也查不到；如果向其中增加了 4 次 NAN，遍历会得到 4 个 NAN。
最后说结论：float 型可以作为 key，但是由于精度的问题，会导致一些诡异的问题，慎用之。
文章转自 https://juejin.cn/post/6844903848587296781</content></entry><entry><title>关于我</title><url>https://www.zhaohaiyu.com/about.html</url><categories/><tags/><content type="html"> 关于我 github: github 博客园: cnblogs email: email</content></entry><entry><title>Go文件系统</title><url>https://www.zhaohaiyu.com/post/go/go-file/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 检测文件是否存在 //存在返回 true，不存在返回 false func fileIfExist(filename string) bool { _, err := os.Stat(filename) if nil != err { fmt.Println(filename, "is not exist!") return false } if os.IsNotExist(err) { return false } return true } 打开文件 f, err := os.Open(filename) if nil != err { fmt.Println("open", filename, "failed!") return } defer f.Close() 如果文件不存在，就会返回错误，如果存在就以只读的方式打开文件。
还可以使用 os.OpenFile() 打开文件，达到不存在就新建，存在就清空（os.O_TRUNC）的目的。当然，也可以不清空文件（os.O_APPEND）。
f, err := os.OpenFile(filename, os.O_RDWR | os.O_CREATE | os.O_TRUNC, 0666) if nil != err { fmt.Println("create", filename, "failed!") return } defer f.Close() 新建文件 f, err := os.Create(filename) if nil != err { fmt.Println("create", filename, "failed!") return } defer f.Close() 注意：如果文件已经存在，那么 os.Create() 会将文件清空。可以使用 os.OpenFile() 新建文件， 参数 flag 为 os.O_CREATE | os.O_EXCL。如果文件已经存在，那么该函数就会返回错误。
f, err := os.OpenFile(filename, os.O_CREATE | os.O_EXCL, 0666) if nil != err { fmt.Println("create", filename, "failed!") return } defer f.Close() 读取文件 读取全部内容 content := make([]byte, 1024) //需要预先分配空间 f, _ := os.Open(filename) defer f.Close() _, err := f.Read(content) if nil != err { fmt.Println("read", filename, "failed!") return } 读取文件内容可以使用 File 的方法——Read。但是使用该方法时需要预先分配空间，用于存储读取的文件内容。我们当然可以提前获取文件的大小，但是这种方式仍然不如 ioutil.ReadAll() 方便。甚至可以直接使用 ioutil.ReadFile()。
ioutil.ReadAll()：
f, _ := os.Open(filename) defer f.Close() content, err := ioutil.ReadAll(f) if nil != err { fmt.Println("read", filename, "failed!") return } fmt.Println(string(content)) ioutil.ReadFile()：
content, err := ioutil.ReadFile(filename) if nil != err { fmt.Println("read", filename, "failed!") return } fmt.Println(string(content)) 按行读取 f, _ := os.Open(filename) defer f.Close() scanner := bufio.NewScanner(f) //按行读取 for scanner.Scan() { fmt.Println(scanner.Text()) //输出文件内容 } 写入文件 f, _ := os.OpenFile(filename, os.O_WRONLY | os.O_APPEND, 0666) defer f.Close() _, err = f.WriteString("target_compile_option") if nil != err { fmt.Println(err) } 这里使用 os.OpenFile() 以追加的方式打开文件。为什么不使用 os.Open() 打开文件呢？因为 os.Open() 是以只读的方式打开文件，无法向文件写入数据。
我们也可以使用 ioutil.WriteFile() 写文件。
writeContent := "write file test" err = ioutil.WriteFile(filename, []byte(writeContent), os.ModePerm) if nil != err { fmt.Println("write", filename, "failed!") } 注意：使用 ioutil.WriteFile(filename string, data []byte, perm os.FileMode) 向文件中写入时，如果文件存在，文件会先被清空，然后再写入。如果文件不存在，就会以 perm 权限先创建文件，然后再写入。
关闭文件 直接调用 File 的 Close() 方法。
f, _ := os.Open(filename) f.Close() 最好使用 defer 关键字执行 Close() 方法，这样能够保证函数退出时文件能被关闭。
删除文件 err := os.Remove(filename) 删除文件前确保文件没有被其他程序使用。如果在当前程序中该文件已被打开，需要先关闭（Close()）文件。</content></entry><entry><title>Go Reflect</title><url>https://www.zhaohaiyu.com/post/go/go-reflect/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 变量的内在机制 Go语言中的变量是分为两部分的:
类型信息：预先定义好的元信息。 值信息：程序运行过程中可动态变化的。 反射介绍 反射是指在程序运行期对程序本身进行访问和修改的能力。程序在编译时，变量被转换为内存地址，变量名不会被编译器写入到可执行部分。在运行程序时，程序无法获取自身的信息。
支持反射的语言可以在程序编译期将变量的反射信息，如字段名称、类型信息、结构体信息等整合到可执行文件中，并给程序提供接口访问反射信息，这样就可以在程序运行期获取类型的反射信息，并且有能力修改它们。
Go程序在运行期使用reflect包访问程序的反射信息。
在上一篇博客中我们介绍了空接口。 空接口可以存储任意类型的变量，那我们如何知道这个空接口保存的数据是什么呢？ 反射就是在运行时动态的获取一个变量的类型信息和值信息。
reflect包 在Go语言的反射机制中，任何接口值都由是一个具体类型和具体类型的值两部分组成的(我们在上一篇接口的博客中有介绍相关概念)。 在Go语言中反射的相关功能由内置的reflect包提供，任意接口值在反射中都可以理解为由reflect.Type和reflect.Value两部分组成，并且reflect包提供了reflect.TypeOf和reflect.ValueOf两个函数来获取任意对象的Value和Type。
reflect.Type 和 reflect.Value 反射是由 reflect 包提供的。它定义了两个重要的类型，Type 和 Value。一个 Type 表示一个Go类型。它是一个接口，有许多方法来区分类型以及检查它们的组成部分，例如一个结构体的成员或一个函数的参数等。唯一能反映 reflect.Type 实现的是接口的类型描述信息（§7.5），也正是这个实体标识了接口值的动态类型。
函数 reflect.TypeOf 接受任意的 interface{} 类型，并以 reflect.Type 形式返回其动态类型：
t := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // "int" fmt.Println(t) // "int" 其中 TypeOf(3) 调用将值 3 传给 interface{} 参数。回到 7.5节 的将一个具体的值转为接口类型会有一个隐式的接口转换操作，它会创建一个包含两个信息的接口值：操作数的动态类型（这里是 int）和它的动态的值（这里是 3）。
因为 reflect.TypeOf 返回的是一个动态类型的接口值，它总是返回具体的类型。因此，下面的代码将打印 &ldquo;*os.File&rdquo; 而不是 &ldquo;io.Writer&rdquo;。稍后，我们将看到能够表达接口类型的 reflect.Type。
var w io.Writer = os.Stdout fmt.Println(reflect.TypeOf(w)) // "*os.File" 要注意的是 reflect.Type 接口是满足 fmt.Stringer 接口的。因为打印一个接口的动态类型对于调试和日志是有帮助的， fmt.Printf 提供了一个缩写 %T 参数，内部使用 reflect.TypeOf 来输出：
fmt.Printf("%T\n", 3) // "int" reflect 包中另一个重要的类型是 Value。一个 reflect.Value 可以装载任意类型的值。函数 reflect.ValueOf 接受任意的 interface{} 类型，并返回一个装载着其动态值的 reflect.Value。和 reflect.TypeOf 类似，reflect.ValueOf 返回的结果也是具体的类型，但是 reflect.Value 也可以持有一个接口值。
v := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // "3" fmt.Printf("%v\n", v) // "3" fmt.Println(v.String()) // NOTE: "&lt;int Value>" 和 reflect.Type 类似，reflect.Value 也满足 fmt.Stringer 接口，但是除非 Value 持有的是字符串，否则 String 方法只返回其类型。而使用 fmt 包的 %v 标志参数会对 reflect.Values 特殊处理。
对 Value 调用 Type 方法将返回具体类型所对应的 reflect.Type：
t := v.Type() // a reflect.Type fmt.Println(t.String()) // "int" reflect.ValueOf 的逆操作是 reflect.Value.Interface 方法。它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值：
v := reflect.ValueOf(3) // a reflect.Value x := v.Interface() // an interface{} i := x.(int) // an int fmt.Printf("%d\n", i) // "3" reflect.Value 和 interface{} 都能装载任意的值。所不同的是，一个空的接口隐藏了值内部的表示方式和所有方法，因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值（就像上面那样），内部值我们没法访问。相比之下，一个 Value 则有很多方法来检查其内容，无论它的具体类型是什么。让我们再次尝试实现我们的格式化函数 format.Any。
我们使用 reflect.Value 的 Kind 方法来替代之前的类型 switch。虽然还是有无穷多的类型，但是它们的 kinds 类型却是有限的：Bool、String 和 所有数字类型的基础类型；Array 和 Struct 对应的聚合类型；Chan、Func、Ptr、Slice 和 Map 对应的引用类型；interface 类型；还有表示空值的 Invalid 类型。（空的 reflect.Value 的 kind 即为 Invalid。）
gopl.io/ch12/format
package format import ( "reflect" "strconv" ) // Any formats any value as a string. func Any(value interface{}) string { return formatAtom(reflect.ValueOf(value)) } // formatAtom formats a value without inspecting its internal structure. func formatAtom(v reflect.Value) string { switch v.Kind() { case reflect.Invalid: return "invalid" case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return strconv.FormatInt(v.Int(), 10) case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr: return strconv.FormatUint(v.Uint(), 10) // ...floating-point and complex cases omitted for brevity... case reflect.Bool: return strconv.FormatBool(v.Bool()) case reflect.String: return strconv.Quote(v.String()) case reflect.Chan, reflect.Func, reflect.Ptr, reflect.Slice, reflect.Map: return v.Type().String() + " 0x" + strconv.FormatUint(uint64(v.Pointer()), 16) default: // reflect.Array, reflect.Struct, reflect.Interface return v.Type().String() + " value" } } 到目前为止，我们的函数将每个值视作一个不可分割没有内部结构的物品，因此它叫 formatAtom。对于聚合类型（结构体和数组）和接口，只是打印值的类型，对于引用类型（channels、functions、pointers、slices 和 maps），打印类型和十六进制的引用地址。虽然还不够理想，但是依然是一个重大的进步，并且 Kind 只关心底层表示，format.Any 也支持具名类型。例如：
var x int64 = 1 var d time.Duration = 1 * time.Nanosecond fmt.Println(format.Any(x)) // "1" fmt.Println(format.Any(d)) // "1" fmt.Println(format.Any([]int64{x})) // "[]int64 0x8202b87b0" fmt.Println(format.Any([]time.Duration{d})) // "[]time.Duration 0x8202b87e0" 通过reflect.Value修改值 到目前为止，反射还只是程序中变量的另一种读取方式。然而，在本节中我们将重点讨论如何通过反射机制来修改变量。
回想一下，Go语言中类似x、x.f[1]和*p形式的表达式都可以表示变量，但是其它如x + 1和f(2)则不是变量。一个变量就是一个可寻址的内存空间，里面存储了一个值，并且存储的值可以通过内存地址来更新。
对于reflect.Values也有类似的区别。有一些reflect.Values是可取地址的；其它一些则不可以。考虑以下的声明语句：
x := 2 // value type variable? a := reflect.ValueOf(2) // 2 int no b := reflect.ValueOf(x) // 2 int no c := reflect.ValueOf(&amp;x) // &amp;x *int no d := c.Elem() // 2 int yes (x) 其中a对应的变量不可取地址。因为a中的值仅仅是整数2的拷贝副本。b中的值也同样不可取地址。c中的值还是不可取地址，它只是一个指针&amp;x的拷贝。实际上，所有通过reflect.ValueOf(x)返回的reflect.Value都是不可取地址的。但是对于d，它是c的解引用方式生成的，指向另一个变量，因此是可取地址的。我们可以通过调用reflect.ValueOf(&amp;x).Elem()，来获取任意变量x对应的可取地址的Value。
我们可以通过调用reflect.Value的CanAddr方法来判断其是否可以被取地址：
fmt.Println(a.CanAddr()) // "false" fmt.Println(b.CanAddr()) // "false" fmt.Println(c.CanAddr()) // "false" fmt.Println(d.CanAddr()) // "true" 每当我们通过指针间接地获取的reflect.Value都是可取地址的，即使开始的是一个不可取地址的Value。在反射机制中，所有关于是否支持取地址的规则都是类似的。例如，slice的索引表达式e[i]将隐式地包含一个指针，它就是可取地址的，即使开始的e表达式不支持也没有关系。以此类推，reflect.ValueOf(e).Index(i)对应的值也是可取地址的，即使原始的reflect.ValueOf(e)不支持也没有关系。
要从变量对应的可取地址的reflect.Value来访问变量需要三个步骤。第一步是调用Addr()方法，它返回一个Value，里面保存了指向变量的指针。然后是在Value上调用Interface()方法，也就是返回一个interface{}，里面包含指向变量的指针。最后，如果我们知道变量的类型，我们可以使用类型的断言机制将得到的interface{}类型的接口强制转为普通的类型指针。这样我们就可以通过这个普通指针来更新变量了：
x := 2 d := reflect.ValueOf(&amp;x).Elem() // d refers to the variable x px := d.Addr().Interface().(*int) // px := &amp;x *px = 3 // x = 3 fmt.Println(x) // "3" 或者，不使用指针，而是通过调用可取地址的reflect.Value的reflect.Value.Set方法来更新对应的值：
d.Set(reflect.ValueOf(4)) fmt.Println(x) // "4" Set方法将在运行时执行和编译时进行类似的可赋值性约束的检查。以上代码，变量和值都是int类型，但是如果变量是int64类型，那么程序将抛出一个panic异常，所以关键问题是要确保改类型的变量可以接受对应的值：
d.Set(reflect.ValueOf(int64(5))) // panic: int64 is not assignable to int 同样，对一个不可取地址的reflect.Value调用Set方法也会导致panic异常：
x := 2 b := reflect.ValueOf(x) b.Set(reflect.ValueOf(3)) // panic: Set using unaddressable value 这里有很多用于基本数据类型的Set方法：SetInt、SetUint、SetString和SetFloat等。
d := reflect.ValueOf(&amp;x).Elem() d.SetInt(3) fmt.Println(x) // "3" 从某种程度上说，这些Set方法总是尽可能地完成任务。以SetInt为例，只要变量是某种类型的有符号整数就可以工作，即使是一些命名的类型、甚至只要底层数据类型是有符号整数就可以，而且如果对于变量类型值太大的话会被自动截断。但需要谨慎的是：对于一个引用interface{}类型的reflect.Value调用SetInt会导致panic异常，即使那个interface{}变量对于整数类型也不行。
x := 1 rx := reflect.ValueOf(&amp;x).Elem() rx.SetInt(2) // OK, x = 2 rx.Set(reflect.ValueOf(3)) // OK, x = 3 rx.SetString("hello") // panic: string is not assignable to int rx.Set(reflect.ValueOf("hello")) // panic: string is not assignable to int var y interface{} ry := reflect.ValueOf(&amp;y).Elem() ry.SetInt(2) // panic: SetInt called on interface Value ry.Set(reflect.ValueOf(3)) // OK, y = int(3) ry.SetString("hello") // panic: SetString called on interface Value ry.Set(reflect.ValueOf("hello")) // OK, y = "hello" 当我们用Display显示os.Stdout结构时，我们发现反射可以越过Go语言的导出规则的限制读取结构体中未导出的成员，比如在类Unix系统上os.File结构体中的fd int成员。然而，利用反射机制并不能修改这些未导出的成员：
stdout := reflect.ValueOf(os.Stdout).Elem() // *os.Stdout, an os.File var fmt.Println(stdout.Type()) // "os.File" fd := stdout.FieldByName("fd") fmt.Println(fd.Int()) // "1" fd.SetInt(2) // panic: unexported field 一个可取地址的reflect.Value会记录一个结构体成员是否是未导出成员，如果是的话则拒绝修改操作。因此，CanAddr方法并不能正确反映一个变量是否是可以被修改的。另一个相关的方法CanSet是用于检查对应的reflect.Value是否是可取地址并可被修改的：
fmt.Println(fd.CanAddr(), fd.CanSet()) // "true false" 获取结构体字段标签 在4.5节我们使用构体成员标签用于设置对应JSON对应的名字。其中json成员标签让我们可以选择成员的名字和抑制零值成员的输出。在本节，我们将看到如何通过反射机制类获取成员标签。
对于一个web服务，大部分HTTP处理函数要做的第一件事情就是展开请求中的参数到本地变量中。我们定义了一个工具函数，叫params.Unpack，通过使用结构体成员标签机制来让HTTP处理函数解析请求参数更方便。
首先，我们看看如何使用它。下面的search函数是一个HTTP请求处理函数。它定义了一个匿名结构体类型的变量，用结构体的每个成员表示HTTP请求的参数。其中结构体成员标签指明了对于请求参数的名字，为了减少URL的长度这些参数名通常都是神秘的缩略词。Unpack将请求参数填充到合适的结构体成员中，这样我们可以方便地通过合适的类型类来访问这些参数。
gopl.io/ch12/search
import "gopl.io/ch12/params" // search implements the /search URL endpoint. func search(resp http.ResponseWriter, req *http.Request) { var data struct { Labels []string `http:"l"` MaxResults int `http:"max"` Exact bool `http:"x"` } data.MaxResults = 10 // set default if err := params.Unpack(req, &amp;data); err != nil { http.Error(resp, err.Error(), http.StatusBadRequest) // 400 return } // ...rest of handler... fmt.Fprintf(resp, "Search: %+v\n", data) } 下面的Unpack函数主要完成三件事情。第一，它调用req.ParseForm()来解析HTTP请求。然后，req.Form将包含所有的请求参数，不管HTTP客户端使用的是GET还是POST请求方法。
下一步，Unpack函数将构建每个结构体成员有效参数名字到成员变量的映射。如果结构体成员有成员标签的话，有效参数名字可能和实际的成员名字不相同。reflect.Type的Field方法将返回一个reflect.StructField，里面含有每个成员的名字、类型和可选的成员标签等信息。其中成员标签信息对应reflect.StructTag类型的字符串，并且提供了Get方法用于解析和根据特定key提取的子串，例如这里的http:"&hellip;&ldquo;形式的子串。
gopl.io/ch12/params
// Unpack populates the fields of the struct pointed to by ptr // from the HTTP request parameters in req. func Unpack(req *http.Request, ptr interface{}) error { if err := req.ParseForm(); err != nil { return err } // Build map of fields keyed by effective name. fields := make(map[string]reflect.Value) v := reflect.ValueOf(ptr).Elem() // the struct variable for i := 0; i &lt; v.NumField(); i++ { fieldInfo := v.Type().Field(i) // a reflect.StructField tag := fieldInfo.Tag // a reflect.StructTag name := tag.Get("http") if name == "" { name = strings.ToLower(fieldInfo.Name) } fields[name] = v.Field(i) } // Update struct field for each parameter in the request. for name, values := range req.Form { f := fields[name] if !f.IsValid() { continue // ignore unrecognized HTTP parameters } for _, value := range values { if f.Kind() == reflect.Slice { elem := reflect.New(f.Type().Elem()).Elem() if err := populate(elem, value); err != nil { return fmt.Errorf("%s: %v", name, err) } f.Set(reflect.Append(f, elem)) } else { if err := populate(f, value); err != nil { return fmt.Errorf("%s: %v", name, err) } } } } return nil } 最后，Unpack遍历HTTP请求的name/valu参数键值对，并且根据更新相应的结构体成员。回想一下，同一个名字的参数可能出现多次。如果发生这种情况，并且对应的结构体成员是一个slice，那么就将所有的参数添加到slice中。其它情况，对应的成员值将被覆盖，只有最后一次出现的参数值才是起作用的。
populate函数小心用请求的字符串类型参数值来填充单一的成员v（或者是slice类型成员中的单一的元素）。目前，它仅支持字符串、有符号整数和布尔型。其中其它的类型将留做练习任务。
func populate(v reflect.Value, value string) error { switch v.Kind() { case reflect.String: v.SetString(value) case reflect.Int: i, err := strconv.ParseInt(value, 10, 64) if err != nil { return err } v.SetInt(i) case reflect.Bool: b, err := strconv.ParseBool(value) if err != nil { return err } v.SetBool(b) default: return fmt.Errorf("unsupported kind %s", v.Type()) } return nil } 如果我们上上面的处理程序添加到一个web服务器，则可以产生以下的会话：
$ go build gopl.io/ch12/search $ ./search &amp; $ ./fetch 'http://localhost:12345/search' Search: {Labels:[] MaxResults:10 Exact:false} $ ./fetch 'http://localhost:12345/search?l=golang&amp;l=programming' Search: {Labels:[golang programming] MaxResults:10 Exact:false} $ ./fetch 'http://localhost:12345/search?l=golang&amp;l=programming&amp;max=100' Search: {Labels:[golang programming] MaxResults:100 Exact:false} $ ./fetch 'http://localhost:12345/search?x=true&amp;l=golang&amp;l=programming' Search: {Labels:[golang programming] MaxResults:10 Exact:true} $ ./fetch 'http://localhost:12345/search?q=hello&amp;x=123' x: strconv.ParseBool: parsing "123": invalid syntax $ ./fetch 'http://localhost:12345/search?q=hello&amp;max=lots' max: strconv.ParseInt: parsing "lots": invalid syntax 显示一个类型的方法集 我们的最后一个例子是使用reflect.Type来打印任意值的类型和枚举它的方法：
gopl.io/ch12/methods
// Print prints the method set of the value x. func Print(x interface{}) { v := reflect.ValueOf(x) t := v.Type() fmt.Printf("type %s\n", t) for i := 0; i &lt; v.NumMethod(); i++ { methType := v.Method(i).Type() fmt.Printf("func (%s) %s%s\n", t, t.Method(i).Name, strings.TrimPrefix(methType.String(), "func")) } } reflect.Type和reflect.Value都提供了一个Method方法。每次t.Method(i)调用将一个reflect.Method的实例，对应一个用于描述一个方法的名称和类型的结构体。每次v.Method(i)方法调用都返回一个reflect.Value以表示对应的值（§6.4），也就是一个方法是帮到它的接收者的。使用reflect.Value.Call方法（我们这里没有演示），将可以调用一个Func类型的Value，但是这个例子中只用到了它的类型。
这是属于time.Duration和*strings.Replacer两个类型的方法：
methods.Print(time.Hour) // Output: // type time.Duration // func (time.Duration) Hours() float64 // func (time.Duration) Minutes() float64 // func (time.Duration) Nanoseconds() int64 // func (time.Duration) Seconds() float64 // func (time.Duration) String() string methods.Print(new(strings.Replacer)) // Output: // type *strings.Replacer // func (*strings.Replacer) Replace(string) string // func (*strings.Replacer) WriteString(io.Writer, string) (int, error) 参考文章：
《go语言圣经》 https://www.liwenzhou.com/posts/Go/13_reflect</content></entry><entry><title>Go并发</title><url>https://www.zhaohaiyu.com/post/go/go-concurrent/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> goroutine goroutine是Go并行设计的核心。goroutine说到底其实就是线程，但是它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比thread更易用、更高效、更轻便。
goroutine是通过Go的runtime管理的一个线程管理器。goroutine通过go关键字实现了，其实就是一个普通的函数。
go hello(a, b, c) 通过关键字go就启动了一个goroutine。我们来看一个例子
package main import ( "fmt" "runtime" ) func say(s string) { for i := 0; i &lt; 5; i++ { runtime.Gosched() fmt.Println(s) } } func main() { go say("world") //开一个新的Goroutines执行 say("hello") //当前Goroutines执行 } // 以上程序执行后将输出： // hello // world // hello // world // hello // world // hello // world // hello 我们可以看到go关键字很方便的就实现了并发编程。 上面的多个goroutine运行在同一个进程里面，共享内存数据，不过设计上我们要遵循：不要通过共享来通信，而要通过通信来共享。
goroutine的调度机制 Go runtime的调度器： 在了解Go的运行时的scheduler之前，需要先了解为什么需要它，因为我们可能会想，OS内核不是已经有一个线程scheduler了嘛？ 熟悉POSIX API的人都知道，POSIX的方案在很大程度上是对Unix process进场模型的一个逻辑描述和扩展，两者有很多相似的地方。 Thread有自己的信号掩码，CPU affinity等。但是很多特征对于Go程序来说都是累赘。 尤其是context上下文切换的耗时。另一个原因是Go的垃圾回收需要所有的goroutine停止，使得内存在一个一致的状态。垃圾回收的时间点是不确定的，如果依靠OS自身的scheduler来调度，那么会有大量的线程需要停止工作。
单独的开发一个GO得调度器，可以是其知道在什么时候内存状态是一致的，也就是说，当开始垃圾回收时，运行时只需要为当时正在CPU核上运行的那个线程等待即可，而不是等待所有的线程。
用户空间线程和内核空间线程之间的映射关系有：N:1,1:1和M:N N:1是说，多个（N）用户线程始终在一个内核线程上跑，context上下文切换确实很快，但是无法真正的利用多核。 1：1是说，一个用户线程就只在一个内核线程上跑，这时可以利用多核，但是上下文switch很慢。 M:N是说， 多个goroutine在多个内核线程上跑，这个看似可以集齐上面两者的优势，但是无疑增加了调度的难度。
Go的调度器内部有三个重要的结构：M，P，S M:代表真正的内核OS线程，和POSIX里的thread差不多，真正干活的人 G:代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。 P:代表调度的上下文，可以把它看做一个局部的调度器，使go代码在一个线程上跑，它是实现从N:1到N:M映射的关键。
图中看，有2个物理线程M，每一个M都拥有一个context（P），每一个也都有一个正在运行的goroutine。 P的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。 图中灰色的那些goroutine并没有运行，而是出于ready的就绪态，正在等待被调度。P维护着这个队列（称之为runqueue）， Go语言里，启动一个goroutine很容易：go function 就行，所以每有一个go语句被执行，runqueue队列就在其末尾加入一个 goroutine，在下一个调度点，就从runqueue中取出（如何决定取哪个goroutine？）一个goroutine执行。
为何要维护多个上下文P？因为当一个OS线程被阻塞时，P可以转而投奔另一个OS线程！ 图中看到，当一个OS线程M0陷入阻塞时，P转而在OS线程M1上运行。调度器保证有足够的线程来运行所以的context P。
图中的M1可能是被创建，或者从线程缓存中取出。
当MO返回时，它必须尝试取得一个context P来运行goroutine，一般情况下，它会从其他的OS线程那里steal偷一个context过来， 如果没有偷到的话，它就把goroutine放在一个global runqueue里，然后自己就去睡大觉了（放入线程缓存里）。Contexts们也会周期性的检查global runqueue，否则global runqueue上的goroutine永远无法执行。
另一种情况是P所分配的任务G很快就执行完了（分配不均），这就导致了一个上下文P闲着没事儿干而系统却任然忙碌。但是如果global runqueue没有任务G了，那么P就不得不从其他的上下文P那里拿一些G来执行。一般来说，如果上下文P从其他的上下文P那里要偷一个任务的话，一般就‘偷’run queue的一半，这就确保了每个OS线程都能充分的使用。
channels goroutine运行在相同的地址空间，因此访问共享内存必须做好同步。那么goroutine之间如何进行数据的通信呢，Go提供了一个很好的通信机制channel。channel可以与Unix shell 中的双向管道做类比：可以通过它发送或者接收值。这些值只能是特定的类型：channel类型。定义一个channel时，也需要定义发送到channel的值的类型。注意，必须使用make 创建channel：
ci := make(chan int) cs := make(chan string) cf := make(chan interface{}) channel通过操作符&lt;-来接收和发送数据
ch &lt;- v // 发送v到channel ch. v := &lt;-ch // 从ch中接收数据，并赋值给v 我们把这些应用到我们的例子中来：
package main import "fmt" func sum(a []int, c chan int) { total := 0 for _, v := range a { total += v } c &lt;- total // send total to c } func main() { a := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(a[:len(a)/2], c) go sum(a[len(a)/2:], c) x, y := &lt;-c, &lt;-c // receive from c fmt.Println(x, y, x + y) } 默认情况下，channel接收和发送数据都是阻塞的，除非另一端已经准备好，这样就使得Goroutines同步变的更加的简单，而不需要显式的lock。所谓阻塞，也就是如果读取（value := &lt;-ch）它将会被阻塞，直到有数据接收。其次，任何发送（ch&lt;-5）将会被阻塞，直到数据被读出。无缓冲channel是在多个goroutine之间同步很棒的工具。
Buffered Channels 上面我们介绍了默认的非缓存类型的channel，不过Go也允许指定channel的缓冲大小，很简单，就是channel可以存储多少元素。ch:= make(chan bool, 4)，创建了可以存储4个元素的bool 型channel。在这个channel 中，前4个元素可以无阻塞的写入。当写入第5个元素时，代码将会阻塞，直到其他goroutine从channel 中读取一些元素，腾出空间。
ch := make(chan type, value) /* value == 0 ! 无缓冲（阻塞） value > 0 ! 缓冲（非阻塞，直到value 个元素） */ 我们看一下下面这个例子，你可以在自己本机测试一下，修改相应的value值
package main import "fmt" func main() { c := make(chan int, 2)//修改2为1就报错，修改2为3可以正常运行 c &lt;- 1 c &lt;- 2 fmt.Println(&lt;-c) fmt.Println(&lt;-c) } //修改为1报如下的错误: //fatal error: all goroutines are asleep - deadlock! Range和Close 上面这个例子中，我们需要读取两次c，这样不是很方便，Go考虑到了这一点，所以也可以通过range，像操作slice或者map一样操作缓存类型的channel，请看下面的例子
package main import ( "fmt" ) func fibonacci(n int, c chan int) { x, y := 1, 1 for i := 0; i &lt; n; i++ { c &lt;- x x, y = y, x + y } close(c) } func main() { c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c { fmt.Println(i) } } for i := range c能够不断的读取channel里面的数据，直到该channel被显式的关闭。上面代码我们看到可以显式的关闭channel，生产者通过内置函数close关闭channel。关闭channel之后就无法再发送任何数据了，在消费方可以通过语法v, ok := &lt;-ch测试channel是否被关闭。如果ok返回false，那么说明channel已经没有任何数据并且已经被关闭。
记住应该在生产者的地方关闭channel，而不是消费的地方去关闭它，这样容易引起panic
另外记住一点的就是channel不像文件之类的，不需要经常去关闭，只有当你确实没有任何发送数据了，或者你想显式的结束range循环之类的
Select 我们上面介绍的都是只有一个channel的情况，那么如果存在多个channel的时候，我们该如何操作呢，Go里面提供了一个关键字select，通过select可以监听channel上的数据流动。
select默认是阻塞的，只有当监听的channel中有发送或接收可以进行时才会运行，当多个channel都准备好的时候，select是随机的选择一个执行的。
package main import "fmt" func fibonacci(c, quit chan int) { x, y := 1, 1 for { select { case c &lt;- x: x, y = y, x + y case &lt;-quit: fmt.Println("quit") return } } } func main() { c := make(chan int) quit := make(chan int) go func() { for i := 0; i &lt; 10; i++ { fmt.Println(&lt;-c) } quit &lt;- 0 }() fibonacci(c, quit) } 在select里面还有default语法，select其实就是类似switch的功能，default就是当监听的channel都没有准备好的时候，默认执行的（select不再阻塞等待channel）。
select { case i := &lt;-c: // use i default: // 当c阻塞的时候执行这里 } 超时 有时候会出现goroutine阻塞的情况，那么我们如何避免整个程序进入阻塞的情况呢？我们可以利用select来设置超时，通过如下的方式实现：
func main() { c := make(chan int) o := make(chan bool) go func() { for { select { case v := &lt;- c: println(v) case &lt;- time.After(5 * time.Second): println("timeout") o &lt;- true break } } }() &lt;- o } runtime goroutine runtime包中有几个处理goroutine的函数：
Goexit
退出当前执行的goroutine，但是defer函数还会继续调用
Gosched
让出当前goroutine的执行权限，调度器安排其他等待的任务运行，并在下次某个时候从该位置恢复执行。
NumCPU
返回 CPU 核数量
NumGoroutine
返回正在执行和排队的任务总数
GOMAXPROCS
用来设置可以并行计算的CPU核数的最大值，并返回之前的值。
参考文章:
《go web编程》 https://www.zhihu.com/question/20862617/answer/27964865</content></entry><entry><title>Go接口</title><url>https://www.zhaohaiyu.com/post/go/go-interface/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 接口的定义 接口类型是对其它类型行为的抽象和概括；因为接口类型不会和特定的实现细节绑定在一起，通过这种抽象的方式我们可以让我们的函数更加灵活和更具有适应能力。
很多面向对象的语言都有相似的接口概念，但Go语言中接口类型的独特之处在于它是满足隐式实现的。也就是说，我们没有必要对于给定的具体类型定义所有满足的接口类型；简单地拥有一些必需的方法就足够了。这种设计可以让你创建一个新的接口类型满足已经存在的具体类型却不会去改变这些类型的定义；当我们使用的类型来自于不受我们控制的包时这种设计尤其有用。
接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。接口类型是一种抽象的类型。它不会暴露出它所代表的对象的内部值的结构和这个对象支持的基础操作的集合；它们只会展示出它们自己的方法。也就是说当你有看到一个接口类型的值时，你不知道它是什么，唯一知道的就是可以通过它的方法来做什么。
package main import "fmt" type canSay interface{ Say() } type dog struct { name string } type cat struct { name string } func (d dog) Say() { fmt.Println(d.name,"say") } func main() { var tom2 canSay tom := dog{name: "汤姆"} tom2 = tom tom2.Say() // 汤姆 say mi := cat{name: "猫咪"} tom2 = mi // 报错 因为cat没有实现接口规定的say方法 } 接口值 接口值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。
package main import ( "bytes" "fmt" "io" "os" ) func main() { var w io.Writer fmt.Printf("类型:%T,值:%v\n",w,w) // 类型:,值: w = os.Stdout fmt.Printf("类型:%T,值:%v\n",w,w) // 类型:*os.File,值:&amp;{0xc00007e280} w = new(bytes.Buffer) fmt.Printf("类型:%T,值:%v\n",w,w) // 类型:*bytes.Buffer,值: w = nil fmt.Printf("类型:%T,值:%v\n",w,w) // 类型: 类型: } 一个包含nil指针的接口不是nil接口
类型断言 类型断言是一个使用在接口值上的操作。语法上它看起来像x.(T)被称为断言类型，这里x表示一个接口的类型和T表示一个类型。一个类型断言检查它操作对象的动态类型是否和断言的类型匹配。
x.(T)T表示类型
package main import ( "bytes" "fmt" "io" "os" ) func main() { var w io.Writer w = os.Stdout f := w.(*os.File) fmt.Printf("类型%T,值:%v\n",f,f) // 类型*os.File,值:&amp;{0xc00014a280} c := w.(*bytes.Buffer) fmt.Printf("类型%T,值:%v\n",c,c) // panic } 判断是什么类型:
package main import ( "fmt" ) func judgeType(x interface{}) { switch v := x.(type) { case string: fmt.Printf("is string:%v\n", v) case int: fmt.Printf("is int:%v\n", v) case bool: fmt.Printf("is bool:%v\n", v) default: fmt.Println("donot know ") } } func main() { judgeType(1) // is int:1 judgeType(true) // is bool:true judgeType("true") // is string:true judgeType(1.22) // donot know } 空接口 空接口的定义 空接口是没有定义任何方法的接口。因此任何类型都实现了空接口。空接口类型的变量可以存储任意类型的变量。
package main import "fmt" func main() { var test interface{} t1 := 1 test = t1 fmt.Printf("类型:%T 值:%v\n",test,test) // 类型:int 值:1 t2 := "zhaohaiyu" test = t2 fmt.Printf("类型:%T 值:%v\n",test,test) // 类型:string 值:zhaohaiyu t3 := false test = t3 fmt.Printf("类型:%T 值:%v\n",test,test) // 类型:bool 值:false t4 := 3.14 test = t4 fmt.Printf("类型:%T 值:%v\n",test,test) // 类型:float64 值:3.14 } 空接口的应用 空接口作为函数的参数 func show(test interface{}) { fmt.Printf("类型:%T 值:%v\n",test,test) } 空接口作为map的值 var studentInfo = make(map[string]interface{}) studentInfo["name"] = "赵海宇" studentInfo["age"] = 18 fmt.Println(studentInfo) // map[age:18 name:赵海宇]</content></entry><entry><title>Go方法</title><url>https://www.zhaohaiyu.com/post/go/go-method/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 方法声明 在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。
package main import "fmt" type People struct { name string age uint8 } func (p People) SayHello() { fmt.Println(p.name, ": hello world") p.age = 20 } func main() { p := People{name: "zhaohaiyu", age: 18} p.SayHello() // zhaohaiyu : hello world fmt.Println(p.age) //18 } 基于指针对象的方法 当调用一个函数时，会对其每一个参数值进行拷贝，如果一个函数需要更新一个变量，或者函数的其中一个参数实在太大我们希望能够避免进行这种默认的拷贝，这种情况下我们就需要用到指针了。
package main import "fmt" type People struct { name string age uint8 } func (p *People) SayHello() { fmt.Println(p.name, ": hello world") p.age = 20 } func main() { p := People{name: "zhaohaiyu", age: 18} p.SayHello() // zhaohaiyu : hello world fmt.Println(p.age) // 20 } 调用时p为person的结构体对象,SayHello是People结构体指针的方法,在go中可以直接调用,亦可以(&amp;p).SayHello()
Nil也是一个合法的接收器类型
package main import "fmt" type MySlice []int func (m *MySlice) sum() int { var num int for _, i := range *m { num += i } return num } func main() { m := MySlice{1,2,3,4,5} fmt.Println(m.sum()) // 15 m = nil fmt.Println(m.sum()) // 0 } 封装 一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。封装有时候也被叫做信息隐藏，同时也是面向对象编程最关键的一个方面。
Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。
这也就是前面的小节中IntSet被定义为struct类型的原因，尽管它只有一个字段：
type IntSet struct { words []uint64 } 当然，我们也可以把IntSet定义为一个slice类型，尽管这样我们就需要把代码中所有方法里用到的s.words用*s替换掉了：
type IntSet []uint64</content></entry><entry><title>Go函数</title><url>https://www.zhaohaiyu.com/post/go/go-function/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 函数声明 函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。
func function-name(param...) (result...) { body } 形式参数列表描述了函数的参数名以及参数类型。这些参数作为局部变量，其值由参数调用者提供。返回值列表描述了函数返回值的变量名以及类型。如果函数返回一个无名变量或者没有返回值，返回值列表的括号是可以省略的。如果一个函数声明不包括返回值列表，那么函数体执行完毕后，不会返回任何值。
func hypot(x, y float64) float64 { return math.Sqrt(x*x + y*y) } fmt.Println(hypot(3,4)) // "5" 递归 函数可以是递归的，这意味着函数可以直接或间接的调用自身。对许多问题而言，递归是一种强有力的技术，例如处理递归的数据结构。
func a(i int) (res int){ if i == 1 { return i } return i * a(i - 1) } fmt.Println(a(5)) // 120 多返回值 在Go中，一个函数可以返回多个值。
func calculation(a,b int)(add,sub int) { add = a + b sub = a - b } 错误 在Go中有一部分函数总是能成功的运行，对各种可能的输入都做了良好的处理，使得运行时几乎不会失败，除非遇到灾难性的、不可预料的情况，比如运行时的内存溢出。导致这种错误的原因很复杂，难以处理，从错误中恢复的可能性也很低。
panic是来自被调函数的信号，表示发生了某个已知的bug。一个良好的程序永远不应该发生panic异常。
value, ok := cache.Lookup(key) if !ok { // ...cache[key] does not exist… } 错误处理策略 当一次函数调用返回错误时，调用者有应该选择何时的方式处理错误。根据情况的不同，有很多处理方式.
resp,err := http.Get("https://www.google.com") if err != nil { fmt.Println(err) } 文件结尾错误（EOF） 函数经常会返回多种错误，这对终端用户来说可能会很有趣，但对程序而言，这使得情况变得复杂。很多时候，程序必须根据错误类型，作出不同的响应。让我们考虑这样一个例子：从文件中读取n个字节。如果n等于文件的长度，读取过程的任何错误都表示失败。如果n小于文件的长度，调用者会重复的读取固定大小的数据直到文件结束。这会导致调用者必须分别处理由文件结束引起的各种错误。基于这样的原因，io包保证任何由文件结束引起的读取失败都返回同一个错误——io.EOF，该错误在io包中定义：
package io import "errors" // EOF is the error returned by Read when no more input is available. var EOF = errors.New("EOF") 调用者只需通过简单的比较，就可以检测出这个错误。下面的例子展示了如何从标准输入中读取字符，以及判断文件结束。
in := bufio.NewReader(os.Stdin) for { r, _, err := in.ReadRune() if err == io.EOF { break // finished reading } if err != nil { return fmt.Errorf("read failed:%v", err) } // ...use r… } 因为文件结束这种错误不需要更多的描述，所以io.EOF有固定的错误信息——“EOF”。对于其他错误，我们可能需要在错误信息中描述错误的类型和数量，这使得我们不能像io.EOF一样采用固定的错误信息。在7.11节中，我们会提出更系统的方法区分某些固定的错误值。
函数值 在Go中，函数被看作第一类值（first-class values）：函数像其他值一样，拥有类型，可以被赋值给其他变量，传递给函数，从函数返回。对函数值（function value）的调用类似函数调用。
func add(a,b int) (sum int) { sum = a + b } func main() { f = add fmt.Println(sum(1,2)) } 函数类型的零值是nil。调用值为nil的函数值会引起panic错误：
var f func(int) int f(3) // 此处f的值为nil, 会引起panic错误 匿名函数 拥有函数名的函数只能在包级语法块中被声明，通过函数字面量（function literal），我们可绕过这一限制，在任何表达式中表示一个函数值。函数字面量的语法和函数声明相似，区别在于func关键字后没有函数名。函数值字面量是一种表达式，它的值被成为匿名函数（anonymous function）。
func squares() func() int { var x int return func() int { x++ return x * x } } func main() { f := squares() fmt.Println(f()) // "1" fmt.Println(f()) // "4" fmt.Println(f()) // "9" fmt.Println(f()) // "16" } 可变参数 参数数量可变的函数称为为可变参数函数。典型的例子就是fmt.Printf和类似函数。Printf首先接收一个的必备参数，之后接收任意个数的后续参数。
在声明可变参数函数时，需要在参数列表的最后一个参数类型之前加上省略符号“&hellip;”，这表示该函数会接收任意数量的该类型参数。
func main() { fmt.Println(sum(1,2,3,4,5)) // 15 var sli = []int{1,2,3,4,5} fmt.Println(sli) // [1 2 3 4 5] fmt.Println(sum(sli...)) // 15 } func sum(values ...int) int { sum := 0 for _, v := range values { sum += v } return sum } Panic异常 Go的类型系统会在编译时捕获很多错误，但有些错误只能在运行时检查，如数组访问越界、空指针引用等。这些运行时错误会引起painc异常。
一般而言，当panic异常发生时，程序会中断运行，并执行此goroute上的defer函数。
当某些不应该发生的场景发生时，我们就应该调用panic。
name := "zhaohaiyu" switch name { case "zhy": fmt.Println("zhy") case "haiyuzhao": fmt.Println("haiyuzhao") default: panic("没有这个名字") } 虽然Go的panic机制类似于其他语言的异常，但panic的适用场景有一些不同。由于panic会引起程序的崩溃，因此panic一般用于严重错误，如程序内部的逻辑不一致。
Recover捕获异常 通常来说，不应该对panic异常做任何处理，但有时，也许我们可以从异常中恢复，至少我们可以在程序崩溃前，做一些操作。
如果在deferred函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。
让我们以语言解析器为例，说明recover的使用场景。考虑到语言解析器的复杂性，即使某个语言解析器目前工作正常，也无法肯定它没有漏洞。因此，当某个异常出现时，我们不会选择让解析器崩溃，而是会将panic异常当作普通的解析错误，并附加额外信息提醒用户报告此错误。
defer func () { if p := recover(); p != nil { fmt.Println(p) // 主动抛错 // 可以进行写日志等操作 } }() panic("主动抛错")</content></entry><entry><title>Go复杂数据结构</title><url>https://www.zhaohaiyu.com/post/go/go-complex-structure/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 数组 数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。 因为数组的长度是固定的，因此在Go语言中很少直接使用数组。
数组的每个元素可以通过索引下标来访问，索引下标的范围是从0开始到数组长度减1的位置。内置的len函数将返回数组中元素的个数。
var a [3]int // 长度为3的数组 fmt.Println(a[0]) // 打印第一个数据 fmt.Println(a[len(a)-1]) // 打印最后一个数据 for i, v := range a { fmt.Printf("%d %d\n", i, v) // 循环数组 i为索引 v为数据 } 默认情况下，数组的每个元素都被初始化为元素类型对应的零值
数组的初始化:
var a [3]int = [3]int{1, 2, 3} b := [...]int{1, 2, 3} a = [4]int{1, 2, 3, 4} // panic 数据初始化就是定长了 长度不能变化 切片 Slice（切片）代表变长的序列，序列中每个元素都有相同的类型。一个slice类型一般写作[]T，其中T代表slice中元素的类型；slice的语法和数组很像，只是没有固定长度而已。
一个slice由三个部分构成：指针、长度和容量。指针指向第一个slice元素对应的底层数组元素的地址，要注意的是slice的第一个元素并不一定就是数组的第一个元素。长度对应slice中元素的数目；长度不能超过容量，容量一般是从slice的开始位置到底层数据的结尾位置。内置的len和cap函数分别返回slice的长度和容量。
多个slice之间可以共享底层的数据，并且引用的数组部分区间可能重叠。
使用make()函数构造切片
make([]T, size, cap) // T:切片类型 size 切片数量 cap 切片容量 append()方法为切片添加元素
sli := make([]int,0,10) sli = append(sli,1) // 添加一个 1 arr := [4]int{6,7,8,9} sli = append(sle,arr...) // 把arr打散并全部添加 添加多个 fmt.Println(sli) // [1 6 7 8 9] 从切片中删除元素
// 从切片中删除元素 a := []int{30, 31, 32, 33, 34, 35, 36, 37} // 要删除索引为2的元素 a = append(a[:2], a[3:]...) fmt.Println(a) //[30 31 33 34 35 36 37] 切片的扩容策略
func growslice(et *_type, old slice, cap int) slice { newcap := old.cap doublecap := newcap + newcap if cap > doublecap { newcap = cap } else { if old.len &lt; 1024 { newcap = doublecap } else { for 0 &lt; newcap &amp;&amp; newcap &lt; cap { newcap += newcap / 4 } if newcap &lt;= 0 { newcap = cap } } } 在分配内存空间之前需要先确定新的切片容量，Go 语言根据切片的当前容量选择不同的策略进行扩容：
如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片容量小于 1024 就会将容量翻倍； 如果当前切片容量大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； MAP 哈希表是一种巧妙并且实用的数据结构。它是一个无序的key/value对的集合，其中所有的key都是不同的，然后通过给定的key可以在常数时间复杂度内检索、更新或删除对应的value。在Go语言中，一个map就是一个哈希表的引用，map类型可以写为map[K]V，其中K和V分别对应key和value。
初始化: m := make(map[string]int) 赋值初始化 m := map[string]int{ "zhy": 18, "who": 30, } // 直接赋值相当于 ages := make(map[string]int) ages["zhy"] = 18 ages["who"] = 30 **Map的迭代顺序是不确定的，并且不同的哈希函数实现可能导致不同的遍历顺序。**遍历的顺序是随机的，每一次遍历的顺序都不相同。
如果要有序:
// 用sort进项排序 var names []string for name := range ages { names = append(names, name) } sort.Strings(names) for _, name := range names { fmt.Printf("%s\t%d\n", name, ages[name]) } 结构体 结构体是一种聚合的数据类型，是由零个或多个任意类型的值聚合成的实体。每个值称为结构体的成员。
type people struct { name string age uint8 hobby []string address string sex uint8 } var zhy people 结构体赋值
h := []string{"唱","跳","RAP","篮球"} zhy := people{"zhaohaiyu",18,h,"地球",1} 或者
var zhy people zhy.name = "zhaohaiyu" zhy.age = 18 zhy.hobby = h zhy.address = "地球" zhy.sex = 1 结构体比较 如果结构体的全部成员都是可以比较的，那么结构体也是可以比较的，那样的话两个结构体将可以使用或!=运算符进行比较。相等比较运算符将比较两个结构体的每个成员，因此下面两个比较的表达式是等价的：
type Point struct{ X, Y int } p := Point{1, 2} q := Point{2, 1} fmt.Println(p.X == q.X &amp;&amp; p.Y == q.Y) // "false" fmt.Println(p == q) // "false" 结构体的继承 在java,python,cpp等语言中都有类的继承的概念,go语言中没有类.用结构体的嵌套实现继承.
type animal struct { name string age int } type people struct { address string animal animal } var zhy = people{ address: "地球", animal: animal{ name: "zhaohaiyu", age: 18, }, } fmt.Println(zhy.animal) // {zhaohaiyu 18} fmt.Println(zhy.animal.name) // zhaohaiyu fmt.Println(zhy.animal.age) // 18 fmt.Println(zhy.address) //地球 JSON JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。它基于ECMAScript(欧洲计算机协会制定的js规范)的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。
Go语言对于这些标准格式的编码和解码都有良好的支持，由标准库中的encoding/json包提供支持
JSON是对JavaScript中各种类型的值——字符串、数字、布尔值和对象——Unicode本文编码。它可以用有效可读的方式表示第三章的基础数据类型和本章的数组、slice、结构体和map等聚合数据类型。
各类型的json数据 boolean true number -273.15 string "hello world!!!!" array ["i", "you", "her"] object {"year": 2020, "event":"huawei","American virus","Trump is crazy"} go语言结构体成员Tag来指定对应的JSON名字。同样，在解码的时候也需要做同样的处理 type People struct { Name string `json:"name"` Age int `json:"age"` PhoneNumber string `json:"phone_number"` } 要将结构体的数据发给游览器前端或者安卓,IOS,APP等进行展示,因为go语言首字母小写只能本包用,在外部包要首字母大写,包括结构体和结构体成员.而且go语言崇尚驼峰体命名,而很多语言崇尚下划线命名.所有我们要用tag把json数据的成员变成首字母小写以及下划线命名.</content></entry><entry><title>Go基础类型</title><url>https://www.zhaohaiyu.com/post/go/go-type/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 整型 Go语言同时提供了有符号和无符号类型的整数运算。这里有int8、int16、int32和int64四种截然不同大小的有符号整数类型，分别对应8、16、32、64bit大小的有符号整数，与此对应的是uint8、uint16、uint32和uint64四种无符号整数类型。
Unicode字符rune类型是和int32等价的类型，通常用于表示一个Unicode码点。这两个名称可以互换使用。同样byte也是uint8类型的等价类型，byte类型一般用于强调数值是一个原始的数据而不是一个小的整数。
下面是Go语言中关于算术运算、逻辑运算和比较运算的二元运算符，它们按照优先级递减的顺序排列：
* / % > &amp; &amp;^ + - | ^ == != >= &amp;&amp; || 两个相同的整数类型可以使用下面的二元比较运算符进行比较；比较表达式的结果是布尔类型。
== // 等于 != // 不等于 &lt; // 小于 &lt;= // 小于等于 > // 大于 >= // 大于等于 浮点型 Go语言提供了两种精度的浮点数，float32和float64。它们的算术规范由IEEE754浮点数国际标准定义，该浮点数规范被所有现代的CPU支持。
float32类型的浮点数可以提供大约6个十进制数的精度，而float64则可以提供约15个十进制数的精度；通常应该优先使用float64类型，因为float32类型的累计计算误差很容易扩散，
var f float32 = 212213 fmt.Println(f == f + 1) 复数 Go语言提供了两种精度的复数类型：complex64和complex128，分别对应float32和float64两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部：
var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // "(-5+10i)" fmt.Println(real(x*y)) // "-5" fmt.Println(imag(x*y)) // "10" 布尔型 一个布尔类型的值只有两种：true和false。if和for语句的条件部分都是布尔类型的值，并且==和&lt;等比较操作也会产生布尔型的值, 布尔值可以和&amp;&amp;（AND）和||（OR）操作符结合
!true // flase a := 10 a > 1 // true 字符串 一个字符串是一个不可改变的字节序列。字符串可以包含任意的数据，包括byte值0，但是通常是用来包含人类可读的文本。文本字符串通常被解释为采用UTF8编码的Unicode码点（rune）序列
s := "hello, world" fmt.Println(len(s)) // "12" len() 长度 fmt.Println(s[0], s[7]) // "104 119" ('h' and 'w') 字符串值也可以用字符串面值方式编写，只要将一系列字节序列包含在双引号即可：
"Hello, 世界" 因为Go语言源文件总是用UTF8编码，并且Go语言的文本字符串也以UTF8编码的方式处理，因此我们可以将Unicode码点也写到字符串面值中。
在一个双引号包含的字符串面值中，可以用以反斜杠\开头的转义序列插入任意的数据。下面的换行、回车和制表符等是常见的ASCII控制代码的转义方式：
\a 响铃 \b 退格 \f 换页 \n 换行 \r 回车 \t 制表符 \v 垂直制表符 \' 单引号 (只用在 '\'' 形式的rune符号面值中) \" 双引号 (只用在 "..." 形式的字符串面值中) \\ 反斜杠 Unicode 因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte）。一个字节能表示的最大的整数就是255（2^8-1=255），而ASCII编码，占用0 - 127用来表示大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码 ，比如大写字母A的编码是65，小写字母z的编码是122。
如果要表示中文，显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312 编码，用来把中文编进去。
类似的，日文和韩文等其他语言也有这个问题。为了统一所有文字的编码，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。
Unicode通常用两个字节表示一个字符，原有的英文编码从单字节变成双字节，只需要把高字节全部填为0就可以。
UTF-8 UTF-8（8位元，Universal Character Set/Unicode Transformation Format）是针对Unicode的一种可变长度字符编码。它可以用来表示Unicode标准中的任何字符，而且其编码中的第一个字节仍与ASCII 相容，使得原来处理ASCII字符的软件无须或只进行少部份修改后，便可继续使用。因此，它逐渐成为电子邮件 、网页及其他存储或传送文字的应用中，优先采用的编码。
字符串和Byte切片 标准库中有四个包对字符串处理尤为重要：bytes、strings、strconv和unicode包。
strings包提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能。 bytes包也提供了很多类似功能的函数，但是针对和字符串有着相同结构的[]byte类型。因为字符串是只读的，因此逐步构建字符串会导致很多分配和复制。在这种情况下，使用bytes.Buffer类型将会更有效，稍后我们将展示。 strconv包提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换。 unicode包提供了IsDigit、IsLetter、IsUpper和IsLower等类似功能，它们用于给字符分类。每个函数有一个单一的rune类型的参数，然后返回一个布尔值。而像ToUpper和ToLower之类的转换函数将用于rune字符的大小写转换。所有的这些函数都是遵循Unicode标准定义的字母、数字等分类规范。strings包也有类似的函数，它们是ToUpper和ToLower，将原始字符串的每个字符都做相应的转换，然后返回新的字符串。 path和path/filepath包提供了关于文件路径名更一般的函数操作。使用斜杠分隔路径可以在任何操作系统上工作。斜杠本身不应该用于文件名，但是在其他一些领域可能会用于文件名，例如URL路径组件。相比之下，path/filepath包则使用操作系统本身的路径规则，例如POSIX系统使用/foo/bar，而Microsoft Windows使用c:\foo\bar等。 当向bytes.Buffer添加任意字符的UTF8编码时，最好使用bytes.Buffer的WriteRune方法，但是WriteByte方法对于写入类似&rsquo;[&lsquo;和&rsquo;]&lsquo;等ASCII字符则会更加有效。 bytes.Buffer类型有着很多实用的功能，我们在第七章讨论接口时将会涉及到，我们将看看如何将它用作一个I/O的输入和输出对象，例如当做Fprintf的io.Writer输出对象，或者当作io.Reader类型的输入源对象。 字符串和数字的转换 除了字符串、字符、字节之间的转换，字符串和数值之间的转换也比较常见。由strconv包提供这类转换功能。
将一个整数转为字符串，一种方法是用fmt.Sprintf返回一个格式化的字符串；另一个方法是用strconv.Itoa(“整数到ASCII”)：
x := 123 y := fmt.Sprintf("%d", x) fmt.Println(y, strconv.Itoa(x)) // "123 123" FormatInt和FormatUint函数可以用不同的进制来格式化数字：
fmt.Println(strconv.FormatInt(int64(x), 2)) // "1111011" fmt.Printf函数的%b、%d、%o和%x等参数提供功能往往比strconv包的Format函数方便很多，特别是在需要包含附加额外信息的时候：
s := fmt.Sprintf("x=%b", x) // "x=1111011" 如果要将一个字符串解析为整数，可以使用strconv包的Atoi或ParseInt函数，还有用于解析无符号整数的ParseUint函数：
x, err := strconv.Atoi("123") // x is an int y, err := strconv.ParseInt("123", 10, 64) // base 10, up to 64 bits ParseInt函数的第三个参数是用于指定整型数的大小；例如16表示int16，0则表示int。在任何情况下，返回的结果y总是int64类型，你可以通过强制类型转换将它转为更小的整数类型。
常量 常量表达式的值在编译期计算，而不是在运行期。每种常量的潜在类型都是基础类型：boolean、string、浮点型或整型。常量不可改变,一个常量的声明也可以包含一个类型和一个值，但是如果没有显式指明类型，那么将从右边的表达式推断类型。
const 声明:
const a = 10 // 整型 const p = 3.1415926 // 浮点型 const str = "zhaohaiyu" // 字符串 const flag = true // 布尔型 如果是批量声明的常量，除了第一个外其它的常量右边的初始化表达式都可以省略，如果省略初始化表达式则表示使用前面常量的初始化表达式写法，对应的常量类型也一样的。
const ( a = 1 b c = 2 d ) fmt.Println(a, b, c, d) // "1 1 2 2" iota 常量生成器 常量声明可以使用iota常量生成器初始化，它用于生成一组以相似规则初始化的常量，但是不用每行都写一遍初始化表达式。在一个const声明语句中，在第一个声明的常量所在的行，iota将会被置为0，然后在每一个有常量声明的行加一。
const ( a = 1 + iota b c d ) fmt.Println(a,b,c,d) // 1,2,3,4</content></entry><entry><title>Go基础结构</title><url>https://www.zhaohaiyu.com/post/go/go-infrastructure/</url><categories><category>go</category></categories><tags><tag>golang</tag></tags><content type="html"> 命名 Go语言中的函数名、变量名、常量名、类型名、语句标号和包名等所有的命名,都遵循一个简单的命名规则：一个名字必须以一个字母（Unicode字母）或下划线开头,后面可以跟任意数量的字母、数字或下划线.大写字母和小写字母是不同的：heapSort和Heapsort是两个不同的名字.
Go语言的关键字有25个,关键字不能用于自定义名字. 分别为:
break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var 还有大约30多个预定义的名字,这些内部预先定义的名字并不是关键字，你可以在定义中重新使用它们。在一些特殊的场景中重新定义它们也是有意义的，但是也要注意避免过度而引起语义混乱.
内建常量: true false iota nil 内建类型: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string error 内建函数: make len cap new append copy close delete complex real imag panic recover 在习惯上，Go语言程序员推荐使用 驼峰式 命名，当名字有几个单词组成的时优先使用大小写分隔，而不是优先用下划线分隔。
声明 Go语言主要有四种类型的声明语句：var、const、type和func，分别对应变量、常量、类型和函数实体对象的声明。
一个Go语言编写的程序对应一个或多个以.go为文件后缀名的源文件中。每个源文件以包的声明语句开始，说明该源文件是属于哪个包。包声明语句之后是import语句导入依赖的其它包，然后是包一级的类型、变量、常量、函数的声明语句.
package main // main包 import "fmt" // 引入fmt内部包 const price = 212.0 // 浮点型常量 func main() { var f = price // f浮点型变量 var c = (f - 32) * 5 / 9 // c浮点型变量 fmt.Printf("f = %g c = %g\n", f, c) // %g为浮点型占位符 fmt.Printf("f:%T,c:%T", f, c) // %T为打印类型 结果:f:float64,c:float64 } 变量 var声明语句可以创建一个特定类型的变量，然后给变量附加一个名字，并且设置变量的初始值。变量声明的一般语法如下：
var 变量名字 类型 = 表达式
// 例如 var name string = "zhy" 其中“类型”或“= 表达式”两个部分可以省略其中的一个。如果省略的是类型信息，那么将根据初始化表达式来推导变量的类型信息。如果初始化表达式被省略，那么将用零值初始化该变量。 数值类型变量对应的零值是0，布尔类型变量对应的零值是false，字符串类型对应的零值是空字符串，接口或引用类型（包括slice、指针、map、chan和函数）变量对应的零值是nil。数组或结构体等聚合类型对应的零值是每个元素或字段都是对应该类型的零值。
var s string fmt.Println(s) // "" 也可以在一个声明语句中同时声明一组变量，或用一组初始化表达式声明并初始化一组变量。如果省略每个变量的类型，将可以声明多个类型不同的变量（类型由初始化表达式推导）：
var i, j, k int // int, int, int var b, f, s = true, 2.3, "four" // bool, float64, string 一组变量也可以通过调用一个函数，由函数返回的多个返回值初始化：
var f, err = os.Open("./project.log") // 打开文件 f为句柄 err为错误 简短变量声明 在函数内部，有一种称为简短变量声明语句的形式可用于声明和初始化局部变量。它以“名字 := 表达式”形式声明变量，变量的类型根据表达式来自动推导。
name := "zhy" f,err := os.Open("./project.log") 指针 一个变量对应一个保存了变量对应类型值的内存空间。一个指针的值是另一个变量的地址。一个指针对应变量在内存中的存储位置。并不是每一个值都会有一个内存地址，但是对于每一个变量必然有对应的内存地址。通过指针，我们可以直接读或更新对应变量的值，而不需要知道该变量的名字（如果变量有名字的话）。指针的定义为*+类型比如*int等,或者把变量的地址赋值给指针,编辑器会自动推到指针的类型
var number *int var a = 100 var b = &amp;a // &amp;为取值符 用*+指针变量出去所指变量的值
fmt.Println(*p) // 0 fmt.Println(*b) // 100 New初始化 另一个创建变量的方法是调用用内建的new函数。表达式new(T)将创建一个T类型的匿名变量，初始化为T类型的零值，然后返回变量地址，返回的指针类型为*T。
p := new(int) // p, *int 类型, 指向匿名的 int 变量 fmt.Println(*p) // "0" *p = 2 // 设置 int 匿名变量的值为 2 fmt.Println(*p) // "2" 变量的生命周期 变量的生命周期指的是在程序运行期间变量有效存在的时间间隔。对于在包一级声明的变量来说，它们的生命周期和整个程序的运行周期是一致的。而相比之下，局部变量的声明周期则是动态的：**每次从创建一个新变量的声明语句开始，直到该变量不再被引用为止，然后变量的存储空间可能被回收。**函数的参数变量和返回值变量都是局部变量。它们在函数每次被调用的时候创建。
赋值 直接赋值x = 100 通过指针赋值*p = &ldquo;zhy&rdquo; 结构体赋值stu.name = &ldquo;zhy&rdquo; 数组切片赋值lst[1] = lst[1] + 1 二元运算符x *= 6等同于x = x * 6 自加自减x++x&ndash; 交换赋值x,y = y,x 函数赋值f, err = os.Open(&ldquo;project.log&rdquo;) 类型 一个类型声明语句创建了一个新的类型名称，和现有类型具有相同的底层结构。新命名的类型提供了一个方法，用来分隔不同概念的类型，这样即使它们底层类型相同也是不兼容的。
type 类型名字 底层类型 包 Go语言中的包和其他语言的库或模块的概念类似，目的都是为了支持模块化、封装、单独编译和代码重用。一个包的源代码保存在一个或多个以.go为文件后缀名的源文件中，通常一个包所在目录路径的后缀是包的导入路径；
作用域 一个声明语句将程序中的实体和一个名字关联，比如一个函数或一个变量。声明语句的作用域是指源代码中可以有效使用这个名字的范围。
func f() {} var g = "g" func main() { f := "f" fmt.Println(f) // main函数的作用域 fmt.Println(g) // g包作用域 fmt.Println(h) // pinic报错 没有找到 } 用:=声明变量,只能在函数内使用,在全局使用会报错</content></entry></search>